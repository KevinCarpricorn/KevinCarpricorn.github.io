[{"title":"傅立叶分析","date":"2022-03-07T14:27:29.000Z","path":"2022/03/07/傅立叶分析（转载）/","tags":[{"name":"数学","slug":"数学","permalink":"http://example.com/tags/%E6%95%B0%E5%AD%A6/"},{"name":"傅立叶","slug":"傅立叶","permalink":"http://example.com/tags/%E5%82%85%E7%AB%8B%E5%8F%B6/"},{"name":"傅立叶分析","slug":"傅立叶分析","permalink":"http://example.com/tags/%E5%82%85%E7%AB%8B%E5%8F%B6%E5%88%86%E6%9E%90/"},{"name":"傅立叶级数","slug":"傅立叶级数","permalink":"http://example.com/tags/%E5%82%85%E7%AB%8B%E5%8F%B6%E7%BA%A7%E6%95%B0/"}]},{"title":"softmax","date":"2022-02-19T06:29:33.000Z","path":"2022/02/19/softmax/","tags":[]},{"title":"如何理解“梯度下降法”？什么是“反向传播”？","date":"2022-02-16T05:25:07.000Z","path":"2022/02/16/梯度下降/","tags":[{"name":"数学","slug":"数学","permalink":"http://example.com/tags/%E6%95%B0%E5%AD%A6/"},{"name":"神经网络","slug":"神经网络","permalink":"http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"梯度","slug":"梯度","permalink":"http://example.com/tags/%E6%A2%AF%E5%BA%A6/"},{"name":"梯度下降法","slug":"梯度下降法","permalink":"http://example.com/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/"},{"name":"反向传播","slug":"反向传播","permalink":"http://example.com/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"},{"name":"偏微分","slug":"偏微分","permalink":"http://example.com/tags/%E5%81%8F%E5%BE%AE%E5%88%86/"},{"name":"链式反导","slug":"链式反导","permalink":"http://example.com/tags/%E9%93%BE%E5%BC%8F%E5%8F%8D%E5%AF%BC/"}]},{"title":"交叉熵如何做损失函数？","date":"2022-02-15T07:33:05.000Z","path":"2022/02/15/交叉熵/","tags":[{"name":"人工智能","slug":"人工智能","permalink":"http://example.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"熵","slug":"熵","permalink":"http://example.com/tags/%E7%86%B5/"},{"name":"信息量","slug":"信息量","permalink":"http://example.com/tags/%E4%BF%A1%E6%81%AF%E9%87%8F/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"神经网络","slug":"神经网络","permalink":"http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"损失函数","slug":"损失函数","permalink":"http://example.com/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"},{"name":"交叉熵","slug":"交叉熵","permalink":"http://example.com/tags/%E4%BA%A4%E5%8F%89%E7%86%B5/"}]},{"title":"“损失函数”是如何设计出来的？直观理解“最小二乘法”和“极大似然估计法”","date":"2022-02-13T08:42:43.000Z","path":"2022/02/13/损失函数/","tags":[{"name":"神经网络","slug":"神经网络","permalink":"http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"损失函数","slug":"损失函数","permalink":"http://example.com/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"},{"name":"机器学期","slug":"机器学期","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E6%9C%9F/"},{"name":"最小二乘法","slug":"最小二乘法","permalink":"http://example.com/tags/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/"},{"name":"极大似然估计","slug":"极大似然估计","permalink":"http://example.com/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/"}]},{"title":"卷积神经网络模型","date":"2021-12-03T19:08:51.000Z","path":"2021/12/04/卷积神经网络模型/","tags":[{"name":"Pytorch","slug":"Pytorch","permalink":"http://example.com/tags/Pytorch/"}]},{"title":"Kaggle--图像分类(CIFAR-10) 基于Pytorch的实现","date":"2021-08-29T09:26:15.000Z","path":"2021/08/29/Kaggle - 图像分类(CIFAR-10)/","tags":[{"name":"Pytorch","slug":"Pytorch","permalink":"http://example.com/tags/Pytorch/"}]},{"title":"ggplot2 cheat sheet (转载)","date":"2021-05-10T17:13:57.000Z","path":"2021/05/11/ggplot2-cheat-sheet-转载/","tags":[{"name":"ggplot2","slug":"ggplot2","permalink":"http://example.com/tags/ggplot2/"}]},{"title":"R语言 dnorm, pnorm, qnorm, rnorm的区别","date":"2021-05-09T12:02:30.000Z","path":"2021/05/09/R语言-dnorm-pnorm-qnorm-rnorm的区别/","tags":[{"name":"R","slug":"R","permalink":"http://example.com/tags/R/"}]},{"title":"Hexo d部署报错之spawn failed的解决方案","date":"2021-05-09T01:25:28.000Z","path":"2021/05/09/Hexo d部署报错之spawn failed的解决方案/","tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://example.com/tags/Hexo/"}]}]