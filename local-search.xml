<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>梯度下降的优化算法</title>
    <link href="/2022/03/09/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%9A%84%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/"/>
    <url>/2022/03/09/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%9A%84%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>通过之前的学习我们知道通过梯度下降法，我们可以优化模型的参数。 但是如果按照我们之前推断的数学方式直接进行实现的话， 以目前的算力几乎是不可能实现的，甚至说在可见的未来也不太可能。 所以说梯度下降法在上个世纪七十年代就提出来了，直到2012年Alexnet出现才得以应用。 在这期间，科学家们的想法主要是对梯度下降法进行优化。 那么我们先不说科学家是怎么想的，我们自己先想一想如何对梯度下降法进行优化。 一个方向是优化计算梯度的时间，另一个方向是优化梯度下降的路径。 我们先来看一看如何优化计算梯度的时间：</p><h3 id="随机梯度下降法">随机梯度下降法</h3><p>假设我们这里使用的是最小交叉熵， 我们可以看到公式： <span class="math display">\[\mathscr{L}\left(\hat{y}, y\right) = -\sum\left(y\log\hat{y} + \left(1-y\right)\log\left(1-\hat{y}\right)\right)\]</span> 在反向传播过程中，我们需要对每一个输入数据的参数都要求梯度,那么在一个特别大的模型或者说最近非常流行的一些深度网络中，数据量是极其庞大的，并且网络的宽度也是极其大的，每一个数据或者参数可能都有非常高的维度， 因此在工程上要直接对所有的输入数据求梯度几乎是不可能的， 即使可以实现也是不实用的。 那我们就可以思考一下，假设我们要知道全国男性的平均身高我们不可能去采集所有男性的身高，因为这很不现实。那这种情况我们会怎么做呢？我们是不是会考虑对部分地区进行采样，对一小块采样数据进行建模，他可以大致模拟全国的数据分布。那么在机器学习领域我们是否也可以使用这种想法呢？ 数学家已经证明了我们确实可以使用类似的方法，我们对某个特定的数据求梯度其实可以大致模拟整个数据的梯度下降的方向。当然在真实情况下，我们不可能只选其中一个数据求梯度，我们会选取一个小批量的数据来作为样本去求它的梯度来 模拟整个数据集的梯度方向。 这个方法又被称为批量梯度下降法（Batch Gradient Descent ｜mini-batch）。 那么这种方法真的可以加快梯度下降的速度吗？ 数学家们已经证明了在凸问题下经过<span class="math inline">\(k\)</span>次迭代之后，随机梯度下降算法和梯度下降算法的误差会在<span class="math inline">\(\frac{1}{\sqrt{k}}\)</span>这个量级（<span class="math inline">\(f(x^{(k)}) - f^* = O(\frac{1}{\sqrt{k}})\)</span> ）。如果是强凸问题的话他的收敛好会更快一些，误差会在<span class="math inline">\(\frac{1}{k}\)</span> (<span class="math inline">\(f(x^{(k)}) - f^* = O(\frac{1}{k})\)</span> )。</p><hr /><p>考虑完第一个优化的方向之后我们就思考第二个方向，是否可以优化梯度下降的路径来优化算法呢？ 我们知道梯度的方向已经指向了数据下降最快的方向那么对路径的优化还有必要吗？当然是有的，如果我们使用随机梯度下降法的话，因为我们选取的数据是随机的那么他的下降路径一定和真实的路径就是有偏差的那么这就给我们带来了优化的空间。即使我们使用的是梯度下降法它仍然是有优化空间的，因为我们每一次求得的梯度只是在当时的那个点梯度下降的最快的方向。对于全局来说他仍然是有偏差的。通过下图我们可以看到：</p><p><img src="./Screen Shot 2022-03-21 at 6.56.22 pm.jpg" alt="" style="zoom:50%;" /></p><p>当我们固定步长时， <span class="math inline">\(A\)</span>点在梯度方向上移动会到达<span class="math inline">\(A^{’}\)</span> 而在<span class="math inline">\(B\)</span>点时梯度方向却发生了改变，那么为了达到极致点的话就会需要得到更多的步数。</p><p>我们当然也是可以直接计算它的最优路径的，那就是我们把他的步长增加到无限小那次就是微积分的概念了，我们就能求得他在极限下的路径但是随之迭代的次数也会增加。 那么有没有一种方法可以在不改变步长的情况下，使得他的路径更平滑呢？</p><h3 id="牛顿法">牛顿法</h3><p>我们先在二维实用一个一维变量举个例子</p><p><img src="./Screen Shot 2022-03-21 at 7.02.27 pm.jpg" alt="" style="zoom:50%;" /></p><p>我们可以看到橙色的线就是这个点的切线在高维来说就是梯度，灰色的线就是最优路径。我们会发现切线方向上固定步长<span class="math inline">\(\Delta x\)</span>的位置和真实方向上差距很大。那我们就思考是否可以使用一个抛物线来拟合函数曲线，使得他的极值点更接近我们的最优路径的方向呢？牛顿就把这个公式写了出来： <span class="math display">\[W = W - \frac{J&#39;(W)}{J&#39;&#39;(W)}\]</span> 那我这个公式是如何得出来的呢？我们假设<span class="math inline">\(J(x)\)</span>为损失函数，我们对他进行二阶的泰勒展开，那么 <span class="math display">\[J(x) \approx J(a_0) + J&#39;(a_0)(x - a_0) + \frac{1}{2}J&#39;&#39;(a_0)(x - a_0)^2\]</span> 如果我们把这个泰勒展开在坐标系中画出来就是这个绿色的曲线，我们可以用<span class="math inline">\(f(x)\)</span>来表示。那么这个函数最接近真实方向的点就是这个函数的极值点。我们令<span class="math inline">\(f&#39;(x) = 0\)</span> <span class="math display">\[\begin{align}f&#39;(x) &amp;= J&#39;(a_0) + J&#39;&#39;(a_0)(x - a_0) = 0 \\x &amp;= a_0 - \frac{J&#39;(a_0)}{J&#39;&#39;(a_0)} \\W &amp;= W - \cancel{\eta\cdot} \frac{J&#39;(W)}{J&#39;&#39;(W)}\end{align}\]</span> 因为我们这里直接使用的是泰勒展开之后的极值点，所以不需要学习率来固定步长。</p><p>在更高的维度来说，其实也是一样的。通过下图可以看到，橙色的线是我们正常使用梯度下降的方向，绿色线是我们使用牛顿法构造出来的方向，而灰色显示真实的方向。</p><p><img src="./Screen Shot 2022-03-21 at 7.22.19 pm.jpg" alt="" style="zoom:50%;" /> <span class="math display">\[W = W - \nabla^2J(W)^{-1} \cdot \nabla J(W)\]</span> 其中<span class="math inline">\(\nabla^2J(W)\)</span> 也就是Hessian矩阵<span class="math inline">\(H(W)\)</span>， <span class="math inline">\(\nabla J(W)\)</span> 是Jacobian矩阵</p><p><img src="./Screen Shot 2022-03-21 at 7.26.15 pm.jpg" alt="" style="zoom:50%;" /></p><hr /><p>牛顿法虽然已经提出了一个很好的思路，但是每次计算的时候我们都还要计算两个梯度矩阵，这个计算量仍是非常大的依旧无法实现。但是既然牛顿法我们可以在所有维度上的梯度统一考虑去寻找一个最优的路径，那为什么不尝试在不同的维度上分别考虑呢？</p><h3 id="动量法冲量法">动量法（冲量法）</h3><p><img src="./Screen%20Shot%202022-03-21%20at%2010.48.30%20pm.jpg" /></p><p>首先我们来看一个比较简单的情况。在这里所有的橙色线表示每一步沿着梯度方向走的路径，我们可以看到分别在横轴和纵轴上有两个分量，我们可以很明显的看到影响路径震荡的原因是纵轴的分量过大。因此为了获得更优的路径我们可以考虑减小每一步纵轴的分量大小并且增加横轴的分量大小，使得他可以更快的到达极值点。就会变成下图这样：</p><p><img src="./Screen Shot 2022-03-21 at 10.57.28 pm.jpg" alt="" style="zoom:67%;" /></p><p>我们可以把权重每一步的变换写出来就是这样： <span class="math display">\[\begin{align}W_{(t)} &amp;= W_{(t-1)} - \eta \cdot \nabla J \\\begin{bmatrix}b_{(t)}\\ W_{(t)1} \\ W_{(t)2} \\ \cdots \\ W_{(t)i}\end{bmatrix} &amp;=\begin{bmatrix} b_{(t-1)}-\eta \cdot \frac{\part J}{\part b} \\W_{(t-1)1} - \eta \cdot \frac{\part J}{\part W_1} \\W_{(t-1)2} - \eta \cdot \frac{\part J}{\part W_2} \\\cdots \\W_{(t-1)i} - \eta \cdot \frac{\part J}{\part W_i}\end{bmatrix}\end{align}\]</span> 为了方便后面的计算我们这里定义一个新的变量 <span class="math inline">\(\Delta W_{(t)i} = \frac{\partial J(W_{(t-1)i})}{\part W_i}\)</span>, 则： <span class="math display">\[W_{(t)i} = W_{(t-1)i} - \eta \cdot \Delta W_{(t)i}\]</span> 这里定义的<span class="math inline">\(\Delta W_{(t)i}\)</span> 表示的是这个系数在这个维度下应该调整多少，他其实跟原本的本质上是没有区别的，原本的公式是在不同的分量上沿着梯度方向调整，我们只不过为了后面的方便写成这个样子。本来我们有了<span class="math inline">\(\Delta W_{(t)i}\)</span>后就可以直接带入计算了， 但这里我们增加了一个中间过程。 <span class="math display">\[\begin{align}V_{(t)} &amp;= V_{(t-1)} + \Delta W_{(t)i} \\W_{(t)i} &amp;= W_{(t-1)i} - \eta \cdot V_{(t)}\end{align}\]</span> 我们定义了一个新的变量 <span class="math inline">\(V_{(t)}\)</span>, 这里他其实是一个递归的定义。我们可以看出来其实这里的<span class="math inline">\(V_{(t-1)}\)</span> 就是把历史上前面所有的<span class="math inline">\(\Delta W_{(t)i}\)</span>的和。通过这种方法我们就可以把历史的信息考虑进来，通过历史的信息对现在的分量调整。我们把历史上所有的<span class="math inline">\(\Delta W_{(t)i}\)</span>求和其实也很容易理解，当当前的某个分量跟过去的分量方向不同的时候分量相加会得到一个折中的方向，当分量相同的时候我们知道这个方向是我们可以更快到达极值点的方向所有分量相加会更大。但是使用这种方法会有一个问题，就是当如果我们步数足够多的话，每一个过去的信息都会一视同仁全部相加。但可能在过去很远的信息对现在的影响相对较小， 以相同的权重进行相加的话可能就不太合适了。所以到这里我们相当于只是给动量法提供了一个思路，真正实现的过程应该是这样的 <span class="math display">\[V_{(t)} = \beta \cdot V_{(t-1)} + (1 - \beta) \cdot \Delta W_{(t)i}\]</span> 这里相当于就是对所有的信息进行一个加权求和， 但为什么这里用额<span class="math inline">\(\beta\)</span> 和 <span class="math inline">\((1-\beta)\)</span>呢？其实这也就用了一个数学上的灰尘常用的一个方法叫指数加权移动平均法（<a href="https://en.wikipedia.org/wiki/Moving_average">EWMA</a>）。通过这种方式我们就可以以最近的步作为基础，更远的步我们给予更小的权重。</p><hr /><p>其实对梯度下降法进行优化，我们不仅可以去参考过去的数据，甚至可以超前去参考未来的数据。</p><h3 id="nesterov">Nesterov</h3><p>在讲Nesterov之前我们先来看一下基本的动量法是怎么做的</p><p><img src="./Screen Shot 2022-03-21 at 11.38.55 pm.jpg" alt="" style="zoom:50%;" /></p><p>这里的橙色虚线是当前位置的梯度方向，绿色虚线是动量方向，而橙色的实线就是动量法中我们下降的方向。</p><p><img src="./Screen Shot 2022-03-21 at 11.44.15 pm.jpg" alt="" style="zoom:50%;" /></p><p>那如果我们再进一步的进行动量法会求得下一个点，而这一个点的方向，显然好于我们之前的方向。那我们有什么方法可以超前获得未来这个点的方向呢？ 这就是Nesterov算法的精妙之处了。 他其实是对原本动量法中的<span class="math inline">\(\Delta W_{(t)i}\)</span>进行了一些修改 <span class="math display">\[\Delta W_{(t)i} = \frac{\part J(W_{(t-1)i}) + \gamma V_{(t-1)}}{\part W_i}\]</span> 我们最开始<span class="math inline">\(W_{(t)i} = W_{(t-1)i} - \eta \cdot V_{(t)}\)</span> 求的是第一个灰色点和第二个灰色点的方向， 而这里的<span class="math inline">\(\Delta W_{(t)i}\)</span> 其实是绿色箭头指向的位置的梯度方向，也就是红色这条线</p><p><img src="./Screen Shot 2022-03-21 at 11.53.54 pm.jpg" alt="" style="zoom:50%;" /></p><p>当我们求出来这个方向后把他向上平移，然后再修正参数</p><p><img src="./Screen Shot 2022-03-21 at 11.55.16 pm.jpg" alt="" style="zoom:50%;" /></p><p>此时获得的梯度方向会更加接近于真实的方向。</p><h3 id="adagrad">AdaGrad</h3><p>除了上述的方法，其实我们也认为学习率不应该是一个固定的值，因为如果学习率太大的话很可能越过极值点， 在极值点附近一直震荡，如果学习率过小的话可能需要过多的步数才能到达极值点。因此一种解决方法就是使用自适应的调整学习率。 AdaGrad算法通过给学习率添加一个参数，让他可以考虑过去梯度的影响从而动态的调整学习率。 <span class="math display">\[W_{(t)i} = W_{(t-1)i} - \frac{\eta}{\sqrt{S_{(t)}} + \varepsilon } \cdot \Delta W_{(t)i}\]</span> 其中 <span class="math inline">\(S_{(t)} = S_{(t-1)} + \Delta W_{(t)i}\cdot \Delta W_{(t)i}\)</span>, 这里的 <span class="math inline">\(\varepsilon\)</span> 是个极小值为了防止除0。这里我们可以理解为对梯度的内积开方，学习到的梯度是真实梯度除以梯度内积的开方。 由于梯度在各个分量上对量级不一致会导致震荡，因此AdaGrad本质是解决各方向导数数值量级的不一致而将梯度数值归一化。</p><p>AdaGrad算法对稀疏数据表现良好，什么叫稀疏数据呢，就是当数据之间特征的类型不同而不是程度不同的时候我们称之为稀疏数据（比如，区分人和狗）。对于稀疏数据我们相当于给定每一个特征的数据量较少，对于每一个维度特征的梯度变化较大，因此使用AdaGrad就能很好的避免这种情况产生的震荡。 但是对于有“平台期”的数据可能就会导致即使经过了平台期梯度依然下降的很慢，因为他需要考虑到历史上所有的信息。</p><p><img src="./Screen Shot 2022-03-22 at 12.52.17 am.jpg" alt="" style="zoom:50%;" /></p><h3 id="rmsprop">RMSProp</h3><p>RMSProp其实是对AdarGrad的一种优化方法。他基于动量法的思想对使用EWMA的方法对AdaGrad进行优化 <span class="math display">\[\begin{align}S_{(t)} &amp;= \beta S_{(t-1)} + (1-\beta)\Delta W_{(t)i}\cdot \Delta W_{(t)i} \\W_{(t)i} &amp;= W_{(t-1)i} - \frac{\eta}{\sqrt{S_{(t)}} + \varepsilon } \cdot \Delta W_{(t)i}\end{align}\]</span></p><h3 id="adam">Adam</h3><p>Adam算法其实就是将动量法和RMSProp进行结合 <span class="math display">\[\begin{align}V_{(t)} &amp;= \beta_1 \cdot V_{(t-1)} + (1 - \beta_1)\cdot \Delta W_{(t)i} \\S_{(t)} &amp;= \beta_2 S_{(t-1)} + (1-\beta_2)\Delta W_{(t)i}\cdot \Delta W_{(t)i} \\W_{(t)i} &amp;= W_{(t-1)i} - \frac{\eta}{\sqrt{S_{(t)}} + \varepsilon } \cdot V_{(t)}\end{align}\]</span></p><h3 id="references">References</h3><p>https://www.bilibili.com/video/BV1r64y1s7fU?spm_id_from=333.999.0.0</p><p>https://en.wikipedia.org/wiki/Moving_average</p><hr /><p><strong><em>知识来源作者为b站UP主王木头学科学</em></strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>随机梯度下降</tag>
      
      <tag>牛顿</tag>
      
      <tag>动量</tag>
      
      <tag>Nestero</tag>
      
      <tag>AdaGra</tag>
      
      <tag>RMSpro</tag>
      
      <tag>Adam</tag>
      
      <tag>优化算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>傅立叶分析</title>
    <link href="/2022/03/07/%E5%82%85%E7%AB%8B%E5%8F%B6%E5%88%86%E6%9E%90%EF%BC%88%E8%BD%AC%E8%BD%BD%EF%BC%89/"/>
    <url>/2022/03/07/%E5%82%85%E7%AB%8B%E5%8F%B6%E5%88%86%E6%9E%90%EF%BC%88%E8%BD%AC%E8%BD%BD%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p>作 者：韩 昊</p><p>知 乎：Heinrich</p><p>微 博：<span class="citation" data-cites="花生油工人">@花生油工人</span></p><p>知乎专栏：与时间无关的故事</p><p>谨以此文献给大连海事大学的吴楠老师，柳晓鸣老师，王新年老师以及张晶泊老师。</p><hr /><p>我保证这篇文章和你以前看过的所有文章都不同，这是12年还在果壳的时候写的，但是当时没有来得及写完就出国了……于是拖了两年，嗯，我是拖延症患者……</p><p>这篇文章的核心思想就是：</p><p><strong>要让读者在不看任何数学公式的情况下理解傅里叶分析。</strong></p><p>傅里叶分析不仅仅是一个数学工具，更是一种可以彻底颠覆一个人以前世界观的思维模式。但不幸的是，傅里叶分析的公式看起来太复杂了，所以很多大一新生上来就懵圈并从此对它深恶痛绝。老实说，这么有意思的东西居然成了大学里的杀手课程，不得不归咎于编教材的人实在是太严肃了。（您把教材写得好玩一点会死吗？会死吗？）所以我一直想写一个有意思的文章来解释傅里叶分析，有可能的话高中生都能看懂的那种。所以，不管读到这里的您从事何种工作，我保证您都能看懂，并且一定将体会到通过傅里叶分析看到世界另一个样子时的快感。至于对于已经有一定基础的朋友，也希望不要看到会的地方就急忙往后翻，仔细读一定会有新的发现。</p><hr /><p>下面进入正题：</p><p>抱歉，还是要啰嗦一句：其实学习本来就不是易事，我写这篇文章的初衷也是希望大家学习起来更加轻松，充满乐趣。但是千万！千万不要把这篇文章收藏起来，或是存下地址，心里想着：以后有时间再看。这样的例子太多了，也许几年后你都没有再打开这个页面。无论如何，耐下心，读下去。这篇文章要比读课本要轻松、开心得多……</p><p>p.s. 本文无论是<span class="math inline">\(\cos\)</span>还是<span class="math inline">\(\sin\)</span>，都统一用“正弦波”（Sine Wave）一词来代表<strong>简谐波</strong>。</p><h2 id="一什么是频域">一、什么是频域</h2><p>从我们出生，我们看到的世界都以时间贯穿，股票的走势、人的身高、汽车的轨迹都会随着时间发生改变。这种以时间作为参照来观察动态世界的方法我们称其为时域分析。而我们也想当然的认为，世间万物都在随着时间不停的改变，并且永远不会静止下来。但如果我告诉你，用另一种方法来观察世界的话，你会发现<u>世界是永恒不变的</u>，你会不会觉得我疯了？我没有疯，这个静止的世界就叫做频域。</p><p>先举一个<strong>公式上并非很恰当</strong>，但意义上再贴切不过的例子：</p><p>在你的理解中，一段音乐是什么呢？<img src="./2ca39677363c65a305207a5491b75825_1440w.jpg" /></p><p>这是我们对音乐最普遍的理解，一个随着时间变化的震动。但我相信对于乐器小能手们来说，音乐更直观的理解是这样的：</p><p><img src="./8e1fce9d7607d97cebf73e1f36f03f06_1440w.jpg" /></p><p>好的！下课，同学们再见。</p><p>是的，其实这一段写到这里已经可以结束了。上图是音乐在时域的样子，而下图则是音乐在频域的样子。所以频域这一概念对大家都从不陌生，只是从来没意识到而已。</p><p>现在我们可以回过头来重新看看一开始那句痴人说梦般的话：世界是永恒的。</p><p>将以上两图简化：</p><p>时域：</p><p><img src="./d4fa1de0327eb491a6941ac84a56e432_1440w.jpg" alt="d4fa1de0327eb491a6941ac84a56e432_1440w" style="zoom:80%;" /></p><p>频域：</p><p><img src="./1ca366b593d877a16c8a49773774b5b9_1440w.jpg" /></p><p>在时域，我们观察到钢琴的琴弦一会上一会下的摆动，就如同一支股票的走势；而在频域，只有那一个永恒的音符。</p><p>所以</p><p><strong>你眼中看似落叶纷飞变化无常的世界，实际只是躺在上帝怀中一份早已谱好的乐章。</strong></p><p>抱歉，这不是一句鸡汤文，而是黑板上确凿的公式：傅里叶同学告诉我们，任何周期函数，都可以看作是不同振幅，不同相位正弦波的叠加。在第一个例子里我们可以理解为，利用对不同琴键不同力度，不同时间点的敲击，可以组合出任何一首乐曲。</p><p>而贯穿时域与频域的方法之一，就是传中说的傅里叶分析。傅里叶分析可分为傅里叶级数（Fourier Serie）和傅里叶变换(Fourier Transformation)，我们从简单的开始谈起。</p><h2 id="二傅里叶级数fourier-series的频谱">二、傅里叶级数(Fourier Series)的频谱</h2><p>还是举个栗子并且有图有真相才好理解。</p><p>如果我说我能用前面说的正弦曲线波叠加出一个带90度角的矩形波来，你会相信吗？你不会，就像当年的我一样。但是看看下图：</p><p><img src="./055bf33bb84555a952804c5dbeb75dd9_1440w.jpg" /></p><p>第一幅图是一个郁闷的正弦波<span class="math inline">\(\cos(x)\)</span></p><p>第二幅图是2个卖萌的正弦波的叠加<span class="math inline">\(\cos(x) + a \cdot cos(3x)\)</span></p><p>第三幅图是4个发春的正弦波的叠加</p><p>第四幅图是10个便秘的正弦波的叠加</p><p>随着正弦波数量逐渐的增长，他们最终会叠加成一个标准的矩形，大家从中体会到了什么道理？</p><p>（只要努力，弯的都能掰直！）</p><p>随着叠加的递增，所有正弦波中上升的部分逐渐让原本缓慢增加的曲线不断变陡，而所有正弦波中下降的部分又抵消了上升到最高处时继续上升的部分使其变为水平线。一个矩形就这么叠加而成了。但是要多少个正弦波叠加起来才能形成一个标准90度角的矩形波呢？不幸的告诉大家，答案是无穷多个。（上帝：我能让你们猜着我？）</p><p>不仅仅是矩形，你能想到的任何波形都是可以如此方法用正弦波叠加起来的。这是没 有接触过傅里叶分析的人在直觉上的第一个难点，但是一旦接受了这样的设定，游戏就开始有意思起来了。</p><p>还是上图的正弦波累加成矩形波，我们换一个角度来看看：</p><p><img src="./563deb4a6599d052b3ba108661872c57_1440w.jpg" /></p><p>在这几幅图中，最前面黑色的线就是所有正弦波叠加而成的总和，也就是越来越接近矩形波的那个图形。而后面依不同颜色排列而成的正弦波就是组合为矩形波的各个分量。这些正弦波按照频率从低到高从前向后排列开来，而每一个波的振幅都是不同的。一定有细心的读者发现了，每两个正弦波之间都还有一条直线，那并不是分割线，而是振幅为0的正弦波！也就是说，为了组成特殊的曲线，有些正弦波成分是不需要的。</p><p>这里，不同频率的正弦波我们称为频率分量。</p><p>好了，关键的地方来了！！</p><p>如果我们把第一个频率最低的频率分量看作“1”，我们就有了构建频域的最基本单元。</p><p>对于我们最常见的有理数轴，数字“1”就是有理数轴的基本单元。</p><p>时域的基本单元就是“1秒”，如果我们将一个角频率为<span class="math inline">\(\omega_0\)</span>的正弦波<span class="math inline">\(\cos(\omega_0t)\)</span>看作基础，那么频域的基本单元就是<span class="math inline">\(\omega_0\)</span>。</p><p>有了“1”，还要有“0”才能构成世界，那么频域的“0”是什么呢？cos（0t）就是一个周期无限长的正弦波，也就是一条直线！所以在频域，0频率也被称为直流分量，在傅里叶级数的叠加中，它仅仅影响全部波形相对于数轴整体向上或是向下而不改变波的形状。</p><p>接下来，让我们回到初中，回忆一下已经死去的八戒，啊不，已经死去的老师是怎么定义正弦波的吧。</p><p><img src="./81ca9447d6c45c162c2d76df75a6690a_1440w.jpg" /></p><p>正弦波就是一个圆周运动在一条直线上的投影。所以频域的基本单元也可以理解为一个始终在旋转的圆</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/1/1a/Fourier_series_square_wave_circles_animation.gif" /><img src="https://upload.wikimedia.org/wikipedia/commons/7/7e/Fourier_series_sawtooth_wave_circles_animation.gif" /><img src="https://upload.wikimedia.org/wikipedia/commons/b/b2/Fourier_series_triangle_wave_circles_animation.gif?20140502233558" /></p><p>介绍完了频域的基本组成单元，我们就可以看一看一个矩形波，在频域里的另一个模样了：</p><p><img src="./e2e3c0af3bdbcba721c5415a4c65da9e_1440w.jpg" /></p><p>这是什么奇怪的东西？</p><p>这就是矩形波在频域的样子，是不是完全认不出来了？教科书一般就给到这里然后留给了读者无穷的遐想，以及无穷的吐槽，其实教科书只要补一张图就足够了：频域图像，也就是俗称的频谱，就是--------</p><p><img src="./19679c871bd33d94e2fc8b174f0d14ab_1440w.jpg" /></p><p>再清楚一点：</p><p><img src="./40cf849e55ed95732a60b52d4019d609_1440w.jpg" /></p><p><img src="https://upload.wikimedia.org/wikipedia/commons/2/2b/Fourier_series_and_transform.gif" /></p><p>可以发现，在频谱中，偶数项的振幅都是0，也就对应了图中的彩色直线。振幅为0的正弦波。</p><p>老实说，在我学傅里叶变换时，维基的这个动图还没有出现，那时我就想到了这种表达方法，而且，后面还会加入维基没有表示出来的另一个谱——相位谱。</p><p>但是在讲相位谱之前，我们先回顾一下刚刚的这个例子究竟意味着什么。记得前面说过的那句“世界是静止的”吗？估计好多人对这句话都已经吐槽半天了。想象一下，世界上每一个看似混乱的表象，实际都是一条时间轴上不规则的曲线，但实际这些曲线都是由这些无穷无尽的正弦波组成。我们看似不规律的事情反而是规律的正弦波在时域上的投影，而正弦波又是一个旋转的圆在直线上的投影。那么你的脑海中会产生一个什么画面呢？</p><p>我们眼中的世界就像皮影戏的大幕布，幕布的后面有无数的齿轮，大齿轮带动小齿轮，小齿轮再带动更小的。在最外面的小齿轮上有一个小人——那就是我们自己。我们只看到这个小人毫无规律的在幕布前表演，却无法预测他下一步会去哪。而幕布后面的齿轮却永远一直那样不停的旋转，永不停歇。这样说来有些宿命论的感觉。说实话，这种对人生的描绘是我一个朋友在我们都是高中生的时候感叹的，当时想想似懂非懂，直到有一天我学到了傅里叶级数……</p><h2 id="三傅里叶级数fourier-series的相位谱">三、傅里叶级数（Fourier Series）的相位谱</h2><p>上一章的关键词是：<strong>从侧面看</strong>。这一章的关键词是：<strong>从下面看</strong>。</p><p>在这一章最开始，我想先回答很多人的一个问题：傅里叶分析究竟是干什么用的？这段相对比较枯燥，已经知道了的同学可以直接跳到下一个分割线。</p><p>先说一个最直接的用途。无论听广播还是看电视，我们一定对一个词不陌生——频道。频道频道，就是频率的通道，不同的频道就是将不同的频率作为一个通道来进行信息传输。下面大家尝试一件事：</p><p>先在纸上画一个<span class="math inline">\(\sin(x)\)</span>，不一定标准，意思差不多就行。不是很难吧。</p><p>好，接下去画一个<span class="math inline">\(\sin(3x) + \sin(5x)\)</span>的图形。</p><p>别说标准不标准了，曲线什么时候上升什么时候下降你都不一定画的对吧？</p><p>好，画不出来不要紧，我把<span class="math inline">\(\sin(3x) + \sin(5x)\)</span>的曲线给你，但是前提是你不知道这个曲线的方程式，现在需要你把<span class="math inline">\(\sin(5x)\)</span>给我从图里拿出去，看看剩下的是什么。这基本是不可能做到的。</p><p>但是在频域呢？则简单的很，无非就是几条竖线而已。</p><p>所以很多在时域看似不可能做到的数学操作，在频域相反很容易。这就是需要傅里叶变换的地方。尤其是从某条曲线中去除一些特定的频率成分，这在工程上称为滤波，是信号处理最重要的概念之一，只有在频域才能轻松的做到。</p><p>再说一个更重要，但是稍微复杂一点的用途——求解微分方程。（这段有点难度，看不懂的可以直接跳过这段）微分方程的重要性不用我过多介绍了。各行各业都用的到。但是求解微分方程却是一件相当麻烦的事情。因为除了要计算加减乘除，还要计算微分积分。而傅里叶变换则可以让微分和积分在频域中变为乘法和除法，大学数学瞬间变小学算术有没有。</p><hr /><p>通过时域到频域的变换，我们得到了一个从侧面看的频谱，但是这个频谱并没有包含时域中全部的信息。因为频谱只代表每一个对应的正弦波的振幅是多少，而没有提到相位。基础的正弦波<span class="math inline">\(A\cdot \sin(\omega t + \theta)\)</span>中，振幅，频率，相位缺一不可，不同相位决定了波的位置，所以对于频域分析，仅仅有频谱（振幅谱）是不够的，我们还需要一个相位谱。那么这个相位谱在哪呢？我们看下图，这次为了避免图片太混论，我们用7个波叠加的图。</p><p><img src="./07199fc0250791d768771b50c098e26a_1440w.jpg" /></p><p>鉴于正弦波是周期的，我们需要设定一个用来标记正弦波位置的东西。在图中就是那些小红点。小红点是距离频率轴最近的波峰，而这个波峰所处的位置离频率轴有多远呢？为了看的更清楚，我们将红色的点投影到下平面，投影点我们用粉色点来表示。当然，这些粉色的点只标注了波峰距离频率轴的距离，并不是相位。</p><p><img src="./e1985fe86283a7b14d1fc7e11d322fcb_1440w.jpg" /></p><p>这里需要纠正一个概念：时间差并不是相位差。如果将全部周期看<span class="math inline">\(2\pi\)</span>或者<span class="math inline">\(360\)</span>度的话，相位差则是时间差在一个周期中所占的比例。我们将时间差除周期再乘<span class="math inline">\(2\pi\)</span>，就得到了相位差。</p><p>在完整的立体图中，我们将投影得到的时间差依次除以所在频率的周期，就得到了最下面的相位谱。所以，频谱是从侧面看，相位谱是从下面看。</p><p>注意到，相位谱中的相位除了<span class="math inline">\(0\)</span>，就是<span class="math inline">\(\pi\)</span>。因为<span class="math inline">\(\cos(t + \pi) = -\cos(t)\)</span>，所以实际上相位为<span class="math inline">\(\pi\)</span>的波只是上下翻转了而已。对于周期方波的傅里叶级数，这样的相位谱已经是很简单的了。另外值得注意的是，由于<span class="math inline">\(\cos(t + 2\pi) = \cos(t)\)</span>，所以相位差是周期的，<span class="math inline">\(\pi\)</span>和<span class="math inline">\(3\pi\)</span>，<span class="math inline">\(5\pi\)</span>，<span class="math inline">\(7\pi\)</span>都是相同的相位。人为定义相位谱的值域为<span class="math inline">\((-\pi, \pi]\)</span>，所以图中的相位差均为<span class="math inline">\(\pi\)</span>。</p><p>最后来一张大集合：</p><p><img src="./4695ce06197677bab880cd55b6846f12_1440w.jpg" /></p><h2 id="四傅里叶变换fourier-transformation">四、傅里叶变换（Fourier Transformation)</h2><p>相信通过前面三章，大家对频域以及傅里叶级数都有了一个全新的认识。但是文章在一开始关于钢琴琴谱的例子我曾说过，这个栗子是一个公式错误，但是概念典型的例子。所谓的公式错误在哪里呢？</p><p>傅里叶级数的本质是将一个周期的信号分解成无限多分开的（离散的）正弦波，但是宇宙似乎并不是周期的。曾经在学数字信号处理的时候写过一首打油诗：</p><p><strong>往昔连续非周期</strong></p><p><strong>回忆周期不连续</strong></p><p><strong>任你ZT， DFT</strong></p><p><strong>还原不回去。</strong></p><p>（请无视我渣一样的文学水平……）</p><p>在这个世界上，有的事情一期一会，永不再来，并且时间始终不曾停息地将那些刻骨铭心的往昔连续的标记在时间点上。但是这些事情往往又成为了我们格外宝贵的回忆，在我们大脑里隔一段时间就会周期性的蹦出来一下，可惜这些回忆都是零散的片段，往往只有最幸福的回忆，而平淡的回忆则逐渐被我们忘却。因为，往昔是一个连续的非周期信号，而回忆是一个周期离散信号。</p><p>是否有一种数学工具将连续非周期信号变换为周期离散信号呢？抱歉，真没有。</p><p>比如傅里叶级数，在时域是一个周期且连续的函数，而在频域是一个非周期离散的函数。这句话比较绕嘴，实在看着费事可以干脆回忆第一章的图片。</p><p>而在我们接下去要讲的傅里叶变换，则是将一个时域非周期的连续信号，转换为一个在频域非周期的连续信号。</p><p>算了，还是上一张图方便大家理解吧：</p><p><img src="./419cd0b2e965aca25d5f8a5a6362d728_1440w.jpg" /></p><p>或者我们也可以换一个角度理解：傅里叶变换实际上是对一个周期无限大的函数进行傅里叶变换。</p><p>所以说，钢琴谱其实并非一个连续的频谱，而是很多在时间上离散的频率，但是这样的一个贴切的比喻真的是很难找出第二个来了。</p><p>因此在傅里叶变换在频域上就从离散谱变成了连续谱。那么连续谱是什么样子呢？</p><p><strong>你见过大海么？</strong></p><p>为了方便大家对比，我们这次从另一个角度来看频谱，还是傅里叶级数中用到最多的那幅图，我们从频率较高的方向看。</p><p><img src="./a185be412974fd73a7925cf1f1cc5372_1440w.jpg" /></p><p>以上是离散谱，那么连续谱是什么样子呢？</p><p>尽情的发挥你的想象，想象这些离散的正弦波离得越来越近，逐渐变得连续……</p><p>直到变得像波涛起伏的大海：</p><p><img src="./ece53f825c6de629befba3de12f929a7_1440w.jpg" /></p><p>很抱歉，为了能让这些波浪更清晰的看到，我没有选用正确的计算参数，而是选择了一些让图片更美观的参数，不然这图看起来就像屎一样了。</p><p>不过通过这样两幅图去比较，大家应该可以理解如何从离散谱变成了连续谱的了吧？原来离散谱的叠加，变成了连续谱的累积。所以在计算上也从求和符号变成了积分符号。</p><p>不过，这个故事还没有讲完，接下去，我保证让你看到一幅比上图更美丽壮观的图片，但是这里需要介绍到一个数学工具才能然故事继续，这个工具就是----------</p><h2 id="五宇宙耍帅第一公式欧拉公式">五、宇宙耍帅第一公式：欧拉公式</h2><p>虚数i这个概念大家在高中就接触过，但那时我们只知道它是-1的平方根，可是它真正的意义是什么呢?</p><p><img src="./42e1f6dc43e8868b4962f5ba389a5df4_1440w.jpg" /></p><p>这里有一条数轴，在数轴上有一个红色的线段，它的长度是1。当它乘以3的时候，它的长度发生了变化，变成了蓝色的线段，而当它乘以-1的时候，就变成了绿色的线段，或者说线段在数轴上围绕原点旋转了180度。</p><p>我们知道乘-1其实就是乘了两次 i使线段旋转了180度，那么乘一次 <span class="math inline">\(i\)</span> 呢——答案很简单——旋转了90度。</p><p><img src="./3e88e9463e4667e50ebdda51dee88358_1440w.jpg" /></p><p>同时，我们获得了一个垂直的虚数轴。实数轴与虚数轴共同构成了一个复数的平面，也称复平面。这样我们就了解到，乘虚数i的一个功能——旋转。</p><p>现在，就有请宇宙第一耍帅公式欧拉公式隆重登场--------- <span class="math display">\[e^{ix} = \cos x + i \sin x\]</span> 这个公式在数学领域的意义要远大于傅里叶分析，但是称它为宇宙第一耍帅公式是因为它的特殊形式——当<span class="math inline">\(x\)</span>等于<span class="math inline">\(\pi\)</span>的时候。 <span class="math display">\[e^{i\pi}+1 = 0\]</span> 经常有理工科的学生为了跟妹子表现自己的学术功底，用这个公式来给妹子解释数学之美：”石榴姐你看，这个公式里既有自然底数<span class="math inline">\(e\)</span>，自然数<span class="math inline">\(1\)</span>和<span class="math inline">\(0\)</span>，虚数<span class="math inline">\(i\)</span>还有圆周率<span class="math inline">\(\pi\)</span>，它是这么简洁，这么美丽啊！“但是姑娘们心里往往只有一句话：”臭屌丝……“</p><p>这个公式关键的作用，是将正弦波统一成了简单的指数形式。我们来看看图像上的涵义：</p><p><img src="./974efc6a99e06dcd623193e960ccbe93_1440w.jpg" /></p><p>欧拉公式所描绘的，是一个随着时间变化，在复平面上做圆周运动的点，随着时间的改变，在时间轴上就成了一条螺旋线。如果只看它的实数部分，也就是螺旋线在左侧的投影，就是一个最基础的余弦函数。而右侧的投影则是一个正弦函数。</p><p>这里不需要讲的太复杂，足够让大家理解后面的内容就可以了。</p><h2 id="六指数形式的傅里叶变换">六、指数形式的傅里叶变换</h2><p>有了欧拉公式的帮助，我们便知道：<strong>正弦波的叠加</strong>，也可以理解为<strong>螺旋线的叠加</strong>在实数空间的投影。而螺旋线的叠加如果用一个形象的栗子来理解是什么呢？</p><p><strong>光波</strong></p><p>高中时我们就学过，自然光是由不同颜色的光叠加而成的，而最著名的实验就是牛顿师傅的三棱镜实验：</p><p><img src="./c2d7bfc819ebcbea8d6f2c8271d4791d_1440w.jpg" /></p><p>所以其实我们在很早就接触到了光的频谱，只是并没有了解频谱更重要的意义。</p><p>但不同的是，傅里叶变换出来的频谱不仅仅是可见光这样频率范围有限的叠加，而是频率从0到无穷所有频率的组合。</p><p>这里，我们可以用两种方法来理解正弦波：</p><p>第一种前面已经讲过了，就是螺旋线在实轴的投影。</p><p>另一种需要借助欧拉公式的另一种形式去理解： <span class="math display">\[e^{it} = \cos(t) + i\cdot \sin(t)\\e^{-it} = \cos(t) - i\cdot \sin(t)\]</span> 将以上两式相加再除2，得到： <span class="math display">\[\cos(t) = \frac{e^{it} + e^{-it}}{2}\]</span> 这个式子可以怎么理解呢？</p><p>我们刚才讲过，<span class="math inline">\(e^{it}\)</span>可以理解为一条逆时针旋转的螺旋线，那么<span class="math inline">\(e^{-it}\)</span>则可以理解为一条顺时针旋转的螺旋线。而cos(t)则是这两条旋转方向不同的螺旋线叠加的一半，因为这两条螺旋线的虚数部分相互抵消掉了！</p><p>举个例子的话，就是极化方向不同的两束光波，磁场抵消，电场加倍。</p><p>这里，逆时针旋转的我们称为正频率，而顺时针旋转的我们称为负频率（注意不是复频率）。</p><p>好了，刚才我们已经看到了大海——连续的傅里叶变换频谱，现在想一想，连续的螺旋线会是什么样子：</p><p>想象一下再往下翻：</p><div class="line-block"></div><div class="line-block"></div><div class="line-block"></div><div class="line-block"></div><div class="line-block"></div><div class="line-block"></div><div class="line-block"></div><div class="line-block"></div><div class="line-block"></div><div class="line-block"></div><div class="line-block"></div><div class="line-block"></div><div class="line-block"></div><div class="line-block"></div><div class="line-block"></div><p><img src="./f116ae26859bdc80b28ea0f8f894ccc0_1440w.jpg" /></p><p>是不是很漂亮？</p><p>你猜猜，这个图形在时域是什么样子？</p><p><img src="./0fdfa0a9b6eea036703ab2499381080c_1440w.jpg" /></p><p>哈哈，是不是觉得被狠狠扇了一个耳光。数学就是这么一个把简单的问题搞得很复杂的东西。</p><p>顺便说一句，那个像大海螺一样的图，为了方便观看，我仅仅展示了其中正频率的部分，负频率的部分没有显示出来。</p><p>如果你认真去看，海螺图上的每一条螺旋线都是可以清楚的看到的，每一条螺旋线都有着不同的振幅（旋转半径），频率（旋转周期）以及相位。而将所有螺旋线连成平面，就是这幅海螺图了。</p><p>好了，讲到这里，相信大家对傅里叶变换以及傅里叶级数都有了一个形象的理解了，我们最后用一张图来总结一下:<img src="./097c9051af221c171730d4bc8f436a72_1440w.jpg" /></p><hr /><p>https://zhuanlan.zhihu.com/p/19763358</p>]]></content>
    
    
    
    <tags>
      
      <tag>数学</tag>
      
      <tag>傅立叶</tag>
      
      <tag>傅立叶分析</tag>
      
      <tag>傅立叶级数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>用最大熵搞懂Softmax</title>
    <link href="/2022/02/19/softmax/"/>
    <url>/2022/02/19/softmax/</url>
    
    <content type="html"><![CDATA[<p>先前我们学习到的sigmoid函数它可以用来解决单一分类问题， 因为sigmoid函数本质上就是把感知机的输出投影到一个区间在<span class="math inline">\([0,1 ]\)</span>的概率分布中， 但问题是如果我们的分类有多个那么就不能使用sigmoid了， 因为我们虽然可以把每个感知机输出的结果归一但我们无法把整层所以感知机的输出做归一化。这里我们就要引出softmax函数了， 那么它是证明计算的呢？</p><h3 id="什么是softmax">什么是softmax</h3><p><img src="./Screen%20Shot%202022-03-07%20at%205.27.34%20pm.jpg" /></p><p>这里可以看到， <span class="math inline">\(y^{(k)}\)</span> 表示的是输入的<span class="math inline">\(k\)</span>个类别每个类别用一个向量表示。<span class="math inline">\(a^{[l](k)}\)</span>表示的是<span class="math inline">\(l\)</span>层最后输出的结果，这里是一个概率分布， 我们要求每一个值是一个概率并且概率总和要等于1. <span class="math inline">\(z^{[l](k)}\)</span>表示的是<span class="math inline">\(l\)</span>层感知机的输出， 在设计softmax函数的的时候我么首先需要考虑的是把每一个输出值转换为一个大于等于0的数， 因此我们引入<span class="math inline">\(e\)</span>将输出作为<span class="math inline">\(e\)</span>的指数， 由于<span class="math inline">\(e^{[l](k)}\)</span>的值域是大于0的，虽然少了等于零的情况但在这里并不重要。 接着我们需要把所有结果归一化， 因此就可以把所有值求和将每个值作为分子，这样最终<span class="math inline">\(l\)</span>层的输出结果就归一了。由于激活函数改变了那么损失函数也需要做相应的变换。<img src="./Screen%20Shot%202022-03-07%20at%205.42.01%20pm.jpg" /></p><p>这里的<span class="math inline">\(p_i^{(k)}\)</span>就是我们计算出来的概率， <span class="math inline">\(q_i^{(k)}\)</span> 是标签里的那个值， 我们需要对每一个概率都做一次交叉熵的计算， 然后再对所有的值做一次求和作为我们最后的损失值。</p><p>我们都说其实softmax就是一个放大sigmoid那就是为什么呢？我们从sigmoid的函数来看看 <span class="math display">\[sigmoid(z^{[l](k)}) = \frac{1}{1 + e^{-z^{[l](k)}}} = \frac{e^{z^{[l](k)}}}{e^{z^{[l](k)}} + 1}\]</span> 我们将sigmoid函数变换了一下他是不是久很像softmax了呢， 如果我们令 <span class="math display">\[\begin{bmatrix} t_1\\ t_2\end{bmatrix} = \begin{bmatrix} e^{z^{[l](k)}}\\ e^0\end{bmatrix} = \begin{bmatrix} e^{z^{[l](k)}}\\ 1\end{bmatrix}\]</span></p><p><span class="math display">\[sigmoid(z^{[l](k)}) = \frac{t_1}{t_1+t_2} \, ;\, 1-sigmoid(z^{[l](k)}) = \frac{1}{t_1+t_2} = \frac{t_2}{t_1+t_2}\]</span></p><p>那么他和有2个分类的softmax没有什么区别了， 可能从结果来看他两并没有太大区别， 但是本质上他们是有很大区别的。 如果我们说sigmoid的分类一个是是猫的类别一个是不是猫的类别，那么softmax的结果表示的就是一个是猫的类别一个是狗的类别。</p><hr /><p>对于softmax我们本质上就是需要寻求一个归一化函数但归一化函数有那么多为什么softmax就选择了以<span class="math inline">\(e\)</span>为底的这种形式呢， 这其实就和最大熵有关了。 我们说神经网络是可以用来逼近任意一个概率模型即使这个概率模型我们写不出来也能逼近， 我们是使得似然值最大或者交叉熵最小。其实我们使用这种方法的默认前提是我们认为似然值最大的那个概率模型最接近我们想要的那个概率模型，而当我们使用了sigmoid, softmax函数时其实我们还默任其满足了另外一个条件就是最大熵原理。</p><h3 id="矩">矩</h3><p>首先这里，我们用一个最简单的高斯分布来举例子。 为了确定一个高斯分布，我们只需要确定他的期望和方差就能够确定一个数据分布。 我们的希望是对于任何一个概率分布都能用类似的方法，准确地表示出来。首先我们来看一下，期望和方差是如何表示的：</p><p><img src="./Screen%20Shot%202022-03-07%20at%207.31.53%20pm.jpg" /></p><p>首先这里的<span class="math inline">\(\mu\)</span> 表示的是对于概率分布<span class="math inline">\(P(x)\)</span>的期望， <span class="math inline">\(\sigma^2\)</span> 表示的是概率分布的方差。 如果我们将方差展开就能发现他是数据平方的期望减去期望的平方<span class="math inline">\(E[x^2] - \mu^2\)</span> 。 我们会发现在期望和方差中出现了<span class="math inline">\(E[x]\)</span>和<span class="math inline">\(E[x^2]\)</span>。 所以数学家们就想对于更复杂的概率分布我们是否也可以用含有类似的形式表达出来。 于是，他们就引入了一个新的概念叫偏度，他是统计数据分布倾斜方向和程度的度量。 如果我们将它展开，就能发现他确实也有类似的形式。 数学家们把<span class="math inline">\(E[x]\)</span>称之为一阶矩， <span class="math inline">\(E[x^2]\)</span>称之为二阶矩。 到此我们就可以思考是否可以使用不同的矩组成的向量来表示一个概率分布的特征， 事实上，数学家们已经证明了，是可以的，具体的证明就需要去发数学教材了这里就不过多证明了， 接下来我只是把他的正确性呈现一下。<img src="./Screen%20Shot%202022-03-07%20at%207.44.19%20pm.jpg" /></p><p>这里定义了一个特征函数<span class="math inline">\(\varphi_X(t)\)</span> , 我们把一个复数<span class="math inline">\(e^{itx}\)</span>放进概率分布求期望。 任何一个概率分布都可以有一个特征函数表示，也就是说任何一个概率分布都有一个特征函数与其一一对应。 对于一个特征函数，我们只要对其进行泰勒展开就能变成上面的形式，到这里我们就非常熟悉了。 特征函数展开后就含有我们所说的一阶矩， 二阶矩等等， 而且我们可以看出特征函数展开后和我们的矩组成的向量其实是线性关系。 因此，对于两个不一样的概率分布我们只需要去比较它们的矩向量，并不需要计算准确的概率分布也能比较它们之间的差距。 到这里，其实我们还有一个小疑问就是数学家们是如何确定一个概率分布有且唯一有一个特征函数与其一对应的呢？ 我们只需要把特征函数展开，然后对其概率密度函数做傅立叶变换就可以发现他的傅立叶变换和特征函数是共轭的， 他们是一个一一对应的关系。 而傅立叶变换就可以和概率分布做一一对应， 于是一个概率分布就可以和一个特征函数做一一对应。 因此假设我们有一个函数<span class="math inline">\(f(x)\)</span>， 我们只需要把它丢到两个概率分布模型中去求期望， 然后比较两个期望是否相等，就可以比较两个模型是否相等了。</p><p><img src="./Screen Shot 2022-03-08 at 4.32.49 pm.jpg" alt="Screen Shot 2022-03-08 at 4.32.49 pm" style="zoom:50%;" /></p><p>当我们了解什么是矩之后，我们就可以拿去和交叉熵作比较了。对于两个形式类似的模型，我们可以用矩来精确的定量比较两个概率模型是否相等，但是如果两个概率模型的形式都差别非常大的话， 使用矩就很难比较两个模型的差别，那我们就可以使用交叉熵来衡量模型之间的差距了。</p><h3 id="经验概率">经验概率</h3><p>那么接下来我们看看如何把我们前面所学到的东西运用在真正的数据里，我们先举一个非常简单的例子。</p><p><img src="./Screen%20Shot%202022-03-08%20at%205.05.52%20pm.jpg" /></p><p>我们先引入一个新的概念也就是这里的<span class="math inline">\(\tilde{p}\)</span> 他叫作经验概率。 也就是我们从数据中可以直接总结出来的概率。 那他究竟是如何计算出来的呢，我们可以看到下面的<span class="math inline">\(\tilde{p}_1, \tilde{p}_2, \tilde{p}_3\)</span> 分别都是数据中不同的条件组合的数量除以数据集的总数计算出来的概率，我们把所有的组合的概率计算之后做一个结合，就是这里的经验概率。 当然这是一个结构型的数据，当我们放到神经网络中以图片为数据的话，又是怎么做的呢？</p><p><img src="./Screen%20Shot%202022-03-08%20at%205.14.10%20pm.jpg" /></p><p>这里的<span class="math inline">\(x, y\)</span> 分别是样本和标签， 也就是图片啦，当然这里的<span class="math inline">\(x, y\)</span> 都是向量。 我们计算每个样本的每个像素的经验分布。 但是，这里就会有个疑问，样本中不可能有两张完全一模一样的图片，那么这样的话这里就很出来的经验概率永远都是<span class="math inline">\(\frac{1}{N}\)</span>， 那不就没有任何意义了吗？ 当然，这是我们从输入层来看是对每一个像素求经验分概率， 但是随着网络的加深感知机的数量越来越少，那每一个感知机就会关注不同的特征，那经验概率的意义就体现出来了。 当我们在隐藏层中再做经验概率时， <span class="math inline">\(\tilde{p}(x, y) = \frac{count(\cdots x_j, \cdots y_i)}{N}\)</span>我们得到了可能就不是简简单单的<span class="math inline">\(\frac{1}{N}\)</span>。当然我们也可以不考虑<span class="math inline">\(y\)</span>求<span class="math inline">\(\tilde{p}(x) = \frac{count(\cdots x_j, \cdots y_i)}{N}\)</span> 。我们的目标是求<span class="math inline">\(P(y\,|\,x)\)</span>， 其中包含了一部分已知的信息，一部分未知的信息，已知的信息要求完全相等，未知的信息我们使用最大熵。</p><p><img src="./Screen Shot 2022-03-08 at 6.01.05 pm.jpg" alt="Screen Shot 2022-03-08 at 6.01.05 pm" style="zoom:50%;" /></p><p>这里我们使用贝叶斯公式将其展开， 然后我们就可以发现我们可以使用前面求到的经验概率<span class="math inline">\(\tilde{p}(x, y), \tilde{p}(x)\)</span>去替换<span class="math inline">\(p(x, y), p(x)\)</span>。 那这一部分就是我们已知的信息， 而另一部分未知的信息，我们就使他熵最大。 其实上面两种方法都可以，但是为了之后的求导更方便我们使用第一种。</p><p>在这之前我们希望两个模型求出来的期望相等，但是我们只知道经验概率是没办法求期望的， 一个函数的期望是随机变量乘以概率再相加，因此我们还需要设计一个随机变量。 我先把随机变量是怎么设计的写出来，我们再来看为什么这么设计。</p><p><img src="./Screen Shot 2022-03-08 at 6.09.10 pm.jpg" alt="Screen Shot 2022-03-08 at 6.09.10 pm" style="zoom:50%;" /></p><p>这里设计了一个随机变量<span class="math inline">\(X\)</span>，当样本空间中的样本满足事件<span class="math inline">\(A\)</span>就等于1如果不满足事件<span class="math inline">\(A\)</span>就等于0。 那为什么这么设计呢，我们来看对随机变量<span class="math inline">\(X\)</span>求期望，我们会发现对随机变量<span class="math inline">\(X\)</span>求得的期望其实就是<span class="math inline">\(\tilde{p}(A)\)</span>，就是满足<span class="math inline">\(A\)</span>的概率本身。 因此对于更多的样本和更多的事件，我们其实不需要去求两个模型的期望。 我们只需要把每一个样本在每个事件中的概率求出来然后进行对比就可以了。 而且，由于这里的随机变量的设计他满足伯努利分布， 而伯努利分布是一个比正态分布更简单的分布，因此这里的函数分量只需要求一阶矩就够了。</p><p><img src="./Screen Shot 2022-03-08 at 6.20.10 pm.jpg" alt="Screen Shot 2022-03-08 at 6.20.10 pm" style="zoom:50%;" /></p><h3 id="条件熵">条件熵</h3><p>前面那个问题搞定之后我们就要来求最大熵了，但是在求最大熵之前，我们遇到另外一个问题就是之前我们求交熵的时候用的都是一般的概率分布， 而我们现在使用的是条件概率分布在熵的方面还是一样的计算方法吗？ 我们先来看一下熵的定义： <span class="math display">\[H(x):=-\sum_{i=1}^n P(X)\cdot \log P(X)\]</span> 那对于条件熵来说，我们是否也可以直接将条件概率分布带入呢？ <span class="math display">\[H(x):=-\sum_{i=1}^n P(Y\, |\, X)\cdot \log P(Y\, |\, X)\]</span> 对于只有一个事件的情况下，我们当然可以怎么做，但是如果有多个事件的话情况就不一样了。 对于每个事件我们都会得到一个不一样的熵。 那我们怎么做一个统一化呢，最简单的想到就是求期望，我们把每一个事件的熵乘以概率再求和就能得到我们想要的条件熵。这里我们把条件熵定义为： <span class="math display">\[H(Y\, |X):=-\sum_{x, y} P(x) P(y \, |\, x)\log (y \, |\, x) = E(H(Y \, |\, X = x^{(k)}))\]</span></p><h2 id="最大化条件熵">最大化条件熵</h2><p>接下来我们需要做的就是最大化条件熵，怎么对<span class="math inline">\(p, x, y\)</span> 取值才能最大化熵。在揭示的过程中我们就真知道为什么都说sigmoid和softmax的本质是最大熵了。首先我们改变一下求熵最大的形式变成求最小， 实际上我们不仅仅是求最小这么简单还需要满足两个条件。</p><p><img src="./Screen Shot 2022-03-08 at 7.05.28 pm.jpg" alt="Screen Shot 2022-03-08 at 7.05.28 pm" style="zoom:50%;" /></p><p>第一个是我们希望从样本空间中得到的经验概率分布的期望和真实的概率分布期望相等。 第二个条件，实际上是满足整个样本空间所有概率的归一。 因为经验概率分布的期望是个常数所以这里直接用<span class="math inline">\(\Delta_k\)</span> 代替。 对于求它的最小值并且满足两个约束条件，我们就会用到高数上非常熟悉的拉格朗日乘数法，我们引入一个变量<span class="math inline">\(\lambda\)</span> 接着就可以把式子改写成这样。 <img src="./Screen Shot 2022-03-08 at 7.10.52 pm.jpg" alt="Screen Shot 2022-03-08 at 7.10.52 pm" style="zoom:50%;" /></p><p>这里需要大家对拉格朗日乘数法有基本的了解（不了解的谷歌去）。 接着我们对拉格朗日函数进行展开， 其实就是对后面的函数的期望展开然后用贝叶斯公式展开就可以获得上面的式子。 接着我们就考虑拉格朗日对偶问题。我们将<span class="math inline">\(P\)</span>作为常数，先求<span class="math inline">\(\lambda\)</span>作为参数的最大值接着把<span class="math inline">\(P\)</span>作为常数，<span class="math inline">\(\lambda\)</span>作为常数求最小值等价于他的对偶问题。<img src="./Screen Shot 2022-03-08 at 7.16.23 pm.jpg" alt="Screen Shot 2022-03-08 at 7.16.23 pm" style="zoom:50%;" /></p><p>接着对于求拉格朗日对偶问题的最小值我们就很熟悉了，就是使他的偏导等于零那么拉格朗日函数就能取到最小值。 我们对<span class="math inline">\(L(P,\lambda)\)</span>求关于<span class="math inline">\(P\)</span>的偏导就是上面这样。通过观察我们可以发现每一项都有一个<span class="math inline">\(\tilde{p}(x)\)</span>并且<span class="math inline">\(\sum_x \tilde{p}(x) = 1\)</span>所以我么可以将所有的<span class="math inline">\(\sum_x \tilde{p}(x)\)</span>提出来。然后使它等于0就可以使它的熵大了。<img src="./Screen Shot 2022-03-08 at 7.21.05 pm.jpg" alt="Screen Shot 2022-03-08 at 7.21.05 pm" style="zoom:67%;" /></p><p>对于上式我们可以看出使得<span class="math inline">\(\frac{\partial L(P, \lambda)}{\partial P(y|x)} = 0\)</span> 显然就是使得括号中的部分等于0就可以。因此我们对它进行一个变化就可以得到<span class="math inline">\(P(y\, |\, x)\)</span>的函数形式。 到这里我们应该就感觉到熟悉了</p><p><img src="./Screen Shot 2022-03-08 at 7.26.31 pm.jpg" alt="Screen Shot 2022-03-08 at 7.26.31 pm" style="zoom:50%;" /></p><p>我们接着对他进行化简，对于前面<span class="math inline">\(e\)</span>的部分我们只需要在指数加个负号就可让他变成分母，对于分子的<span class="math inline">\(e\)</span>的指数如果我们把它用向量的形式表示就可以变成 <span class="math inline">\(\eta\)</span>是一个关于<span class="math inline">\(\lambda\)</span>的向量。 那么关于分母的部分，我们别忘了我们是为什么引入<span class="math inline">\(\lambda_0\)</span>， 我们的目的是加入概率归一这个约束条件。那么对于<span class="math inline">\(P(y\,|\,x)\)</span>这个条件概率我们只需要让他的分母为所有分子的合就可以了。到这里我们就非常熟悉了。</p><p><img src="./Screen%20Shot%202022-03-08%20at%207.35.11%20pm.jpg" /></p><p>我们只要把它放到神经网络，你去看一看就明白为什么了， 我们把它的分子当作<span class="math inline">\(t\)</span>的话，这不就是softmax函数吗。softmax是怎么得出来的其实就是在求最大熵的时候得出来的，而这里的<span class="math inline">\(e\)</span>也没有我们原来想的那么简单，他其实是在考虑熵的时候引入的。所以当我们使用了softmax或者sigmoid函数是其实就默认选择了最大熵的方式进行机器学习了。</p><p><strong>References</strong></p><p>https://www.bilibili.com/video/BV1cP4y1t7cP?spm_id_from=333.999.0.0</p><p>https://zhuanlan.zhihu.com/p/19763358</p><p>https://zhuanlan.zhihu.com/p/23739221</p><hr /><p><strong><em>知识来源作者为b站UP主王木头学科学</em></strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>人工智能</tag>
      
      <tag>数学</tag>
      
      <tag>最大熵</tag>
      
      <tag>条件熵</tag>
      
      <tag>机器学习</tag>
      
      <tag>softmax</tag>
      
      <tag>矩</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何理解“梯度下降法”？什么是“反向传播”？</title>
    <link href="/2022/02/16/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    <url>/2022/02/16/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/</url>
    
    <content type="html"><![CDATA[<p>本章要解决的问题：</p><ol type="1"><li>梯度到底是什么</li><li>梯度如何被利用到神经网络中去训练神经网络的</li></ol><h3 id="什么是反向传播">什么是反向传播</h3><p>反向传播嘛顾名思义就是把信息反方向的传播的一种方式。在这之前我们先来看什么是正向传播， 神经网络中正向传播其实就是把信息输入神经网络， 信息通过一个一个感知机计算最后输出一个结果，说是感知器实际上就是感知机中的<span class="math inline">\(W,\,b\)</span>对结果产生的影响。而每个<span class="math inline">\(W,\,b\)</span>对结果产生的影响的大小就要看他们具体的数值了有的对结果影响大有的对结果影响小。</p><p>反向传播其实和正向传播是一样的，当一个神经网络没有训练好时它的结果是又偏差的，而这个偏差也是依赖于感知机中的<span class="math inline">\(W,\,b\)</span>的数值。相对于正向传播，反向传播不只是当当反向反了而已，反的还有它的传递的信息。它传递的是偏差的信息，将这些偏差传递到一个个参数上，最后根据每个参数对偏差做出的贡献大小相应的进行修改。</p><h3 id="反向传播是如何修改参数的">反向传播是如何修改参数的</h3><p>首先我们先用一个最符合直觉方法来理解一下反向传播究竟是怎么传播的，但先打个预防针，这个方法它并不正确只是可以方便我们的理解。</p><p><img src="./Screen%20Shot%202022-02-16%20at%206.42.40%20pm.jpg" /></p><p>首先这里的<span class="math inline">\(a^{[3]}\)</span>就是最后一层感知机输出的结果， <span class="math inline">\(\sigma\)</span>就是激活函数啦。<span class="math inline">\(W^{[3]},\,b^{[3]}\)</span>分别是最后一个感知机的权重和偏置，而<span class="math inline">\(a^{[2]}\)</span>是上一层隐藏层输出的结果。 这里我们使用交叉熵来计算损失值<span class="math inline">\(J\)</span>。</p><p><img src="./Screen%20Shot%202022-02-16%20at%206.47.32%20pm.jpg" /></p><p>这里我们假设损失值就是个大饼，我们可以通过分配这个大饼的方式去按贡献大小分配个每个参数。在这一层中我们就可以分配个<span class="math inline">\(W^{[3]},\,b^{[3]}\)</span>然后进行修改，但是我们并不能直接修改<span class="math inline">\(a^{[2]}\)</span>所以我们就需要将这部分反向传播给上一层。</p><p><img src="./Screen%20Shot%202022-02-16%20at%206.52.42%20pm.jpg" /></p><p>当然不是平均分配给每个感知机，而是需要根据每个感知机贡献的多少来进行分配，而每个感知机的参数如何调整又需要根据每个感知机的具体情况进行细分。然后我们对每个<span class="math inline">\(W^{[2]},\,b^{[2]}\)</span>再进行调整，但它需要承担的偏差也并不是由他自己决定的还需要继续向前传播。</p><p><img src="./Screen%20Shot%202022-02-16%20at%206.55.14%20pm.jpg" /></p><p>而前一层的感知机所需要承担的偏差是由后面所有感知机共同决定的，这里应该是需要一个算法来决定每个感知机究竟要分配多少偏差。到目前为止我们用了一个不正常但很符合直觉的办法理解反向传播是如何分配偏差的。但这种符合直觉的方法实际上在真正数值计算上并没有那么容易，那还有别的方法吗？当然有！我们前面用这种想切西瓜的方法来进行偏差的分配其实是数值的加法，那我们是否可以考虑使用向量来解决呢？使用向量的话我们就需要考虑到它不止有数值还有反向了，这就要引出梯度这个概念。</p><p>其实准确来说应该是梯度的反方向。因为按照定义梯度是指向数值增加最快的方向，而反方向就是数值减少最快的方向。</p><h3 id="什么是梯度">什么是梯度</h3><p><span class="math display">\[梯度 = \nabla f(x,\,y)\]</span></p><p>这个其实就是在求<span class="math inline">\(f(x,\,y)\)</span>这个函数的梯度。我们来看下面这张图，红色的曲面其实就是<span class="math inline">\(f(x,\, y)\)</span>这个函数，可以看到我们可以选定曲线上任意一个点过这个点做切面，在这个切面上有无数个切线而最特殊的就是图中的黑线他表示在这条切线上函数的数值变化最快并且他与梯度密切相关。在左图中的这个向量就是梯度，他其实就是这条黑线在平面上的投影。梯度指向的方向就是函数在这个点上数值增加最快的方向，并且梯度永远都和等高线垂直。</p><p><img src="./Screen%20Shot%202022-02-16%20at%207.13.22%20pm.jpg" /></p><p>我们现在选定一个点然后看到我们可沿着这个点做出它点梯度，因为他是个向量所以我们可以在平面中沿着坐标轴做出梯度的分量。我们假设<span class="math inline">\(x\)</span>轴和<span class="math inline">\(y\)</span>轴的单位向量分别是<span class="math inline">\(i,\,j\)</span>当我们知道了单位向量后其实我们就可以把梯度的这两个分量表达出来。<span class="math inline">\(α,\,β\)</span>分别是分量的系数，我们把分量表示出来了就可以很轻松的写出梯度的表达式了。</p><p><img src="./Screen%20Shot%202022-02-16%20at%207.25.01%20pm.jpg" /></p><p>到这里我们实际上就是把梯度进行了分解，那么梯度他有个非常重要的意义就是它始终指向函数数值变化最快的方向。那么如果我们确定了一个点后我们想要沿着梯度的方向也就是数值变化最快的方向变化那也就变得非常简单了。</p><p><img src="./Screen%20Shot%202022-02-16%20at%207.32.18%20pm.jpg" /></p><p>我们只需要把原来的<span class="math inline">\(x\)</span>加上一个<span class="math inline">\(\alpha\)</span>倍数，在原来的<span class="math inline">\(y\)</span>上加一个<span class="math inline">\(\beta\)</span>的倍数，而这个倍数<span class="math inline">\(\eta\)</span>是相等的，所以就相当于梯度在<span class="math inline">\(x,\,y\)</span>上的分量同时放大或缩小最后的方向是不变的。</p><h3 id="如何在神经网络中使用梯度">如何在神经网络中使用梯度</h3><p>但我们已经理解了什么事梯度后我们其实就可以把原本的损失函数<span class="math inline">\(J\)</span>看成是前面的函数<span class="math inline">\(f\)</span></p><p><img src="./Screen%20Shot%202022-02-16%20at%207.39.39%20pm.jpg" /></p><p>那么损失函数的梯度其实就是代表它增大最快的那个方向，那如果取反就是损失值减小最快的那个方向了。</p><hr /><p><strong><em>以下数学不严谨，只可意会</em></strong></p><hr /><p><img src="./Screen%20Shot%202022-02-16%20at%207.46.02%20pm.jpg" /></p><p>首先这里的<span class="math inline">\(\nabla J\)</span>就是损失函数的梯度啦，<span class="math inline">\(α, \,β, \, \gamma\)</span> 分别是梯度在三个分量上的系数。那么根据前面讲的如果我们需要沿着梯度的反方向改变值的话我们就需要在原来的值基础上减去<span class="math inline">\(\eta\)</span>倍的原来的系数。那么在这一层我们就可以直接对权重和偏执进行更新，但是我们并不能直接修改<span class="math inline">\(a^{[2]}\)</span>，我们需要继续进行方向传播。那既然如此我们不如对它进行一下位置的调换</p><p><img src="./Screen%20Shot%202022-02-16%20at%207.53.22%20pm.jpg" /></p><p>我们就会发现<span class="math inline">\(β\)</span>其实就是目前的<span class="math inline">\(a^{[2]}\)</span>和我们期望的<span class="math inline">\(a^{[2]}\)</span>之间的差值，而我们舍去<span class="math inline">\(\eta\)</span>因为在之后我们继续进行反向传播它还会分配给之后的权重和偏置，所以我们不要在这里乘上这个倍数，因此我们先将他舍去以方便后续的计算。</p><p>到这里我们可以发现这里其实和损失函数有着异曲同工之妙。损失函数是表示我们期望的结果和目前的结果的差值，而这里也是表示上一层隐藏层输出的结果和我们期望的结果的差值。因此我们可以把它假设成一个<strong>“损失函数”</strong>，这里并非是真的损失函数但我们可以假设他是然后用同样的计算进行后续的操作。</p><p>上述的<span class="math inline">\(α, \,β, \, \gamma\)</span> 并不严谨，实际上他们都是以向量的方式表达的，具体数学在这里就不细分析了，以下给出简要的表达式（不会的回去补高数！！） <span class="math display">\[\nabla f(x, y) \hspace{20mm}\\=(\frac{\partial f}{\partial x},\, \frac{\partial f}{\partial y}) \hspace{10mm}\\=\frac{\partial f}{\partial x} \cdot i + \frac{\partial y}{\partial y}\cdot j\]</span> 这样我们就能使用偏导来代替前面的<span class="math inline">\(α, \,β, \, \gamma\)</span> 了 <span class="math display">\[\alpha = \frac{\partial J}{\partial W^{[3]}} \\\gamma = \frac{\partial J}{\partial b^{[3]}} \hspace{2mm}\\\beta = \frac{\partial J}{\partial a^{[2]}} \hspace{1mm}\]</span> 接下来我们就可以直接替换原本的<span class="math inline">\(α, \,β, \, \gamma\)</span> 用偏导代替，但在下一层中的差值就不是由当当一个感知机决定了我们就前面所有的值求平均。</p><p><img src="./Screen%20Shot%202022-02-17%20at%204.16.58%20pm.jpg" /></p><h3 id="梯度下降法的严谨数学表达">梯度下降法的严谨数学表达</h3><p><img src="./Screen%20Shot%202022-02-17%20at%204.30.36%20pm.jpg" /></p><p>接下来我们就用相对严谨的数学进一步的理解梯度下降法中数据是如何反向传递的。首先我们单独拎一个感知机出来看，图中的<span class="math inline">\(a^{[l-1]}\)</span> 表示的是上一层的输出结果<span class="math inline">\(l\)</span>表示第<span class="math inline">\(l\)</span>层，这里的<span class="math inline">\(a^{[l-1]}\)</span>其实是一个矩阵，矩阵的每一个值表示的是上一层每一个感知机的输出结果。<span class="math inline">\(W_i^{[l]}\)</span>表示的是<span class="math inline">\(l\)</span>层的所有权重每个权重都是一个向量。 <span class="math inline">\(b_i^{[l]}\)</span>表示的是<span class="math inline">\(l\)</span>层的偏置。我们把上一层的所有结果乘以权重矩阵的转置加上偏置就是我们的结果<span class="math inline">\(z_i^{[l]}\)</span>，但感知机的输出结果还需要通过激活函数<span class="math inline">\(\sigma\)</span>输出结果<span class="math inline">\(a_i^{[l]}\)</span>。虽然这样的表达已经很简洁了但是，如果我们需要一一个感知机的这么写还是很复杂。</p><p><img src="./Screen%20Shot%202022-02-17%20at%204.49.28%20pm.jpg" /></p><p>其实我们可以直接按整层的来开这了的<span class="math inline">\(z^{[l]}\)</span>是个矩阵代表的是<span class="math inline">\(l\)</span>层所有的输出。权重矩阵每一行表示的是当层每一个感知机的权重，每一列其实可以看成是上一层的每一个感知机的权重。<span class="math inline">\(a^{[l-1]}\)</span>表示的是上一层的所有输出结果，<span class="math inline">\(b^{[l]}\)</span>表示的是<span class="math inline">\(l\)</span>层的所有偏置。 就此我们隐藏式层算是介绍完了。接下来我们就要关注一下输出层了。</p><figure><img src="./Screen%20Shot%202022-02-17%20at%204.57.50%20pm.jpg" alt="Screen Shot 2022-02-17 at 4.57.50 pm" /><figcaption aria-hidden="true">Screen Shot 2022-02-17 at 4.57.50 pm</figcaption></figure><p>我们知道在输出层我们需要使用损失函数<span class="math inline">\(J\)</span>来计算神经网络的输出和我们的期望的差值。这里<span class="math inline">\(a^{[l](k)}\)</span>就是神经网络输出层输出的<span class="math inline">\(k\)</span>个结果，<span class="math inline">\(y^{(k)}\)</span> 其实就是我们训练数据打的标签，对于每个<span class="math inline">\(x^[(k)]\)</span>都是人工识别标注的。在输入层中<span class="math inline">\(x\)</span> 就是我们输入的一个一个数据，<span class="math inline">\(x^{(k)}\)</span>的每一个值就是一个数据的分量，假设如果是图片数据那么<span class="math inline">\(x_1^{(k)} \cdots x_j^{(k)}\)</span>就是图片的每个像素。到此为止我们考虑的都是自由一个输出结果的二分问题，实际上我们一个扩充一下 。</p><h3 id="关于多输出的神经网络的反向传播">关于多输出的神经网络的反向传播</h3><p><img src="./Screen%20Shot%202022-02-17%20at%205.19.17%20pm.jpg" /></p><p>扩充之后输出层就不只有一个节点了而是有<span class="math inline">\(i\)</span>个节点，每个节点都有一个输出值，而这里的损失函数<span class="math inline">\(J\)</span>是对谁有的输出<span class="math inline">\(a_i^{[l](k)}\)</span>的一个统一判断的损失值。也就是整体的这个神经网络离我们的预期还差多少。 因为这里我们只考虑训练神经网络的时候，在训练神经网络的时候这里的<span class="math inline">\(y^{(k)}\)</span>和<span class="math inline">\(x^{(k)}\)</span>都是个确定的值，不是变动参量，所以这里的损失函数我们还可以再简写一下变成<span class="math inline">\(J(a_i^{[l]})\)</span>，损失函数唯一依赖的就是神经网络最后的输出值。</p><p><img src="./Screen%20Shot%202022-02-17%20at%205.25.42%20pm.jpg" /></p><p>我们知道如果要进行反向传播第一步就要对损失函数求梯度，那么因为损失函数依赖于最后每个感知机输出的值，所以对于每个输出都有一个分量，而这个分量就是输出层每个感知机需要承担的偏差值。为了后面描述方便我更愿意在这里添加一个虚拟的<span class="math inline">\(l+1\)</span>层，这个<span class="math inline">\(l+1\)</span>层不是真实存在的只是为了表述方便。我们吧每一个分量当作是一个新的误差函数，而每一个误差函数只对这一个感知机有效对别的感知机无效。</p><p><img src="./Screen%20Shot%202022-02-17%20at%205.34.03%20pm.jpg" /></p><p>那么我们为了继续向前传播就需要对每一个误差函数求梯度，也就是这里的<span class="math inline">\(\nabla J_1^{[l+1]} \cdots \nabla J_i^{[l+1]}\)</span>。</p><p>到这里我们就可以继续一步一步向前传播了，但为了理解我们继续展开来看看。首先我们需要关注的是<span class="math inline">\(\frac{\partial J_1^{[l+1]}}{\partial W_1^{[l]}}\)</span>，我们知道损失函数<span class="math inline">\(J\)</span>其实是一个关于<span class="math inline">\(a^{[l]}\)</span>的函数，而这个<span class="math inline">\(a^{[l]}\)</span>是一个关于激活函数<span class="math inline">\(\sigma\)</span>的函数，所以我们这里需要使用链式求导对她进行展开。 展开之后我们发现对每个分量都有一个<span class="math inline">\(\frac{\partial J_1^{[l+1]}}{\partial \sigma}\)</span>，对于这个我们就可以利用原本那个整体的损失函数<span class="math inline">\(J(a_i^{[l]})\)</span>带进来。就会变成： <span class="math display">\[\nabla J_1^{[l+1]} = (\frac{ v J_1^{[l+1]}}{\partial \sigma}\frac{\partial \sigma}{\partial z_1^{[l]}}\frac{\partial z_1^{[l]}}{\partial W_1^{[l]}},\, \frac{\partial J_1^{[l+1]}}{\partial \sigma}\frac{\partial \sigma}{\partial z_1^{[l]}}\frac{\partial z_1^{[l]}}{\partial a^{[l-1]}},\, \frac{\partial J_1^{[l+1]}}{\partial \sigma}\frac{\partial \sigma}{\partial z_1^{[l]}}\frac{\partial z_1^{[l]}}{\partial b_1^{[l]}})\]</span> 后面为了简化表达就不继续展开了。然后我们还需要关注另一就是<span class="math inline">\(\partial W_1^{[l]}\)</span>，我们知道<span class="math inline">\(W_1^{[l]}\)</span>是个向量所以它是有分量的，队友有分量的进行求偏导其实这里是有简化的。他其实相当于对每个分量进行求偏导。对于<span class="math inline">\(a^{[l-1]}\)</span>也是同理。后面也不继续展开了。</p><p><img src="./Screen%20Shot%202022-02-17%20at%205.49.08%20pm.jpg" /></p><p>但我们已经知道了这些分量后我们就可以对参数进行修改了</p><p><img src="./Screen%20Shot%202022-02-17%20at%205.57.32%20pm.jpg" /></p><p>对于<span class="math inline">\(W,\,b\)</span>我们就可以直接进行修改了这里的<span class="math inline">\(\eta\)</span>其实就是我们常说的学习率了，然后对于<span class="math inline">\(a\)</span>我们可以构建新的损失函数继续进行反向传播。这里我们利用了滑动窗口的思想来理解接下来的操作。</p><p><img src="./Screen%20Shot%202022-02-17%20at%206.02.36%20pm.jpg" /></p><p>对于每一个损失函数求梯度，这里每一个梯度都有多个分量，每个感知机的偏差都由上一层的所有感知机共同承担。这里每一个<span class="math inline">\(a\)</span>又都是一个关于<span class="math inline">\(W,\,a,\,b\)</span>的函数，所以我们可以继续展开。</p><p><img src="./Screen%20Shot%202022-02-17%20at%206.08.32%20pm.jpg" /></p><p>在这里我们需要多注意的是对于<span class="math inline">\(l\)</span>层所有的感知机来说，他们需要承担的偏差值就不是由一个感知机来赋予的了，而是由所有的感知机共同赋予的。我们把所有偏差值的分量统一加起来求平均把它作为需要调整的的量。接下来我们就可以把所有的需要调整的偏差值写出来。 <span class="math display">\[(\Delta W_1^{l},\, \Delta a^{[l-1]},\, \Delta b_1^{[l]},\,\cdots\,,\,\Delta W_i^{l},\, \Delta a^{[l-1]},\, \Delta b_i^{[l]})\]</span></p><p><span class="math display">\[(\Delta W_1^{l},\, J_1^{[l]},\, \Delta b_1^{[l]},\,\cdots\,,\,\Delta W_i^{l},\, J_i^{[l]},\, \Delta b_i^{[l]})\]</span></p><p>其中<span class="math inline">\(W,\, b\)</span>就可以直接进行修改了，然后我们重新定义<span class="math inline">\(J_i^{[l]}\)</span>就可以把这个循环继续下去了。</p><h3 id="references">References</h3><p>https://www.geogebra.org/m/HpDDHprj</p><p>https://www.bilibili.com/video/BV1Zg411T71b?spm_id_from=333.999.0.0</p><hr /><p><strong><em>知识来源作者为b站UP主王木头学科学</em></strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>数学</tag>
      
      <tag>神经网络</tag>
      
      <tag>梯度</tag>
      
      <tag>梯度下降法</tag>
      
      <tag>反向传播</tag>
      
      <tag>偏微分</tag>
      
      <tag>链式反导</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>交叉熵如何做损失函数？</title>
    <link href="/2022/02/15/%E4%BA%A4%E5%8F%89%E7%86%B5/"/>
    <url>/2022/02/15/%E4%BA%A4%E5%8F%89%E7%86%B5/</url>
    
    <content type="html"><![CDATA[<h3 id="最大似然估计为什么又叫交叉熵">“最大似然估计”为什么又叫“交叉熵”</h3><p>下面这个是吴恩达大佬在他的课程里面写出来的最大似然估计法的公式，<span class="math inline">\(y\)</span>是标签值， <span class="math inline">\(\hat{y}\)</span>是神经网络的估计值。 <span class="math display">\[\mathscr{L}\left(\hat{y}, y\right) = -\left(y\log\hat{y} + \left(1-y\right)\log\left(1-\hat{y}\right)\right)\]</span> 这个的确是用最大似然估计法写出来的损失函数，但是，只要你对损失函数有了解，就可能见到过，同样的这个公式也叫<strong>交叉熵</strong>，或者说是<strong>最小交叉熵方法</strong>。</p><p>这就是有疑问的地方了，同样一个东西，为什么既可以叫这个名字，又可以叫那个名字。如果，两个名字相似也就算了，<strong>关键是“最大似然估计”和“交叉熵”两个没有丝毫相似的地方，为什么可以表示同一种东西呢</strong>？</p><p>这就需要搞明白交叉熵到底是什么东西了，等把它搞明白之后，你就会明白，交叉熵和最大似然估计，虽然它们设计损失函数的思路不同，但是它们却是殊途同归，本质上是相同的。</p><p>本章将会了解以下内容：</p><ol type="1"><li>如何比较两个不同的概率分布？</li><li>什么是信息量？信息量是如何定义出来的？</li><li>什么是熵？</li><li>什么是KL散度（相对熵）和交叉熵？</li><li>用交叉熵如何设计损失函数？真的和最大似然估计法没有区别吗？</li></ol><h3 id="熵可以让不同的类型的概率分布实现公度">熵可以让不同的类型的概率分布实现公度</h3><p>还是拿分类问题来举例，给了一堆猫狗的照片要把它们正确的分开，猫狗的区别这是有一个客观的规律的。我们上一次也讲过了，这个客观的规律，我们可以用函数来表示，也可以概率分布来表示。</p><p>假如说，这个真实的规律我们可以用<span class="math inline">\(P\left(y,\,x\,|\,\text{真实规律}\right)\)</span>来表示，其中<span class="math inline">\(y\)</span>判断结果，<span class="math inline">\(x\)</span>是输入的图片，如果以真实规律作为条件，那么输入的图片一定能准确地判断出是猫还是狗。那机器学习呢？其实就是在计算机里面尽可能没有差别地把这个<span class="math inline">\(P\left(y,\,x\,|\,\text{真实规律}\right)\)</span>概率分布学出来。</p><p>这里就出现一个关键问题了，假如说机器学习算法做出了一个猜测，<span class="math inline">\(P\left(y,\,x\,|\,\text{真实规律}\right)\)</span>。我们应该如何判断，这个猜测出来的概率分布与表示真实规律的概率分布是不是一样的？</p><p>其实不只是是判断出来“一样”还是“不一样”就可以了，还需要知道它们之间的差距有多大，这样才能帮助机器学习的算法调整和修改，越来越接近真实规律。</p><p>那么如何才能对两个概率分布做出比较呢？</p><p>如果是同一类的概率分布的话，那还好办。比如说，都是正态分布，影响分布的参数就两个，一个均值一个方差。只需要判断真实规律和猜测规律里面这两个参数是不是一样，不一样的话看看参数差了多少，就行了。</p><p>但真实的情况却不是这么简单，真实规律表现出来是什么样子的，我们根本不知道，别说我们根本无法确定真实规律那个概率分布到底是什么类型的，就算是确定了，决定它的参数也可能有很多，无法进行简单地比较。</p><p>于是，比较两个概率分布的最大障碍出现了。<strong>两个不同类型的概率分布，它们无法直接公度</strong>。</p><p>那怎么办呢？有什么方法可以让无法公度的两个概率分布，变得可以公度吗？</p><p>这件事上，虽然不能一下子想到解决方法，但是说到公度的话，我们的世界里有一个特别伟大的系统，通过它可以让许多本来无法公度的事情变得可以公度，这或许可以给我们带来启发。</p><p>这个系统就是货币系统，它让许多无法公度的事情，都可以变成一个价格数字，通过价格就能进行比较了。</p><p>就比如，一个房子，你家里的老房子，在里面有几代人的记忆，对于你来说这个房子是价值很大的。但是，对于买房的人来说，这并没有什么特殊的，他心中这个房子的价值一定不如你。这本来是一个无法公度的事情，因为你们选择的根本就是不同的价值体系。</p><p>不过没有关系，只要把房子放到货币体系里面，货币体系就可以完成对这个房子价值的评估，在你和买房人之间寻找到一个价值平衡点。</p><p>虽然价格体系的运行方式很复杂，但是有一点是能给我们启发的，那就是不论是什么东西，它都可以把它们换成一串数字，变成数字之和就可以进行公度了。</p><p>那么不同类型的概率分布，它们是不是也可以有类似的方法，先把它们转换成一串数字，将这个数字作为他们进行公度的代表。</p><p>还真有，这个<strong>概率分布的“货币体系”就是熵</strong>。</p><p>所有的概率分布，都可以统一地被转换成熵，比较两个概率分布是不是相同，不同的话，它们之间又相差多少，都可以用熵来进行衡量了。</p><p>那到底是什么是熵呢？在了解它之前，我们还需要了解一个前置概率，信息量。</p><h3 id="信息量是什么">信息量是什么</h3><p>信息量这个词我们还是比较熟悉的，在日常口语中我们就在使用，假如说你看新闻刷到一个惊天大瓜，你可能就会感叹说这个新闻的信息量太足了。</p><p>什么是信息？一条信息的功能就是让你从“不知道”变得“知道”，信息量肯定就是对信息的这个功能进行的度量了。可是，如果信息的使命就是让“不知道”变成“知道”，也就是说这是一个“是否”的二值问题，那信息也就没有度量的必要了，反正就两种情况。</p><p>关键是，一条信息不是“知道”和“不知道”非此即彼的，它还能让你既不是完全不知道，又不是完全知道。如果是这样的话，那对信息进行度量就有意义了，就是去度量一下这个“知道”的程度。</p><p>这种既不是完全不知道，又不是完全知道的状态还真有，举个例子。假如说有8只球队参加世界杯，有这样两种情况：</p><ol type="1"><li>如果你什么消息都没有听说，有人问你阿根廷夺冠没有啊，你回答说不知道。</li><li>随后，你看到一个消息，说阿根廷已经进决赛了，这个时候再问你阿根廷夺冠没有啊，你还是说不知道。</li></ol><p><img src="./7899da57ce319f2ab072772dbac334df69f1dbdb.png@942w_680h_progressive.png" /></p><p>虽然两种情况，你对阿根廷是否夺冠回答的都是不知道，但是这里的“不知道”和“不知道”还是很不一样的。<span class="math inline">\(a\)</span>情况的不知道，因为还没有比赛所以阿根廷夺冠的概率是<span class="math inline">\(\frac{1}{8}\)</span>，b情况阿根廷已经进到决赛了，虽然还没有最终夺冠，但是夺冠的确定性已大大增加，已经达到了<span class="math inline">\(\frac{1}{2}\)</span>。</p><p>所以说，“阿根廷进决赛”这个消息，让你对阿根廷夺冠这个事件，从完全不知道，到有些知道了。也就是说，这个消息它应该是有信息量的。</p><p>从前面这个例子，我们也能看出来对于阿根廷夺冠这件事，不同的消息含有的信息量很可能是不同的。</p><p>如果我和你说，我今天中午多吃了一个包子，这虽然也是个消息，但是这个消息对于阿根廷夺冠来说信息量就<span class="math inline">\(0\)</span>。</p><p>总结一下的话，其实我们应该有这一个感觉了，定性上来说，信息量它应该是，某个消息对“某个事件的确定程度改变了多少”进行的衡量。而确定性改变了多少，其实也就是前面说的那个概率的改变，阿根廷夺冠从原来的<span class="math inline">\(\frac{1}{8}\)</span>变成了<span class="math inline">\(\frac{1}{2}\)</span>。</p><p>但是定量上来说，信息量到底是多少呢？难道就是凭着直觉，简单地用<span class="math inline">\(\frac{1}{2}\)</span>减去<span class="math inline">\(\frac{1}{8}\)</span>，用这个差值去定义信息量吗？ 没有这么简单。</p><h3 id="信息量的良定义">信息量的良定义</h3><p>要想对信息量给出一个良定义，不能产生自我矛盾，就需要考虑一下不同情况中，我们对信息量的理解是什么样的。</p><p>就比如，我们可以看这样一种情况。</p><p><img src="./b84943df5cf47c4a1957bdb1459303aaf6b02a27.png@942w_615h_progressive.png" /></p><p>这里的3个箭头代表着3个消息，绿色消息是阿根廷进入了决赛，蓝色消息则是阿根廷直接夺得冠军，这两个消息的起点都是一样的，都是在你不知道任何比赛结果的时候听到的消息。</p><p>而橙色消息，它则是依赖于绿色消息的，它代表的是，在你知道阿根廷进决赛之后，又赢得决赛夺得冠军。</p><p>如果我们想要信息量来衡量3个消息，那么我们可以看出信息量应该满足下面等式：</p><ul><li>$信息量(蓝色消息)=信息量(绿色消息)+信息量(橙色消息) $</li></ul><p>一个消息的信息量具体是多少，虽然我们现在还不知道，但是我们可以确定，这个信息量应该是和对应事件发生的概率有关。于是我们就可以拿这个概率作为变量，那计算信息量这个函数应该如下：</p><ul><li><span class="math inline">\(信息量(\frac{1}{8})=信息量(\frac{1}{4})+信息量(\frac{1}{2})\)</span> —— ①</li></ul><p>到这里其实还没有完，因为函数里的变量是概率，根据条件概率的性质，我们知道这里还隐含着一个条件，那就是：</p><ul><li><span class="math inline">\(P(夺冠)=P(夺冠|进决赛)×P(进决赛)\)</span> —— ②</li></ul><p>把①和②一结合，我们就可以发现这样一个关系：</p><ul><li><span class="math inline">\(信息量(\frac{1}{4} × \frac{1}{2})=信息量(\frac{1}{4})+信息量(\frac{1}{2})\)</span></li></ul><p>仔细看一下这个式子就能发现，计算信息量的这个函数，如果想要自洽、想要是良定义的，那么它必须满足一个条件，那就是自变量的乘法等于函数值的加法。</p><p>满足这样这样的函数应该是什么样子的？</p><p>理论上来说，满足这个性质的函数应该是有千千万万的，但是其中最简单的应该就是对数运算log了。log对数运算是唯一满足这种关系的初等函数。</p><p>到现在，我想大家心中都会有一个冲动，就是把信息量定义为： <span class="math display">\[\text{信息量}\left(P\left(X\right)\right) :=?log_?P\left(X\right)\]</span> 不论是说<a href="https://baike.baidu.com/item/奥卡姆剃刀原理/10900565?fr=aladdin">奥卡姆剃刀原理</a>，还是说人们本能的喜欢偷懒，这个用最简单的方式给出定义的冲动都特别正常。我想，当年香农给出信息量的定义的时候，也是这么想的。</p><p>接下来需要确定的就是这个式子里的两个问号了，系数是多少？对数的底又是多少？</p><p>一切都为了简单，不考虑别的话，系数应该就是<span class="math inline">\(1\)</span>了，只不过需要确定的是，到底是<span class="math inline">\(1\)</span>还是<span class="math inline">\(-1\)</span>。</p><p>如果硬规定，系数就是1也行，只不过我们现在做的并不是完全凭空发明出信息量这个概念，如果是凭空创造出来的，那么发明人怎么定那我们就怎么用。我们现在面对的问题是，信息量这个概念，我们在日常生活中就在用，只不过定理的定义不是很清晰，我们现在做的其实是把这个定义换成更精确的数学方式表达出来，所以数学的定义不应该和我们的口语表达有冲突。</p><p>所以到底是<span class="math inline">\(1\)</span>还是<span class="math inline">\(-1\)</span>，就需要看一下我们口语中，自变量（也就是那个概率值）越大函数值越大，还是自变量越小函数值越大了。</p><p>还是看上面阿根廷夺冠的例子，绿色消息是阿根廷进入决赛，蓝色消息是阿根廷夺得冠军，一个发生的概率是1/4，一个发生的概率是1/8，单从概率的数值上来看的话，显然绿色消息值更大。但是这两个消息那个信息量更大呢？</p><p>我们的感觉肯定是蓝色的消息信息量更大啊，绿色的消息只是让阿根廷夺冠这件事概率增加了，并没有完全确定，而蓝色消息却是给出了一个完全确定的结果，显然蓝色的消息带来的不确定程度的改变更剧烈，也就是带来的信息量更大。</p><p>所以信息量，它的自变量和函数值应该是一个反比关系，也就是第一个问号，那个系数应该是<span class="math inline">\(-1\)</span>。 <span class="math display">\[\text{信息量}\left(P\left(X\right)\right) :=-log_?P\left(X\right)\]</span> 剩下没有确定的就是对数运算的底了，这里底到底取多少，其实已经不那么重要了，可以取<span class="math inline">\(e\)</span>为底，也可以取<span class="math inline">\(10\)</span>为底，还可以取<span class="math inline">\(2\)</span>为底。当然，现在我们习惯的方式用2为底，这样子计算出来的信息量单位是比特。</p><p>取不同的底，其实就是信息量的单位不同，以<span class="math inline">\(e\)</span>为底的单位是纳特(nat)或者是nit，以<span class="math inline">\(10\)</span>为底的单位是哈特(Hart)或者是dit。</p><p>其中比特我们最熟悉，这最早是由香农提出来的。而以<span class="math inline">\(10\)</span>为底的信息量，最早是1928年有拉尔夫·哈特利(Ralph Hartley)提出来的，后来图灵也用<span class="math inline">\(10\)</span>为底计算过信息量，只不过图灵把这样的信息量单位称为ban。</p><p>这里值得注意的是，信息量是有单位的（也就是说信息量有量纲）。什么意思呢？这里用bit作为例子来说明一下。</p><p>我们知道，说到单位，比如说米、千克，它们都是有一个基准尺度的，具体长度是多少、质量是多少，都是与这个基准尺度做比较得出来的。比如，曾经米的基准就是子午线的千万分之一，后来才改成用光速定义，公斤的基准尺度曾经是用放在法国的国际千克原器的质量，后来才改成用普朗克常数定义。</p><p>既然信息量也是有单位的，那么这个bit单位的基准尺度是什么呢？</p><p>其实bit就是用像抛硬币这种“<span class="math inline">\(50\%\)</span>正、<span class="math inline">\(50\%\)</span>反”的情况作为基准尺度的，其他的bit数值都是与这个基准尺度比较得到的。</p><p><span class="math inline">\(\frac{1}{2}\)</span>概率的事件是<span class="math inline">\(1\)</span>bit，<span class="math inline">\(\frac{1}{4}\)</span>概率的事件是<span class="math inline">\(2\)</span>bit，这就是说这两个概率分别可以用<span class="math inline">\(1\)</span>个硬币和<span class="math inline">\(2\)</span>个硬币等价表示。至于<span class="math inline">\(\frac{1}{3}\)</span>的概率，对应的信息量是约等于<span class="math inline">\(1.58\)</span>bit。虽然我们现实中不可能是抛<span class="math inline">\(1.58\)</span>个硬币，但是数学上还是可以这样来表示出来的。</p><p>这里再多说一下，在计算机里面，我们经常说<span class="math inline">\(8\)</span>bit、<span class="math inline">\(16\)</span>bit这些词，这些词不只表示一个信号里面含有的信息量，还用来表示存储空间的大小。</p><p>这是为什么呢？</p><p>举个例子，假如说计算机里面有一个<span class="math inline">\(16\)</span>bit的空间，这个空间里0、1、0、1到底是怎么排列组合的，是不确定的，任何一种情况的概率都是<span class="math inline">\(\frac{1}{2}^{16}\)</span>。当计算机接受到1个信息，这里的空间存储上了一个2进制数字（具体是什么数字无所谓），这里的可能性就从原来的<span class="math inline">\(\frac{1}{2}^{16}\)</span>概率变成了确定的<span class="math inline">\(1\)</span>，这个信息量是多少？就是<span class="math inline">\(16\)</span>bit啊。这个空间最多可以承载多少的信息量？就是<span class="math inline">\(16\)</span>bit了。</p><p>于是存储空间的大小和信息量统一了，这也是bit又可以表示存储空间的原因。</p><h3 id="熵是一个系统里信息量的期望值">熵是一个系统里信息量的期望值</h3><p>对信息量了解之后，我们就可以来看熵了。</p><p>熵这个概念，现在已经比较出圈了，本来一个学科里面很偏门的概念，现在在互联网圈子里面却人尽皆知。</p><p>主要就是熵增这个概念太火了，它涉及到了整个宇宙的宿命，宇宙的未来就是在不可对抗的熵增过程中归于热寂。那熵到底是什么呢？在科普内容里面，很少有人把熵的定义公式拿出来讲的，都是说<strong>熵是对一个系统的混乱程度的度量</strong>。</p><p>当初的先贤们是如何提出熵这个概念的，他们最初的想法是什么，我们很难还原了，不过我们现在还是可以对熵做逆向工程，试着来理解一下，前面说的系统的混乱程度到底是什么意思？为什么用信息量可以去描述系统的混乱程度？</p><p>我们可以先来看这样一个问题，有两场比赛，假如说这两场比赛就是两个系统。</p><p><img src="./5da5016d8b883f7da6081355f55aae59672fb976.png@942w_290h_progressive.png" /></p><p>一场比赛是比利时对战阿根廷（系统1），因为它们水平差不多，所以两队赢球的概率都是<span class="math inline">\(50\%\)</span>。另一场比赛是法国对中国（系统2），实力相差比较大，所以法国赢球的概率<span class="math inline">\(99\%\)</span>，中国赢球的概率是<span class="math inline">\(1\%\)</span>。</p><p>请问，这两个系统那个的混乱程度更高？</p><p>这个问题并不是靠直觉马上就能回答出来的，还是要琢磨一下。法国对中国，这个系统不出意外的话，肯定是法国赢，也就是最后的结果确定性更高。而比利时对阿根廷，这个就不能说意外不意外了，谁赢都有可能，所以最后结果是什么就很不确定。</p><p>这里我是用不确定的程度来描述两场比赛的，其实这个不确定的程度也就是我们日常说的混乱程度，比利时和阿根廷比赛，因为结果特别不确定，所以很混乱。反过来说你，一个屋子很混乱，也就是你的袜子到底在哪里，非常不确定。</p><p>既然和概率、不确定性搭上关系了，那么我们前面介绍的信息量就可以派上用场了。</p><p>两次比赛，分别对应着两个可能的事件（系统1是“比利时赢”和“阿根廷赢”两个事件，系统2是“法国赢”和“中国赢”两个事件），它们对应的信息量计算结果出来如下：</p><p><img src="./5262bdbc97fbc0edff46ddd34754fc26620a5000.png@942w_414h_progressive.png" /></p><p>比利时对阵阿根廷，不论谁获胜，信息量都是1bit。法国对阵中国，法国赢球的概率很高，所以他们赢球带来的信息量就很少，但是如果中国赢球了，那这个信息量就很大了，超过了6.6bit。</p><p>这么看的话，系统1这个系统里两个事件的信息量加起来才是2bit，还没有中国赢球一个事件的信息量大，如果用信息量来表示熵，是不是就会有问题啊。明明系统1更不确定，但是计算出来却是系统1的信息量更少。</p><p>别急，熵的确是“系统里面所有可能事件对应的信息量总和”，只不过不是把它们简单地加起来就行了，而是需要加权求和。这个权重是什么？就是这个事件发生的概率啊。</p><p><img src="./e577e8cd24c9aafa024487ae7d1fe1084141838e.png@942w_497h_progressive.png" /></p><p>加上权重之后，就合理了，从上图就可以看出系统1得到的值的确是比系统2更大了。</p><p>而且这个加上权重的动作也挺合理的，就比如说，中国队夺冠了这个事情如果发生了的话，信息量的确还挺大的，但是它得真发生了才行了，可事实呢，它只有1%的可能性发生，99%的可能性都是法国夺冠。</p><p>所以，一个系统到底含有多少信息量，那还需要看具体一个事件对整个系统到底能贡献多少信息量才行。如果事件没发生，那就是没有贡献啊，就不能放在总和里面。越是一个事件贡献了多少信息量，就可以理解成信息量乘上对应事件发生的概率。</p><p>那熵到底是什么？这个问题就简单了，熵就是所有事件对应的信息量的加权和，那这个加权和是什么？就是这个系统里面信息量的期望值啊。</p><p>那么我们就可以<strong>对熵做出如下定义</strong>了，其中<span class="math inline">\(H\left(S\right)\)</span>表示<span class="math inline">\(S\)</span>系统的熵，<span class="math inline">\(E\)</span>是求期望，<span class="math inline">\(I(X)\)</span>是求信息量，<span class="math inline">\(P\left(x_i\right)\)</span>表示<span class="math inline">\(x_i\)</span>事件的概率。</p><p><img src="./b14c7987fc718bb8641a09c0821e876d7b7879ba.png@942w_480h_progressive.png" /></p><p>现在我们已经知道熵到底是什么了。我们最开始的目的是什么？是比较两个概率分布，一个表示真实的规律，一个表示机器学习猜测的规律，看看两个概率分布它们相差有多少。</p><p>现在有了熵，我们是不是就可以直接比较两个概率分布的差距了呢？把两个概率分布的熵都算出来，然后看看相差多少。</p><p>哪有这么简单，别忘了，真实规律我们是不知道的，既然不知道，那它的熵还怎么求呢？没有办法。</p><p>那么有没有什么方法，即便不知道一个概率分布的熵具体是多少，也能知道两个概率分布之间的差距是多少呢？ 有！这就是KL散度和交叉熵了。</p><h3 id="kl散度相对熵和交叉熵">KL散度（相对熵）和交叉熵</h3><p>假如说，下面这个图表示的是两个系统的概率分布，其中系统<span class="math inline">\(S\)</span>代表的是真实的规律，系统<span class="math inline">\(O\)</span>代表的是机器学习模型里面猜测的那个规律。</p><p><img src="./166b97f632272d046a9d62720bf536756e4bac6b.png@942w_363h_progressive.png" /></p><p>这两个系统的概率分布如果是相同的话，那么毫无疑问，两个系统的熵也一定是相等的，而且我还能大概确定，两个系统越像，熵应该是越接近的。</p><p>不过，这个事情不能反过来想，两个系统的熵相同，两个系统的概率分布就一定相同吗？好像并没有这么简单，因为简单的一个数字，维度太少了。一张200元的高铁票和一件200元的衣服，它们价格相同，但是这两个东西却是天差地别。</p><p>所以，看两个系统是不是相同，不能是直接比较两个系统的熵，这会太简单粗暴。那怎么办呢？这个时候就需要KL散度这个概念了。</p><p>KL散度就不是粗暴的比较一个总体的熵了，而是比较得更细致，每一个事件<span class="math inline">\(x_i\)</span>对应的信息量，都会拿来进行比较。如果每一个事件的信息量都是相同的，那么两个概率分布肯定就是相同的了。</p><p>于是KL散度就可以做出如下定义：</p><p><img src="./65ad9077e81ac853dc82efa4470f3fd0f9b583a4.png@942w_198h_progressive.png" /></p><p>可以注意到，这个定义本质上也是一个加权求和，求和的是两个系统中同一个事件的信息量的差值，加的那个权重是其中一个系统里这个事件的概率值。从这里也能看出来，这里的系统<span class="math inline">\(S\)</span>和系统<span class="math inline">\(O\)</span>，它们并不是平等的，把<span class="math inline">\(S\)</span>和<span class="math inline">\(O\)</span>交换之后并不能保证得到相同的值。 <span class="math display">\[D_{KL}\left(S\,\|\,O\right)\neq D_{KL}\left(O\,\|\,S\right)\]</span> 也就是说，KL散度它相当于会在两个系统中挑选了一个作为基准（我这里用的是<span class="math inline">\(S\)</span>系统作为基准），拿另一个系统与这个基准进行比较。因为这是用<span class="math inline">\(S\)</span>系统的熵作为基准，去衡量另一个系<span class="math inline">\(O\)</span>的熵，所以KL散度也叫相对熵。</p><p>当KL散度给出来之后，用熵直接比较太简单粗暴的问题给解决了，但是这个东西我们应该怎么用呢？直接看KL散度的定义的话，还是很难想到怎么用的，不过只需要对KL散度的定义变变形，这个问题就会变得简单了。</p><p><img src="./4ac700e2f47237fc391422f788cbd2b5075fe19f.png@942w_261h_progressive.png" /></p><p>经过变形之后我们就能发现，KL散度可以被分成两个部分，其中后面的那个部分计算出来就是系统<span class="math inline">\(S\)</span>的熵，这部分算出来是多少是与系统<span class="math inline">\(O\)</span>无关的。所以，真正决定KL散度的其实是前面那部分，它的大小决定着KL散度的大小。</p><p>于是这部分就可以被单独拿出来讨论，所以<strong>它就被定义成为了交叉熵</strong>。想知道系统<span class="math inline">\(S\)</span>和系统<span class="math inline">\(O\)</span>是否一样，不需要去计算它们的KL散度，只需要去看它们的交叉熵。</p><p>我们的目标是什么，是希望机器学习模型中猜测出来的那个概率分布<span class="math inline">\(O\)</span>，与真实的概率分布<span class="math inline">\(S\)</span>接近。这个接近如果用KL散度来表示的话，就是KL散度要尽可能地接近数值0，正值太大、负值太小都不行。</p><p>那如果我们的目标不用KL散度来表示，而是用交叉熵来表示，应该是什么样子的呢？如果直接看前面推导出的那个式子，我们可以看到，我们的目标可以表示成交叉熵的值与系统<span class="math inline">\(S\)</span>的熵最接近时，目标达成。</p><p>但是这里也就有问题了，这代表着如何能找到最合适的交叉熵，要分两种情况来考虑：</p><ul><li>当交叉熵的值大于系统<span class="math inline">\(S\)</span>的熵时，我们的目标是寻找交叉熵最小的值</li><li>当交叉熵的值小于系统<span class="math inline">\(S\)</span>的熵时，我们的目标是寻找交叉熵最大的值</li></ul><p>这个时候，我们一般都会不禁地想，如果只有一种情况该多好啊，这样问题就简单了，我们寻找最接近系统<span class="math inline">\(S\)</span>的系统<span class="math inline">\(O\)</span>，就变成一个对交叉熵求最值的问题了，如果是第一种情况就是求最小值，如果是第二种情况就是求最大值。</p><p>我想数学家们也和我们有同样的想法，所以他们真的从数学上证明了，不需要两种情况都考虑，只需要考虑第一种情况。</p><p>这是因为，从数学上就可以证明，交叉熵的值一定是会大于等于系统<span class="math inline">\(S\)</span>的熵的。所以，只需要考虑如何对交叉熵求最小值就行了。一个系统与系统<span class="math inline">\(S\)</span>的交叉熵最小值，那么这个系统与S最接近。</p><p>这个证明过程就不写了，感兴趣的话，大家可以自己去了解一下<a href="https://zh.wikipedia.org/wiki/吉布斯不等式">吉布斯不等式</a>。（重点关注一下条件，概率值<span class="math inline">\(p_i\)</span>和<span class="math inline">\(q_i\)</span>是归一的，后面要用到）</p><p>至此，我们终于了解交叉熵到底是怎么来的，以及为什么交叉熵最小的时候，两个概率分布最接近。</p><p>但是，这个概念是如何应用到神经网络里面的？它对应的损失函数应该如何设计？为什么求交叉熵最小的方法，又可以被称为最大似然估计法？</p><h3 id="最小交叉熵和最大似然估计两种损失函数等价">“最小交叉熵”和“最大似然估计”两种损失函数等价</h3><p>要想把交叉熵这个概念应用到神经网络里面，那我们首先需要做的是把神经网络变成一个概率问题。假设说这是一个判断是猫是狗的二分问题，那么真实规律和神经网络猜测的规律，可以用下面两个概率分布来进行表示。</p><p>其中随机变量<span class="math inline">\(z\)</span>，表示这个规律对图片的判断结果。</p><p><img src="./5d5e5b42dfab7438fbdd16ec58eabb3a686c6941.png@942w_359h_progressive.png" /></p><p>于是，交叉熵就可以写成如下形式，（因为是归一的，所以可以用<a href="https://zh.wikipedia.org/wiki/吉布斯不等式">吉布斯不等式</a>，也就是KL散度可以转化成交叉熵问题）：</p><p><img src="./ab41c87fe55a68afff093d5a24e6ffaeeb5fef22.png@942w_144h_progressive.png" /></p><p>不过，只是这样的话，我们是没有办法计算交叉熵的，因为我们并不清楚<span class="math inline">\(P\left(z_i,\,x_i\,|\,\text{真实规律}\right)\)</span>和<span class="math inline">\(P\left(z_i,\,x_i\,|\,\text{猜测规律}\right)\)</span>的概率分布</p><p>我们知道是什么？</p><p>是<span class="math inline">\(P\left(z_i,\,x_i\,|\,\text{真实规律}\right)\)</span>和<span class="math inline">\(P\left(z_i,\,x_i\,|\,\text{猜测规律}\right)\)</span>的概率，这里不一样的是<span class="math inline">\(x_i\)</span>的位置，<span class="math inline">\(x_i\)</span>也就是输入的数据、猫狗的图片从原来的随机变量，变成了条件。</p><p>然后我们就可以得到下图的关系。其中<span class="math inline">\(\hat{y}\)</span>表示神经网络在输入图片后的计算结果，因为<span class="math inline">\(\hat{y}\)</span>经常是经过sigmoid计算后的结果，所以可以直接看做是一个概率值。</p><p><img src="./704b2dc51a6681951fb2f5d1bfc1dfa73d0e4534.png@942w_279h_progressive.png" /></p><p>从<span class="math inline">\(P\left(z_i,\,x_i\,|\,\text{真实规律}\right)\)</span>，到<span class="math inline">\(P\left(z_i\,|\,x_i,\,\text{真实规律}\right)\)</span>，我们知道中间差了一个<span class="math inline">\(P(x_i)\)</span> <span class="math display">\[P\left(z_i,\,x_i\,|\,真实规律\right)=P\left(z_i\,|\,x_i,\,真实规律\right) \cross P\left(x_i\right)\]</span> 于是交叉熵就可以写成下面的样子：</p><p><img src="./ddb7708dfaf12ffcd1570e4b5f273a4687845fe6.png@942w_135h_progressive.png" /></p><p>这里的<span class="math inline">\(P(x_i)\)</span>其实代表的就是，这个训练用的图片是按照什么概率从茫茫多的图片中抽样出来的。这个值我们并不清楚，不过训练集的图片我们基本上也就是认为它们是被随机挑选出来的，也就是说不同图片的概率应该都是相同的。于是P(xi)就可以看做是一个常数。</p><p>又因为我们希望求的是在交叉熵取最小值时的“猜测规律”的情况，所以当<span class="math inline">\(P(x_i)\)</span>是常数的时候，对最后的结果是不会有影响的。</p><p>也就是说：</p><p><img src="./1125e2d70ade5d39f2d5fe7ec93775dadff5b41a.png@942w_207h_progressive.png" /></p><p><img src="./fb6a922a72973f7dd35146c4960c9efcf70c1e4b.png@942w_224h_progressive.png" /></p><p>当然，我们更习惯的用法，其实是将猫狗用<span class="math inline">\(1\)</span>和<span class="math inline">\(0\)</span>来表示，如果说用<span class="math inline">\(1\)</span>表示是猫，<span class="math inline">\(0\)</span>表示是狗，那么<span class="math inline">\(y\)</span>作为图片的标签值有：猫的标签值<span class="math inline">\(y=1\)</span>，狗的标签值<span class="math inline">\(y=0\)</span>。于是前面的那个概率关系就可以变成如下的样子：</p><p><img src="./6fb867e1e224e8c75043c45e99a4b3dfb632d8dc.png@942w_362h_progressive.png" /></p><p>然后我们再对上面几种情况归纳整理一下，就可以得出最小交叉熵的最终表达形式了，其中<span class="math inline">\(i\in\left\{1,2,\cdots,n\right\}\)</span>，表示的是训练集图片有<span class="math inline">\(n\)</span>个，<span class="math inline">\(j\in\left\{1, 2\right\}\)</span>，表示这是一个二分类问题：</p><p><img src="./e88a8a33291cc7949a5f25cb202b1849b285c61a.png@942w_389h_progressive.png" /></p><p><img src="./c0858206816dd5da24c49d42d955b6b42a72bbf9.png@942w_186h_progressive.png" /></p><p>到了这一步，是不是就非常眼熟了？我们可以再把最开始吴恩达老师课程里的那个损失函数表达式拿下来看一下： <span class="math display">\[\mathscr{L}\left(\hat{y}, y\right) = -\left(y\log\hat{y} + \left(1-y\right)\log\left(1-\hat{y}\right)\right)\]</span> 是不是一模一样的？吴恩达老师给出的是一个图片的计算公式，如果考虑的是把所有图片的交叉熵都计算出来，就是我写出来的样子了。也就是说，最小交叉熵和最大似然估计，它们殊途同归，本质上是等价的。</p><p>当然，这里还有多提一下，从数学上来看，最小交叉熵和最大似然估计是等价的，但是硬要较真儿的话，两个方法在物理上还是不同的。因为，交叉熵是有量纲的，而似然值没有量纲，最大似然值最后之所以会出现log和负号，也只是为了计算的方法，本身并没有物理意义。交叉熵就不同了，它的log和负号，是让它有单位的关键。</p><h3 id="references">References</h3><p>https://www.bilibili.com/video/BV15V411W7VB?spm_id_from=333.999.0.0</p><p>https://www.bilibili.com/read/cv15258489?spm_id_from=333.999.0.0</p><p>https://baike.baidu.com/item/奥卡姆剃刀原理/10900565?fr=aladdin</p><p>https://zh.wikipedia.org/wiki/吉布斯不等式</p><hr /><p><strong><em>知识来源作者为b站UP主王木头学科学</em></strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>人工智能</tag>
      
      <tag>机器学习</tag>
      
      <tag>熵</tag>
      
      <tag>信息量</tag>
      
      <tag>神经网络</tag>
      
      <tag>深度学习</tag>
      
      <tag>损失函数</tag>
      
      <tag>交叉熵</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>“损失函数”是如何设计出来的？直观理解“最小二乘法”和“极大似然估计法”</title>
    <link href="/2022/02/13/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    <url>/2022/02/13/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p>在吴恩达的课程中提到了两个公式分别是最小二乘法和极大似然估计 <span class="math display">\[\mathscr{L}\left(\hat{y}, y\right) = \frac{1}{2}\left(\hat{y}-y\right)^2\]</span></p><p><span class="math display">\[\mathscr{L}\left(\hat{y}, y\right) = -\left(y\log\hat{y} + \left(1-y\right)\log\left(1-\hat{y}\right)\right)\]</span></p><p>本章要解决的问题：</p><ol type="1"><li>直观的理解损失函数是什么， 为什么这么重要</li><li>吴恩达老师给出的两个损失函数分布是最小二乘法和极大似然估计，他们是怎么来的， 为什么叫这个名字</li><li>最小二乘法和极大似然估计有什么联系</li></ol><h3 id="损失函数的作用">损失函数的作用</h3><p>在弄明白损失函数是如何设计出来之前，我们得先清楚损失函数的作用是什么</p><p>首先如果我们要判断一张照片是不是猫，对于人来说是很简单的我们只需要看一眼便有了答案。如果让我们去制定一个标准来认定符合什么的是猫符合什么的不是猫其实并没有那么容易，但在我们心里我们知道是有那么一个定义或者规律的。</p><p>所以对于机器来说我们并不需要直接告诉他们去判断一个物品是什么的准确标准是什么，而是让他们学习找到这个规律。 具体过程就是先判断再比较然后调整，一直循环这个过程。而损失函数就是用来比较这个环节用来比较模型的判断和我们脑中的判断的差距有多大。</p><p>通过损失函数我们能知道当前模型和我们脑中的模型的一个差值， 然后我们可以通过比如梯度下降来把损失函数计算出来的差值分配给各个参数。使用梯度下降的好处就是我们可以知道具体哪个参数贡献的差值较多哪个较少。最后通过调整参数然后一遍一遍的判断计算损失值修改我们最后把差值降低到一定的范围之内。</p><h3 id="最小二乘法是怎么得出来的">“最小二乘法”是怎么得出来的</h3><p>想要获得真实规律和神经网络里规律的差值我们就需要设计出损失函数对他们进行比较，但我们无法将真实规律和模型的规律进行直接比较因为我们并不知道真实的规律。</p><p>庆幸的是我有已经打好标签的数据集，这些数据我们已经知道正确结果了，换句话来说这些标签其实就是真实规律的判读结果。那既然我们无法直接比较规律我们就可以比较他们判断的结果。如果我们猜测的规律就是真实规律的话， 那么神经网络的判断结果一定和数据标签一致。<span class="math inline">\(\hat{y}\)</span>是神经网络判断的结果， <span class="math inline">\(y\)</span>是标签的真实结果，那么损失函数就可以设计成， 把数据集里所有数据都放到神经网络判断一遍，挨个比较猜测的结果和真实的结果，看看它们之间差了多少，然后把所有的差值都加起来。 <span class="math display">\[\sum_{i=1}^{n} \left| \hat{y}_i-y_i \right|\]</span> 我们都知道，绝对值这个函数并不是全定义域都可导的，而随后求最小值还要进行求导，所以我们就可以把绝对值换成平方（还额外加了一个系数<span class="math inline">\(\frac{1}{2}\)</span>，这是因为求导的时候指数部分的<span class="math inline">\(2\)</span>会拿下来，可以和<span class="math inline">\(\frac{1}{2}\)</span>抵消）。 <span class="math display">\[\sum_{i=1}^{n} \frac{1}{2} \left( \hat{y}_i-y_i \right)^2\]</span> 于是寻找最接近真实规律的过程，就可以描述成是求上面这个式子最小值的过程，而这就是最小二乘法，二乘其实就是以前对平方的一种称呼。</p><h3 id="如果深度学习是个概率问题">如果深度学习是个概率问题</h3><p>第一个式子是怎么设计出来的，这个问题我解决了。那第二个式子又是如何设计出来的？它又为什么叫做极大似然估计法，似然又是个啥？</p><p>要想明白这些，就需要切换一下视角了，需要从概率的视角来看深度学习问题。</p><p>怎么切换成概率呢？我们可以先来看一下最理想的情况，比如，我们可以想象一下，把真实规律用概率分布的方式表示出来，会是什么样子。 （假如说就是判断是一个非猫即狗的二分问题）</p><p><img src="./c9ae479fee42ac6ebd90dcb960aec72ec926bd5f.png@942w_564h_progressive.png" /></p><p>也就是说，只要图片是猫，那么判断的结果一定不会是狗；如果图片是狗，那么判断的结果就一定不是猫，没有任何判断错误的情况出现。（注意：“具体一个猫的图片判断结果也是猫”这个事件的概率并不等于1，“所有猫的图片都判断成猫”、“所有狗的图片都判断成狗”，它们这些事件的概率全加起来才是1）</p><p>但是我们猜测出来的规律呢？虽然仍然可以用一个概率分布来表示，但是就没有这么准了，就算是给了一张猫的图片，但是神经网络还是有概率把它判断成狗。最理想的情况，当然是让我们猜测出来的规律可以和真实规律的概率分布一模一样，但现实是，我们几乎不可能得到和真实规律一模一样的规律，只能近似。（这个原因，需要对PAC框架和VC维理论有比较深入的理解之后才能解释清楚，这里就不多解释了。可以简单的理解为，任何一种机器学习的模型能力都是有限的，所以无法学到真实规律。）</p><p>不过，不论这么样，不论是真实的规律，还是我们猜测的规律，都可以用一个条件概率分布来呈现。我们得到的数据集里面打好标签的数据，其实就是在真实规律这个概率分布下进行抽样得到的结果，而深度学习的过程，就是我们已经有了样本数据，去反推背后概率分布是什么的过程。</p><p>这就相当于，你有一个不知道正反概率是什么的硬币，抛了10次结果是7正3反，如何才能反推出这个硬币正反的真实概率。</p><h3 id="已知样本数据-如何反推概率分布">已知样本数据， 如何反推概率分布</h3><p>如何才能反推出硬币真实的概率呢？投了10次，7正3反，是不是说硬币的概率就一定是正面的概率是0.7，反面的概率是0.3呢？</p><p>这么想很符合我们的直觉，但这并不是一件板上钉钉的事情。</p><p>你可以想一下，假如说，我们的硬币是正反概率都是0.5的话，你抛10次，难道就真的能保证一定是5次正、5次反吗？不一定吧，出现6正4反，4正6反也还是挺常见的吧。更甚者，运气好到极点，10次全部是正面也是有可能的。</p><p>那么，当我们不知道硬币正反概率的时候，7正3反，就一定0.7的概率吗？也不一定，对吧。完全有可能是，硬币的概率是0.1正、0.9反，但是运气就是很好，抛出了7正3反的结果。或者是，概率本来是0.8正、0.2反，但是运气就差那么一点，抛出了7正3反。</p><p><img src="./bacfcc010cdd58ecb38063d4ee08b6153b150c0a.png@942w_567h_progressive.png" /></p><p>也就是说，我们知道抛硬币的结果（抽样结果），我们没有办法唯一确定一个真实的概率（背后的规律）。就像前面看到的，7正3反的硬币结果，没有办法排除掉任何一种概率，它们都有可能。</p><p>不过，虽然我们没有办法百分百确定样本背后的概率分布原本是什么样子的，但是我们还是可以确定，最有可能情况是什么。</p><p>比如，<span class="math inline">\(C_1\)</span>~<span class="math inline">\(C_{10}\)</span>代表着10次抛硬币的结果，<span class="math inline">\(\theta\)</span>是硬币决定正反概率的属性（这个属性是未知的；也可以直接理解为硬币固有的概率属性），那么抛10次硬币有7次是正面对应的概率就是等号右边这么多。 <span class="math display">\[P\left(C_1, C_2, C_3, \cdots, C_{10}\,|\, \theta\right)=\binom{10}{7}\prod_{i=1}^{10}P\left(C_i\,|\,\theta\right)\]</span> 有了这个式子之后，我们就可以算出来，如果硬币抛出来正面朝上的概率分别是0.1、0.7和0.8的时候，要想得到抛10次硬币7次朝上的概率分布是多少。</p><p><img src="./4ab09f469008f93a1341e23ac2e8751e2a68c27f.png@942w_572h_progressive.png" /></p><p>大家算一下就知道，显然当正面概率是0.7的时候，发生的概率是最大的。</p><p>所以，我们直觉上觉得抛10次硬币7次正面，硬币的概率应该是0.7，不是没有根据的，这种情况与其他的情况想比，的确是可能性最大的。其实对于任何已经知道了样本，想要反推背后的概率分布，都可以用类似的思路。这种思路，虽然没有办法百分百的知道真实的情况是什么，但是显然猜0.7是正面，这样的正确的可能性最大。对应到深度学习里面也一样，也是已知了一堆样本数据，目的是想办法反推出生成样本数据的真实概率分布。虽然没有办法百分百确定是哪一个，但是我们还是有办法确定哪一个的可能性最大。</p><p>而这个思路，就是最大似然估计法的思路，其中的“最大”这个词，对应的就是前面说的可能性最大。至于为什么是似然值，而不是概率值，这个就用解释一下似然值和概率值的区别了。</p><h3 id="似然和概率有什么不一样">“似然”和“概率”有什么不一样</h3><p>什么是似然值？首先，它也是用来表示可能性的，但是它又和概率描述的问题不一样。就比如，<span class="math inline">\(C\)</span>代表了硬币是正还是反，<span class="math inline">\(\theta\)</span>是硬币决定正反概率的属性。 <span class="math display">\[P\left(C\, | \,\theta\right)\]</span> 这是一个概率分布的前提是，<span class="math inline">\(C\)</span>是随机变量。随机变量是什么意思呢？其实就是在说，当<span class="math inline">\(\theta\)</span>是一个固定值的时候，把所有<span class="math inline">\(C\)</span>的可能取值都考虑进来，把它们对应的概率值加起来，最后的结果是归一的。 <span class="math display">\[\sum_{x\in All}P\left(C = x\,|\,\theta=a\right)=1\]</span> 但是我们可以想一下，在前面我们的问题是什么？我们面临的问题是，<span class="math inline">\(C\)</span>是一个确定的值（也就是样本已经确定了），未知的是<span class="math inline">\(\theta\)</span>。<span class="math inline">\(\theta\)</span>是一个条件，它不是随机变量，也就是说如果把全部<span class="math inline">\(\theta\)</span>的取值都考虑进来，它并不要求满足归一。也就是下式不一定等于1。 <span class="math display">\[\sum_{x\in All}P\left(C = b\,|\,\theta=x\right)\neq1\]</span> 了解这些之后，我们应该就能明白了，如果我们设计一个函数，它的变量是<span class="math inline">\(\theta\)</span>： <span class="math display">\[\mathscr{L}\left(\theta\right)=P\left(C\,|\,\theta\right)\]</span> 这个L函数的结果，虽然还是一个概率值，也能表示某个事件发生的可能性，但是它又和概率分布的概率不太一样。概率如果写成函数的话，变量一定是随机变量才对，而这里变量是条件。</p><p>而我们在已知某个抽样结果后，反推那种情况的可能性最大，其实就是在求这个L函数的最大值。</p><p>至于这个函数呢？因为和概率表达意义不同，所以就被赋予了一个新的名字，似然函数。我们说的最大似然估计法，其实就是在说，要求出似然函数的最大值，这个最大值对着的就是最有可能的规律。</p><h3 id="最大似然估计法为什么要写成这个样子">“最大似然估计法”为什么要写成这个样子</h3><p>最大似然估计法到底是什么意思，我们已经知道了，剩下的就是神经网络里面的最大似然法为什么写出来是这个样子的。 <span class="math display">\[\mathscr{L}\left(\hat{y}, y\right) = -\left(y\log\hat{y} + \left(1-y\right)\log\left(1-\hat{y}\right)\right)\]</span> 我们先来看一下前面的抛硬币的例子。在这个例子里面，我们已经知道了抛硬币的结果，求原本的硬币概率是多少。如果把抛硬币的例子和神经网络对应起来的话，抛硬币的结果对应的就是已经有的数据集<span class="math inline">\(\left&lt;x_i,\,y_i\right&gt;\)</span>，求硬币的概率<span class="math inline">\(\theta\)</span>对应到神经网络里面就是求所有的参数<span class="math inline">\(W,\,b\)</span>。</p><p>有了这个对应之后，我们就比较容易思考了，于是就有如下：</p><p><img src="./2eddf21423ed4fc545d7a150c5e507473c817487.jpg@942w_531h_progressive.jpg" /></p><p>经过上面的整理之后，就得到了似然函数的表达式了。我们的目标，也就是最接近真实规律的神经网络的参数<span class="math inline">\(\left(W,\,b\right)\)</span>，其实就是求上式在取得最大值时<span class="math inline">\(W,\,b\)</span>分别等于什么。</p><p>(在求最大值的时候灰色部分是可以忽略的。特别是P(xi)，这是因为我们默认数据集是优质的数据集，数据集里的图片都是相互独立的，而且应该是等概率的。如果这部分有问题，那就需要重新整理数据集，让数据集尽可能满足这个条件。)</p><p><img src="./ae305c47cc4014af3104a0a4dabc3db2de9f4e1b.jpg@942w_531h_progressive.jpg" /></p><p>通过上面的推导，就可以看出来了，为什么吴恩达老师的最大似然估计法的式子要写成那个样子了。</p><h3 id="最小二乘法可以等价于最大似然估计法">“最小二乘法”可以等价于“最大似然估计法”</h3><p>本来，讲到这里，最开始我们所有的问题就都已经解决了。不论是是最小二乘法，还是极大似然估计法，它们其实都是用来比较神经网络猜测的那个规律和真实的规律的方法。</p><p>最小二乘法认为，当所有的误差的平方值最小时，神经网络里面猜测的规律与真实的规律最接近。最大似然估计法则认为，当似然值最大的时候，猜测的规律与真实的规律最接近。</p><p>如果就是这么看的话，最小二乘法好像和极大似然估计法是两套不想干的判断标准，最后选择哪个好像就是一个偏好问题。</p><p>但其实如果对最小二乘法的本质有所了解的话，就会发现从某种程度上来说，最小二乘法与最大似然估计在底层是相通的。</p><p>为什么这么说呢？</p><p>我们可以看看最小二乘法最后求出来的最值是什么。为了简化问题，我们把Y当做变量，代表不同<span class="math inline">\(W,\,b\)</span>下神经网络得出的判断结果。这样的话，损失函数就可以写成： <span class="math display">\[J\left(Y\right) = \sum_{i=1}^n\frac{1}{2}\left(Y-y_i\right)^2\]</span> 当损失函数取值最小的时候，<span class="math inline">\(Y\)</span>等于什么，我们可以通过求导的方式求出来，因为<span class="math inline">\(J\)</span>函数最小值的时候，导数一定为0。于是就有： <span class="math display">\[\frac{\mathrm{dJ} }{\mathrm{d} x} = 0 \\\Rightarrow \sum_{i=1}^n\left(Y-y_i\right) = 0\\\Rightarrow Y = \frac{\sum_{i=1}^ny_i}{n}\hspace{7mm}\\\Rightarrow Y = \bar{y}\hspace{23mm}\]</span> 从这里就可以看出来，当<span class="math inline">\(Y\)</span>等于所有<span class="math inline">\(y_i\)</span>的平均值时得到最小值。</p><p>如果只是进行到这一步的话，我们还什么都看不出来。但是我们还可以把<span class="math inline">\(Y-y_i\)</span>看做是神经网络的判断结果与真实结果的误差，也就是： <span class="math display">\[\varepsilon = Y - y_i\]</span> 那么我们是可以把数据集里每个数据对应的<span class="math inline">\(\varepsilon\)</span>看做抽样结果，也就相当于前面抛硬币例子里面7正3反的结果。这样的话，我们其实是可以利用最大似然估计法的。(注意这里用最大似人估计法时，随机变量是误差<span class="math inline">\(\varepsilon\)</span>，而前面用最大似然估计法的时候随机变量是判断结果<span class="math inline">\(y_i\)</span>，这还是有些不一样的。)</p><p>利用最大似然估计法的话，可以得到似然函数如下: <span class="math display">\[L(Y) = P\left(\varepsilon_1,\varepsilon_2,\cdots,\varepsilon_n\,|\,Y\right)\\=\prod_{i=1}^{n}P(Y-y_i)\hspace{1mm}\]</span> 求最大值，其实就是下面的函数对<span class="math inline">\(Y\)</span>求导等于0： <span class="math display">\[\frac{\mathrm{dL} }{\mathrm{d} Y} = 0\]</span> 具体这里的最大值求出来是多少我们先放一下，但是在前面我们已经知道，用最小二乘法已经求出来了，当Y等于yi的平均值时，是我们的目标。而最小二乘法和极大似然估计法，它们虽然用到了不同的思路，但都是在解决同一个问题，那我们是不是可以认为，它们其实是殊途同归的，最后的答案都是<span class="math inline">\(Y\)</span>应该等于<span class="math inline">\(y_i\)</span>的平均值。</p><p>如果真的可以做出这样的假设的话，那把平均值这个答案带到最大似然估计法里面，就可以去反推一下这个概率分布是什么样子的了。带进去之后，就会发现，这个概率分布的概率密度函数如下： <span class="math display">\[f\left(\varepsilon\right)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{\varepsilon^2}{2\sigma^2}}\]</span> 这是什么？这就是正态分布啊。</p><p>于是最小二乘法和最大似然估计法的关系就变成了这样：如果我们认定神经网络得到的结果与真实情况的误差，是属于正态分布的话，那么最小二乘法与极大似然估计法是等价的。</p><p>我们都知道正态分布最开始是被高斯最先提出来的，他提出来的思路是什么？虽然细节上可能会有差别，但是大体上他就是做了类似的思考，也就是认为最小二乘法和极大似然估计法应该殊途同归，然后计算得出了正态分布的表达式。</p><p>所以，最小二乘法和极大似然估计法，虽然形式上非常不同，但是它们本质上还是相通的。只不过，最小二乘法比极大似然估计法多了一个前提，那就是它要求误差的分布属于正态分布，只有这样的时候，最小二乘法和极大似然估计法才是等价的。</p><p>其实，最大似然估计法很多人也把它称为交叉熵法，这是因为极大似然估计法和交叉熵方法是彻彻底底的等价，而不是最小二乘法这种有条件的等价。</p><h3 id="references">References</h3><p>https://www.bilibili.com/read/cv14977249?spm_id_from=333.999.0.0</p><p>https://www.bilibili.com/video/BV1Y64y1Q7hi?spm_id_from=333.999.0.0</p><p>https://www.bilibili.com/video/BV1FT4y1E74V?from=search&amp;seid=1554295885016367140&amp;spm_id_from=333.337.0.0</p><hr /><p><strong><em>知识来源作者为b站UP主王木头学科学</em></strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>神经网络</tag>
      
      <tag>损失函数</tag>
      
      <tag>机器学期</tag>
      
      <tag>最小二乘法</tag>
      
      <tag>极大似然估计</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>卷积神经网络模型</title>
    <link href="/2021/12/04/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"/>
    <url>/2021/12/04/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h3 id="卷积神经网络lenet">卷积神经网络（LeNet)</h3><p><img src="https://miro.medium.com/max/1400/1*1TI1aGBZ4dybR6__DI9dzA.png" /></p><p><strong>模型结构</strong>：卷积层块， 全链接层块</p><ul><li>卷积层块：2个<strong>卷积层 + 最大池化层</strong> 的结构组成。 由于LeNet是较早的CNN， 在每个卷积层 + 池化层后多会跟一个sigmod层 来修正输出结果。 而现在用的较多的是Relu。</li><li>全连接层块：输入为二维向量。 单卷积层块的输出传入全连接层的时候会对小批量对每个样本进行扁平化（flatten）</li></ul><p>LeNet 会随着网络的加深，宽度逐渐降低，通道逐渐增多。</p><h3 id="深度卷积神经网络alexnet">深度卷积神经网络（AlexNet）</h3><h3 id="section"><img src="https://www.researchgate.net/publication/320052364/figure/fig1/AS:543136445198336@1506505227088/Scheme-of-the-AlexNet-network-used.png" /></h3><p><strong>模型结构</strong>：5层卷积 + 2层全连接隐藏层 + 1层全连接输出层</p><ul><li>卷积层： 前2个用的分别是11x11和5x5的卷积核，其余的都是3x3的卷积核。 第一， 第二， 第五个卷积层后都使用了3x3，步幅为2 的最大池化层。</li><li>全连接层：2个输出个数为4096的全连接层携带着将近1GB的模型参数。</li><li>激活函数：AlexNet使用了Relu激活函数。相比于sigmod，Relu有着更简单的计算并且在不同初始化的情况下更容易训练。例如在一些特殊初始化下， sigmod在正区间的输出极度接近0， 这会导致模型很难继续更新，而Relu在正区间的值恒为1。</li><li>过拟合：AlexNet使用了丢弃法来控制模型复杂度和防止过拟合。并且它用了大量的图象增广， 包括翻转， 裁剪， 改变颜色等，来进一步防止过拟合。</li></ul><h3 id="使用重复元素的网络vgg">使用重复元素的网络（VGG）</h3><p><img src="https://www.researchgate.net/profile/Max-Ferguson/publication/322512435/figure/fig3/AS:697390994567179@1543282378794/Fig-A1-The-standard-VGG-16-network-architecture-as-proposed-in-32-Note-that-only.png" /></p><p><strong>模型结构</strong>：VGG块 + 全连接层块</p><ul><li>VGG块：卷积层 + 池化层， 卷积层都是用相通的填充为1，3x3的卷积核接上一个步幅为2 ， 窗口为2x2的最大池化层</li><li>全连接层块：与LeNet相似</li></ul><p>VGG是个十分对称的网络，每层都成倍的增加或者减少。相比AlexNet它提供了一种简单固定的卷积模型和深度模型的构建思路。</p><h3 id="网络中的网络nin">网络中的网络（NiN）</h3><p><img src="https://miro.medium.com/max/1400/1*fWGsLkUnDaWz7KbIlRt9Hg.png" /></p><p><strong>模型结构</strong> ： NiN块</p><ul><li>NiN块：AlexNet是用多个卷积层 + 全连接层输出的结构，NiN提出了另一种思路， 它通过将小块<strong>卷积层+“全连接”层</strong>串联组成网络。由于全连接层是二维而卷积层通常来说是四维的， 所以NiN块使用1x1的卷积层代替全连接层（期中空间维度（高宽）上的每一个元素相当于样本，通道相当于特征）。每个卷积层与AlexNet类似，都是11x11， 5x5， 3x3.并且每个NiN块后接一个步幅为2，窗口大小为3x3的最大池化层。</li></ul><p>相比AlexNet，NiN去掉了最后3个全连接层，使用输出通道等于标签类别的NiN块， 然后使用全局平局池化层对每个通道中所有元素求平均并直接用于分类。 这个好处是可以显著减小模型参数尺寸， 但会造成训练时间的增加。</p><h3 id="含有并行连接的网络googlenet">含有并行连接的网络（GoogLeNet）</h3><p><img src="https://pytorch.org/assets/images/googlenet1.png" /></p><ul><li>Inception块：GoogLeNet的基础块，它借鉴NiN的网络串联网络的思路。 在每个Inception块中包含4条并行线路。前3条分别使用1x1， 3x3， 5x5的卷积层来抽取不通空间尺度下的特征信息， 期中第二三条线中先使用了1x1的卷积层来减少输入通道数，以降低模型复杂度。 最后一条使用3x3的最大池化层接1x1的卷积层来改变通道数。4条线都适用合适的填充来保证输入和输出的高宽一致。</li></ul><p><img src="https://miro.medium.com/max/2542/1*rXcdL9OV5YKlYyks9XK-wA.png" /></p><h3 id="残差网络resnet">残差网络（ResNet)</h3><p><img src="https://d2l.ai/_images/resnet-block.svg" /></p><ul><li>残差块：一般来说对于激活函数的输入是神经网络一层层的计算的输出结果，但是由于网络的不断加深容易出现梯度不稳定（梯度爆炸，梯度消失）。随着网络的逐渐加深，误差并不会越来越小残差块的目的就是为了解决梯度不稳定。 它通过一种跳跃的连接方式让输出结果需要参考输入结果。</li></ul><p><img src="https://miro.medium.com/max/874/1*R-Yzqn6VLmIyITO3ZxA1sQ.png" /></p><ul><li>残差块原理：<span class="math inline">\(a^{[l+2]}=g(z^{[l+2]}+a^{[l]})=g(w^{[l+2]}a^{[l+1]} + b^{[l+2]}a^{[l]})\)</span> 我们现在不考虑 <span class="math inline">\(b^{[l+2]}\)</span>, 当发生梯度消失的时候， <span class="math inline">\(w^{[l+2]}=0\)</span>, 此时<span class="math inline">\(a^{[l+2]}=g(a^{[l]})\)</span>, 相当于把第一层的输出直接经过Relu输出。并不会因为梯度消失产生负面的影响。</li></ul><h3 id="稠密连接网络densenet">稠密连接网络（DenseNet）</h3><p><img src="https://pytorch.org/assets/images/densenet1.png" /></p><p><strong>模型结构</strong>：稠密层 + 过渡层</p><ul><li>稠密层：DenseNet和ResNet十分相似，区别在于DenseNet不像ResNet将前一个模块的输出直接加到模块的输出上而是直接在通道上进行叠加</li><li>过渡层：为了防止通道数一直叠加导致模型复杂度过大，过渡层通过使用1x1的卷积层减小通道数，并使用步幅为2的平均池化层减半高宽进一步降低复杂度。</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kaggle--图像分类(CIFAR-10) 基于Pytorch的实现</title>
    <link href="/2021/08/29/Kaggle%20-%20%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB(CIFAR-10)/"/>
    <url>/2021/08/29/Kaggle%20-%20%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB(CIFAR-10)/</url>
    
    <content type="html"><![CDATA[<blockquote><p>CIFAR-10 是计算机视觉领域中一个非常重要的数据集. 它由Hinton的学生Alex Krizhevsky 和 Ilya Sutskever整理的小型数据集. 其中包括 10 个不同类别的RGB 3通道 32 * 32 的图像: 飞机 (airplane)、汽车 (automobile)、鸟类 (bird)、猫 (cat)、鹿(deer)、狗(dog)、蛙类(frog)、马(horse)、船(ship) 和卡车 (truck). 我们可以直接从Kaggle官网获得数据集 https://www.kaggle.com/c/cifar-10. 其中包含一个test文件和train文件. test 文件中有60000张图像, 每个类各有6000张. train文件中包含300000万张图像, 其中只有10000张作为测试, 省下的是Kaggle为了防止人工标记数据集的额外数据.</p></blockquote><h2 id="整理数据集">1. 整理数据集</h2><p>首先我们先导入一些必要的库</p><figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> shutil<br><span class="hljs-keyword">import</span> collections<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> models<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>data_dir = <span class="hljs-string">&quot;C:\\Users\\***\\OneDrive\\桌面\\kaggle\\CIFAR-10&quot;</span><br></code></pre></td></tr></table></figure><p>我们需要对数据集进行整理以一遍训练和测试使用. 函数<strong>read_labels</strong>用来读取训练集的标签文件并以 <strong>name: label</strong> 的字典形式储存.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_labels</span>(<span class="hljs-params">file</span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        lines = f.readlines()[<span class="hljs-number">1</span>:]<span class="hljs-comment">#从1开始读是为了排除文件的title行</span><br>    tokens = [l.rstrip().split(<span class="hljs-string">&#x27;,&#x27;</span>) <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">dict</span>((name, label) <span class="hljs-keyword">for</span> name, label <span class="hljs-keyword">in</span> tokens)<br></code></pre></td></tr></table></figure><p>我们使用一种非常常规的数据处理方法将文件每个标签作为一个文件夹储存对应的图片, 但这种方法并不高效, 我们相当于把所有图片copy了一次, 当数据量非常大到时候这个方法可能会过于耗时.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">copyfile</span>(<span class="hljs-params">filename, target_dir</span>):<span class="hljs-comment">#将图片复制到对应文件夹, 如果文件夹不存在则创建文件夹</span><br>    os.makedirs(target_dir, exist_ok=<span class="hljs-literal">True</span>)<br>    shutil.copy(filename, target_dir)<br></code></pre></td></tr></table></figure><p>下面我们对所有图片进行reorganize, 其中valid_ratio是验证集样本和原始数据集样本的比 (我们需要把数据急分成两部分一部分用作验证一部分用作训练, 由于数据量并不是很小所以不需要做k折交叉验证). 让我们以 valid_ratio=0.1 为例，由于原始的训练集有 50000 张图像，因此 train_valid_test/train 路径中将有 45000 张图像⽤ 于训练，而剩下 5000 张图像将作为路径 train_valid_test/valid 中的验证集。组织数据集后，同类别的图像将被放置在同⼀⽂件夹下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">reorg_train_valid</span>(<span class="hljs-params">data_dir, labels, valid_ratio</span>):<br>    n = collections.Counter(labels.values()).most_common()[-<span class="hljs-number">1</span>][<span class="hljs-number">1</span>]<span class="hljs-comment">#每一个标签的数量</span><br>    n_valid_per_label = <span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>, math.floor(n * valid_ratio))<span class="hljs-comment">#验证集中每个标签的数量</span><br>    label_count = &#123;&#125;<br>    <span class="hljs-keyword">for</span> train_file <span class="hljs-keyword">in</span> os.listdir(os.path.join(data_dir, <span class="hljs-string">&#x27;train&#x27;</span>)):<br>        label = labels[train_file.split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>]]<br>        filename = os.path.join(data_dir, <span class="hljs-string">&#x27;train&#x27;</span>, train_file)<br>        copyfile(filename, os.path.join(data_dir, <span class="hljs-string">&#x27;train_valid_test&#x27;</span>, <span class="hljs-string">&#x27;train_valid&#x27;</span>, label))<br>        <span class="hljs-keyword">if</span> label <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> label_count <span class="hljs-keyword">or</span> label_count[label] &lt; n_valid_per_label:<br>            copyfile(filename, os.path.join(data_dir, <span class="hljs-string">&#x27;train_valid_test&#x27;</span>, <span class="hljs-string">&#x27;valid&#x27;</span>, label))<br>            label_count[label] = label_count.get(label, <span class="hljs-number">0</span>) + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">else</span>:<br>            copyfile(filename, os.path.join(data_dir, <span class="hljs-string">&#x27;train_valid_test&#x27;</span>, <span class="hljs-string">&#x27;train&#x27;</span>, label))<br>    <span class="hljs-keyword">return</span> n_valid_per_label<br></code></pre></td></tr></table></figure><p>然后我们再定义一个函数对测试集进行整理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">reorg_test</span>(<span class="hljs-params">data_dir</span>):<br>    <span class="hljs-keyword">for</span> test_file <span class="hljs-keyword">in</span> os.listdir(os.path.join(data_dir, <span class="hljs-string">&#x27;test&#x27;</span>)):<br>        copyfile(os.path.join(data_dir, <span class="hljs-string">&#x27;test&#x27;</span>, test_file),<br>                 os.path.join(data_dir, <span class="hljs-string">&#x27;train_valid_test&#x27;</span>, <span class="hljs-string">&#x27;test&#x27;</span>, <span class="hljs-string">&#x27;unknown&#x27;</span>))<br>      <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">reorg_CIFAR10</span>(<span class="hljs-params">data_dir, valid_ratio</span>):<br>    labels = read_labels(os.path.join(data_dir, <span class="hljs-string">&#x27;trainLabels.csv&#x27;</span>))<br>    reorg_train_valid(data_dir, labels, valid_ratio)<br>    reorg_test(data_dir)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size = <span class="hljs-number">128</span><br>valid_ratio = <span class="hljs-number">0.1</span><span class="hljs-comment"># 10% 的训练集数据作为验证集</span><br>reorg_CIFAR10(data_dir, valid_ratio)<br></code></pre></td></tr></table></figure><h2 id="图像增广">2. 图像增广</h2><p>为了防止过拟合我们对图像进行增强, 由于测试集只用作测试所以我们字对其做标准化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">transform_train = torchvision.transforms.Compose([<br>    torchvision.transforms.Resize(<span class="hljs-number">40</span>),<span class="hljs-comment"># 这里吧图像放大到 40*40 后在按比例取32*32是为了取局部特征</span><br>    torchvision.transforms.RandomResizedCrop(<span class="hljs-number">32</span>, scale=(<span class="hljs-number">0.64</span>, <span class="hljs-number">1.0</span>), ratio=(<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>)),<br>    torchvision.transforms.RandomHorizontalFlip(),<span class="hljs-comment"># 垂直翻转</span><br>    torchvision.transforms.RandomVerticalFlip(),<span class="hljs-comment"># 水平翻转</span><br>    torchvision.transforms.ToTensor(),<br>    torchvision.transforms.Normalize([<span class="hljs-number">0.4914</span>, <span class="hljs-number">0.4822</span>, <span class="hljs-number">0.4465</span>], [<span class="hljs-number">0.2023</span>, <span class="hljs-number">0.1994</span>, <span class="hljs-number">0.2010</span>]),<br>    torchvision.transforms.ColorJitter(brightness=<span class="hljs-number">0.5</span>, contrast=<span class="hljs-number">0.5</span>, saturation=<span class="hljs-number">0.5</span>, hue=<span class="hljs-number">0.5</span>) <span class="hljs-comment"># 百分之五十的概率对曝光, 对比度, 饱和度, 色调进行变换</span><br>])<br><br>transform_test = torchvision.transforms.Compose([<br>    torchvision.transforms.ToTensor(),<br>    torchvision.transforms.Normalize([<span class="hljs-number">0.4914</span>, <span class="hljs-number">0.4822</span>, <span class="hljs-number">0.4465</span>], [<span class="hljs-number">0.2023</span>, <span class="hljs-number">0.1994</span>, <span class="hljs-number">0.2010</span>])<br>])<br></code></pre></td></tr></table></figure><h2 id="读取数据集">3. 读取数据集</h2><p>接下来问他们用torchvision.datasets.ImageFolder实例来读取不同的数据集包括每张图片的标签.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">train_ds, train_valid_ds = [<br>    torchvision.datasets.ImageFolder(<br>        os.path.join(data_dir, <span class="hljs-string">&#x27;train_valid_test&#x27;</span>, folder),<br>        transform=transform_train<br>    ) <span class="hljs-keyword">for</span> folder <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;train&#x27;</span>, <span class="hljs-string">&#x27;train_valid&#x27;</span>]<br>]<br><br>valid_ds, test_ds = [<br>    torchvision.datasets.ImageFolder(<br>        os.path.join(data_dir, <span class="hljs-string">&#x27;train_valid_test&#x27;</span>, folder),<br>        transform=transform_test<br>    ) <span class="hljs-keyword">for</span> folder <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;valid&#x27;</span>, <span class="hljs-string">&#x27;test&#x27;</span>]<br>]<br></code></pre></td></tr></table></figure><p>使用DataLoader对数据进行图像增广的操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">train_iter, train_valid_iter = [<br>    DataLoader(<br>        dataset, batch_size, shuffle=<span class="hljs-literal">True</span>, drop_last=<span class="hljs-literal">True</span><span class="hljs-comment"># drop last现在可有可无</span><br>    ) <span class="hljs-keyword">for</span> dataset <span class="hljs-keyword">in</span> (train_ds, train_valid_ds)<br>]<br><br>valid_iter = DataLoader(valid_ds, batch_size, shuffle=<span class="hljs-literal">False</span>, drop_last=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">4</span>)<br>test_iter = DataLoader(test_ds, batch_size, shuffle=<span class="hljs-literal">False</span>, drop_last=<span class="hljs-literal">False</span>, num_workers=<span class="hljs-number">4</span>)<br><span class="hljs-comment"># num_workers 使用多线程运行</span><br></code></pre></td></tr></table></figure><h2 id="定义模型">4.定义模型</h2><p>这里我们使用models 模块中的resnet50模型, 对于CIAFAR-10我们从头训练不使用迁移学习. 但我们需要讲最后一层全连接层的输出改成我们需要的输出类别个数. 损失函数这里使用交叉熵误差.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_net</span>():<br>    num_classes = <span class="hljs-number">10</span><br>    net = models.resnet50(pretrained=<span class="hljs-literal">False</span>)<br>    net.fc = nn.Linear(models.resnet50().fc.in_features, num_classes)<br>    <span class="hljs-keyword">return</span> net<br><br>loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&quot;none&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="定义训练函数">5. 定义训练函数</h2><h3 id="辅助函数">辅助函数</h3><p>对象Accumulator 用于计算所有变量之和</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Accumulator</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;For accumulating sums over `n` variables.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n</span>):<br>        self.data = [<span class="hljs-number">0.0</span>] * n<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">self, *args</span>):<br>        self.data = [a + <span class="hljs-built_in">float</span>(b) <span class="hljs-keyword">for</span> a, b <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.data, args)]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reset</span>(<span class="hljs-params">self</span>):<br>        self.data = [<span class="hljs-number">0.0</span>] * <span class="hljs-built_in">len</span>(self.data)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> self.data[idx]<br></code></pre></td></tr></table></figure><p>accuracy 用于计算预测正确的数量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">accuracy</span>(<span class="hljs-params">y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Compute the number of correct predictions.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(y_hat.shape) &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> y_hat.shape[<span class="hljs-number">1</span>] &gt; <span class="hljs-number">1</span>:<br>        y_hat = argmax(y_hat, axis=<span class="hljs-number">1</span>)<br>    cmp = astype(y_hat, y.dtype) == y<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>(reduce_sum(astype(cmp, y.dtype)))<br></code></pre></td></tr></table></figure><p>evaluation_acc 用于计算验证准确率</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_acc</span>(<span class="hljs-params">net, data_iter, device=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(net, nn.Module):<br>        net.<span class="hljs-built_in">eval</span>()<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> device:<br>            device = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(net.parameters())).device<br><br>    metric = Accumulator(<span class="hljs-number">2</span>)<br><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(X, <span class="hljs-built_in">list</span>):<br>                X = [x.to(device) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X]<br>            <span class="hljs-keyword">else</span>:<br>                X = X.to(device)<br>            y = y.to(device)<br>            metric.add(accuracy(net(X), y), size(y))<br>    <span class="hljs-keyword">return</span> metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure><p>train_batch 用于对每个batch进行训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_batch</span>(<span class="hljs-params">net, feature, label, loss, optimizer, device</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(feature, <span class="hljs-built_in">list</span>):<br>        feature = [x.to(device) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> feature]<br>    <span class="hljs-keyword">else</span>:<br>        feature = feature.to(device)<br>    loss = loss.to(device)<br>    net.train()<br>    net.cuda()<br>    label = label.cuda(<span class="hljs-number">0</span>)<br>    optimizer.zero_grad()<br>    pred = net(feature)<br>    l = loss(pred, label)<br>    l.<span class="hljs-built_in">sum</span>().backward()<br>    optimizer.step()<br>    train_loss_sum = l.<span class="hljs-built_in">sum</span>()<br>    train_acc_sum = (pred.argmax(dim=<span class="hljs-number">1</span>) == label).<span class="hljs-built_in">sum</span>().item()<br>    <span class="hljs-keyword">return</span> train_loss_sum, train_acc_sum<br></code></pre></td></tr></table></figure><h3 id="定义训练函数-1">定义训练函数</h3><p>接下来我们定义train函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">net, train_iter, valid_iter, num_epochs, lr, wd, device, lr_period, lr_decay</span>):<br>    output_params = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">id</span>, net.fc.parameters()))<br>    feature_params = <span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> p: <span class="hljs-built_in">id</span>(p) <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> output_params, net.parameters())<br>    optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=wd)<br>    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_period, lr_decay)<br>    num_batches = <span class="hljs-built_in">len</span>(train_iter)<br>    legend = [<span class="hljs-string">&#x27;train loss&#x27;</span>, <span class="hljs-string">&#x27;train acc&#x27;</span>]<br>    <span class="hljs-keyword">if</span> valid_iter <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        legend.append(<span class="hljs-string">&#x27;valid acc&#x27;</span>)<br>    net.cuda()<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        start = time.time()<br>        net.train()<br>        metric = Accumulator(<span class="hljs-number">3</span>)<br>        <span class="hljs-keyword">for</span> i, (feature, label) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_iter):<br>            l, acc = train_batch(net, feature, label, loss, optimizer, device)<br>            metric.add(l, acc, label.shape[<span class="hljs-number">0</span>])<br>        <span class="hljs-keyword">if</span> valid_iter <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            valid_acc = evaluate_acc(net, valid_iter, device)<br>        scheduler.step()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span>&#x27;</span> + <span class="hljs-string">f&#x27;train loss <span class="hljs-subst">&#123;metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">2</span>]:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span> + <span class="hljs-string">f&#x27;train acc <span class="hljs-subst">&#123;metric[<span class="hljs-number">1</span>] / metric[<span class="hljs-number">2</span>]:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span> + <span class="hljs-string">f&#x27; time: <span class="hljs-subst">&#123;time.time() - start&#125;</span> sec&#x27;</span>)<br>    measures = (<span class="hljs-string">f&#x27;train loss <span class="hljs-subst">&#123;metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">2</span>]:<span class="hljs-number">.3</span>f&#125;</span>, &#x27;</span><br>                <span class="hljs-string">f&#x27;train acc <span class="hljs-subst">&#123;metric[<span class="hljs-number">1</span>] / metric[<span class="hljs-number">2</span>]:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br>    <span class="hljs-keyword">if</span> valid_iter <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        measures += <span class="hljs-string">f&#x27;, valid acc <span class="hljs-subst">&#123;valid_acc:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span><br>    <span class="hljs-built_in">print</span>(measures + <span class="hljs-string">f&#x27; examples/sec on <span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(device)&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="训练模型">6. 训练模型</h2><p>我们开始对模型进行训练, 这里使用GPU训练, 并且lr_period, lr_decay我们设置为4, 0.9, 意味着每4个周期学习率自乘0.9</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">device, num_epochs, lr, wd = <span class="hljs-string">&#x27;cuda&#x27;</span>, <span class="hljs-number">100</span>, <span class="hljs-number">2e-4</span>, <span class="hljs-number">5e-4</span><br>lr_period, lr_decay, net = <span class="hljs-number">4</span>, <span class="hljs-number">0.9</span>, get_net()<br>train(net, train_iter, valid_iter, num_epochs, lr, wd, device, lr_period, lr_decay)<br></code></pre></td></tr></table></figure><h2 id="提交结果">7. 提交结果</h2><p>但我们训练出了满意的结果后我们使用设计好的超参数和训练好的模型对测试集重新训练并且对测试集进行分类提交.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">net, preds = get_net(), []<br>train(net, train_valid_iter, <span class="hljs-literal">None</span>, num_epochs, lr, wd, device, lr_period, lr_decay)<br><span class="hljs-keyword">for</span> X, _ <span class="hljs-keyword">in</span> test_iter:<br>    y_hat = net(X.to(device))<br>    preds.extend(y_hat.argmax(dim=<span class="hljs-number">1</span>).<span class="hljs-built_in">type</span>(torch.int32).cpu().numpy())<br>sorted_ids = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(test_ds) + <span class="hljs-number">1</span>))<br>sorted_ids.sort(key=<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">str</span>(x))<br>df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;id&#x27;</span>: sorted_ids, <span class="hljs-string">&#x27;label&#x27;</span>: preds&#125;) <span class="hljs-comment"># 此为Kaggle要求格式</span><br>df[<span class="hljs-string">&#x27;label&#x27;</span>] = df[<span class="hljs-string">&#x27;label&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: train_valid_ds.classes[x])<br>df.to_csv(<span class="hljs-string">&#x27;C:\\Users\\***\\OneDrive\\桌面\\kaggle\\CIFAR-10\\submission.csv&#x27;</span>, index=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>最终我们会得到一个submission.csv文件我们就可以把他上传到Kaggle啦.</p><h2 id="references">References</h2><p>https://tangshusen.me/Dive-into-DL-PyTorch/#/</p><p>https://zh-v2.d2l.ai/</p><p>https://github.com/d2l-ai/d2l-zh</p><p>https://pytorch.org/docs/stable/index.html</p><p>https://blog.csdn.net/mao_hui_fei/article/details/89477938</p>]]></content>
    
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ggplot2 cheat sheet (转载)</title>
    <link href="/2021/05/11/ggplot2-cheat-sheet-%E8%BD%AC%E8%BD%BD/"/>
    <url>/2021/05/11/ggplot2-cheat-sheet-%E8%BD%AC%E8%BD%BD/</url>
    
    <content type="html"><![CDATA[<p><img src= "https://i.loli.net/2021/05/11/L8SQ9tZkW7YdRX4.png"></p><p><img src="https://i.loli.net/2021/05/11/6LzuwcQAZnqlDfg.png"></p><h2 id="reference">reference</h2><p>https://www.rstudio.com/resources/cheatsheets/</p>]]></content>
    
    
    
    <tags>
      
      <tag>ggplot2</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>R语言 dnorm, pnorm, qnorm, rnorm的区别</title>
    <link href="/2021/05/09/R%E8%AF%AD%E8%A8%80-dnorm-pnorm-qnorm-rnorm%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <url>/2021/05/09/R%E8%AF%AD%E8%A8%80-dnorm-pnorm-qnorm-rnorm%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<h1 id="前言">前言</h1><p>dnorm, pnorm, qnorm, rnorm 是R语言中常用的正态分布函数. <strong>norm</strong> 指的是正态分布(也可以叫高斯分布(<strong>normal distribution</strong>)), R语言中也有其他不同的分布操作也都类似. <strong>p q d r</strong> 这里分别指的是不同的函数下面将会详细简介这不同函数在正态分布中的应用以及这是个命令在R中如何使用.</p><h2 id="dnorm">dnorm</h2><p><strong>d</strong> - 指的是概率密度函数(probability density function)</p><p>正态分布的公式: <span class="math display">\[f(x|\mu, \sigma)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}\]</span> <img src="https://i.loli.net/2021/05/09/oEpTxL26XQB7AFZ.png" width="75%"></p><p>dnorm实质上是正态分布概率密度函数值. 说人话就是返回上面这个函数的值.下面我们在代码中演示下:</p><figure class="highlight r"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><pre><code class="hljs R"><span class="hljs-comment"># 输出在标准正态分布下(mean = 0, standard deviation = 1) 0 的z-sore</span><br>dnorm<span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-punctuation">,</span> mean<span class="hljs-operator">=</span><span class="hljs-number">0</span><span class="hljs-punctuation">,</span> sd<span class="hljs-operator">=</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.3989423</span><br><span class="hljs-comment"># 因为是标准正态分布所以mean和sd是可以省略的</span><br>dnorm<span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.3989423</span><br><span class="hljs-comment"># 如果是一个非标准正态分布如下:</span><br>dnorm<span class="hljs-punctuation">(</span><span class="hljs-number">2</span><span class="hljs-punctuation">,</span> mean<span class="hljs-operator">=</span><span class="hljs-number">5</span><span class="hljs-punctuation">,</span> sd<span class="hljs-operator">=</span><span class="hljs-number">3</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.08065691</span><br></code></pre></td></tr></table></figure><h2 id="pnorm">pnorm</h2><p><strong>p</strong> - 指的是概率密度积分函数（从无限小到 x 的积分）(Probability density integral function)</p><p>x指的是一个z-score, 专业名词听着玄幻, 其实就是正态分布曲线下x左边的面积(概率占比), 我们知道z-score求在哪个分为数上</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs R"><span class="hljs-comment"># 标准正态分布</span><br>pnorm<span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.5 (50%)</span><br>pnorm<span class="hljs-punctuation">(</span><span class="hljs-number">2</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.9772499</span><br><span class="hljs-comment"># 非标准正态分布</span><br>pnorm<span class="hljs-punctuation">(</span><span class="hljs-number">2</span><span class="hljs-punctuation">,</span> mean<span class="hljs-operator">=</span><span class="hljs-number">5</span><span class="hljs-punctuation">,</span> sd<span class="hljs-operator">=</span><span class="hljs-number">3</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.1586553</span><br><span class="hljs-comment"># 也可以求x右边的概率</span><br>pnorm<span class="hljs-punctuation">(</span><span class="hljs-number">2</span><span class="hljs-punctuation">,</span> mean<span class="hljs-operator">=</span><span class="hljs-number">5</span><span class="hljs-punctuation">,</span> sd<span class="hljs-operator">=</span><span class="hljs-number">3</span><span class="hljs-punctuation">,</span> lower.tail<span class="hljs-operator">=</span><span class="hljs-literal">FALSE</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.81586553</span><br><span class="hljs-comment"># pnorm也能用来求置信区间</span><br>pnorm<span class="hljs-punctuation">(</span><span class="hljs-number">3</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">-</span> pnorm<span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.1573054</span><br></code></pre></td></tr></table></figure><p><img src="https://i.loli.net/2021/05/09/UunzrTedDcxh7Vf.png"></p><p>上图用R可以这么写</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs R">pnorm<span class="hljs-punctuation">(</span><span class="hljs-number">2</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.9772499</span><br></code></pre></td></tr></table></figure><h2 id="qnorm">qnorm</h2><p><strong>q</strong> - 指的是分位数函数(quantile function)</p><p>简单来说它就是pnorm的反函数, 通过百分比算z-score, 我知道分位数求z-score, 例如:</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs R"><span class="hljs-comment"># 在标准正态分布中求z-score</span><br>qnorm<span class="hljs-punctuation">(</span><span class="hljs-number">0.5</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0</span><br>qnorm<span class="hljs-punctuation">(</span><span class="hljs-number">0.96</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 1.750686</span><br>qnorm<span class="hljs-punctuation">(</span><span class="hljs-number">0.99</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 2.326348</span><br></code></pre></td></tr></table></figure><h2 id="rnorm">rnorm</h2><p><strong>r</strong> - 指的是随机数函数(random function)（常用于概率仿真）</p><p>它是用来生成一组符合正态分布的随机数, 例如:</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs R"><span class="hljs-comment"># 设置随机数种子</span><br>set.seed<span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span><br><span class="hljs-comment"># 生成5个符合标准正态分布的随机数</span><br>rnorm<span class="hljs-punctuation">(</span><span class="hljs-number">5</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078</span><br><span class="hljs-comment"># 生成10个mean=70, sd=5的正态分布随机数</span><br>rnorm<span class="hljs-punctuation">(</span><span class="hljs-number">10</span><span class="hljs-punctuation">,</span> mean<span class="hljs-operator">=</span><span class="hljs-number">70</span><span class="hljs-punctuation">,</span> sd<span class="hljs-operator">=</span><span class="hljs-number">5</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 65.89766 72.43715 73.69162 72.87891 68.47306 77.55891 71.94922 66.89380 58.92650 75.62465</span><br></code></pre></td></tr></table></figure><p>在R语言中生成别的各种分布也都是以d, p, q, r开头, 原理和正态分布相似</p><h2 id="references">references</h2><p>http://www.360doc.com/content/18/0913/18/19913717_786412696.shtml</p><p>https://www.runoob.com/r/r-basic-operators.html</p>]]></content>
    
    
    
    <tags>
      
      <tag>R</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hexo d部署报错之spawn failed的解决方案</title>
    <link href="/2021/05/09/Hexo%20d%E9%83%A8%E7%BD%B2%E6%8A%A5%E9%94%99%E4%B9%8Bspawn%20failed%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <url>/2021/05/09/Hexo%20d%E9%83%A8%E7%BD%B2%E6%8A%A5%E9%94%99%E4%B9%8Bspawn%20failed%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
    
    <content type="html"><![CDATA[<p>关于Hexo部署的时候报错导致无法推送到github估计是很多小伙伴第一次接触Hexo框架编写博客的常见问题, 下面介绍两种解决方案.</p><p><img src="https://i.loli.net/2021/05/09/fsRDw1AS2VpO35o.png"></p><h2 id="解决方案一">解决方案(一)</h2><ol type="1"><li>在博客文件夹(通常是***)中删除时 <strong>.deploy_git</strong> 文件</li><li>命令行(terminal)[不推荐使用<strong>cmd</strong>, 使用 <strong>git bash</strong> 等] 中输入 <code>git config --global core.autocrlf false</code>把git加入系统环境变量</li><li>重新执行<code>hexo c</code> <code>hexo g</code> <code>hexo d</code></li></ol><p>上Google百度一查大部分都是这种方法, xdm可以自己试试看万一成了呢. 但我下面推荐另一种可能的解决方案</p><h2 id="解决方案二">解决方案(二)</h2><ol type="1"><li><p>首先用文本编辑器(我使用的是Notepad++)打开博客文件夹(通常是***)中的 **_config.yml** 配置文件</p></li><li><p>修改配置文件中的<strong>repo</strong></p><figure class="highlight dts"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><pre><code class="hljs dts"><span class="hljs-meta"># Deployment</span><br><span class="hljs-meta">## Docs: https:<span class="hljs-comment">//hexo.io/docs/one-command-deployment</span></span><br><span class="hljs-symbol">deploy:</span><br><span class="hljs-symbol">  type:</span> git<br><span class="hljs-symbol">  repo:</span>https:<span class="hljs-comment">//github.com/YourName/YourName.github.io.git(不要使用这个)</span><br>  git@github.com:YourName/YourName.github.io.git(用这个)<br><span class="hljs-symbol">  branch:</span> master<br></code></pre></td></tr></table></figure></li><li><p>重新执行<code>hexo c</code> <code>hexo g</code> <code>hexo d</code></p></li></ol><p>这样就大功告成啦, 很简单吧, 继续写你的博客吧!</p><h2 id="reference">reference</h2><p>https://blog.zhheo.com/p/128998ac.html</p><p>https://blog.csdn.net/njc_sec/article/details/89021083</p>]]></content>
    
    
    
    <tags>
      
      <tag>Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
