<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>如何理解“梯度下降法”？什么是“反向传播”？</title>
    <link href="/2022/02/16/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    <url>/2022/02/16/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/</url>
    
    <content type="html"><![CDATA[<p>本章要解决的问题：</p><ol type="1"><li>梯度到底是什么</li><li>梯度如何被利用到神经网络中去训练神经网络的</li></ol><h3 id="什么是反向传播">什么是反向传播</h3><p>反向传播嘛顾名思义就是把信息反方向的传播的一种方式。在这之前我们先来看什么是正向传播， 神经网络中正向传播其实就是把信息输入神经网络， 信息通过一个一个感知机计算最后输出一个结果，说是感知器实际上就是感知机中的<span class="math inline">\(W,\,b\)</span>对结果产生的影响。而每个<span class="math inline">\(W,\,b\)</span>对结果产生的影响的大小就要看他们具体的数值了有的对结果影响大有的对结果影响小。</p><p>反向传播其实和正向传播是一样的，当一个神经网络没有训练好时它的结果是又偏差的，而这个偏差也是依赖于感知机中的<span class="math inline">\(W,\,b\)</span>的数值。相对于正向传播，反向传播不只是当当反向反了而已，反的还有它的传递的信息。它传递的是偏差的信息，将这些偏差传递到一个个参数上，最后根据每个参数对偏差做出的贡献大小相应的进行修改。</p><h3 id="反向传播是如何修改参数的">反向传播是如何修改参数的</h3><p>首先我们先用一个最符合直觉方法来理解一下反向传播究竟是怎么传播的，但先打个预防针，这个方法它并不正确只是可以方便我们的理解。</p><p><img src="./Screen%20Shot%202022-02-16%20at%206.42.40%20pm.jpg" /></p><p>首先这里的<span class="math inline">\(a^{[3]}\)</span>就是最后一层感知机输出的结果， <span class="math inline">\(\sigma\)</span>就是激活函数啦。<span class="math inline">\(W^{[3]},\,b^{[3]}\)</span>分别是最后一个感知机的权重和偏置，而<span class="math inline">\(a^{[2]}\)</span>是上一层隐藏层输出的结果。 这里我们使用交叉熵来计算损失值<span class="math inline">\(J\)</span>。</p><p><img src="./Screen%20Shot%202022-02-16%20at%206.47.32%20pm.jpg" /></p><p>这里我们假设损失值就是个大饼，我们可以通过分配这个大饼的方式去按贡献大小分配个每个参数。在这一层中我们就可以分配个<span class="math inline">\(W^{[3]},\,b^{[3]}\)</span>然后进行修改，但是我们并不能直接修改<span class="math inline">\(a^{[2]}\)</span>所以我们就需要将这部分反向传播给上一层。</p><p><img src="./Screen%20Shot%202022-02-16%20at%206.52.42%20pm.jpg" /></p><p>当然不是平均分配给每个感知机，而是需要根据每个感知机贡献的多少来进行分配，而每个感知机的参数如何调整又需要根据每个感知机的具体情况进行细分。然后我们对每个<span class="math inline">\(W^{[2]},\,b^{[2]}\)</span>再进行调整，但它需要承担的偏差也并不是由他自己决定的还需要继续向前传播。</p><p><img src="./Screen%20Shot%202022-02-16%20at%206.55.14%20pm.jpg" /></p><p>而前一层的感知机所需要承担的偏差是由后面所有感知机共同决定的，这里应该是需要一个算法来决定每个感知机究竟要分配多少偏差。到目前为止我们用了一个不正常但很符合直觉的办法理解反向传播是如何分配偏差的。但这种符合直觉的方法实际上在真正数值计算上并没有那么容易，那还有别的方法吗？当然有！我们前面用这种想切西瓜的方法来进行偏差的分配其实是数值的加法，那我们是否可以考虑使用向量来解决呢？使用向量的话我们就需要考虑到它不止有数值还有反向了，这就要引出梯度这个概念。</p><p>其实准确来说应该是梯度的反方向。因为按照定义梯度是指向数值增加最快的方向，而反方向就是数值减少最快的方向。</p><h3 id="什么是梯度">什么是梯度</h3><p><span class="math display">\[梯度 = \nabla f(x,\,y)\]</span></p><p>这个其实就是在求<span class="math inline">\(f(x,\,y)\)</span>这个函数的梯度。我们来看下面这张图，红色的曲面其实就是<span class="math inline">\(f(x,\, y)\)</span>这个函数，可以看到我们可以选定曲线上任意一个点过这个点做切面，在这个切面上有无数个切线而最特殊的就是图中的黑线他表示在这条切线上函数的数值变化最快并且他与梯度密切相关。在左图中的这个向量就是梯度，他其实就是这条黑线在平面上的投影。梯度指向的方向就是函数在这个点上数值增加最快的方向，并且梯度永远都和等高线垂直。</p><p><img src="./Screen%20Shot%202022-02-16%20at%207.13.22%20pm.jpg" /></p><p>我们现在选定一个点然后看到我们可沿着这个点做出它点梯度，因为他是个向量所以我们可以在平面中沿着坐标轴做出梯度的分量。我们假设<span class="math inline">\(x\)</span>轴和<span class="math inline">\(y\)</span>轴的单位向量分别是<span class="math inline">\(i,\,j\)</span>当我们知道了单位向量后其实我们就可以把梯度的这两个分量表达出来。<span class="math inline">\(α,\,β\)</span>分别是分量的系数，我们把分量表示出来了就可以很轻松的写出梯度的表达式了。</p><p><img src="./Screen%20Shot%202022-02-16%20at%207.25.01%20pm.jpg" /></p><p>到这里我们实际上就是把梯度进行了分解，那么梯度他有个非常重要的意义就是它始终指向函数数值变化最快的方向。那么如果我们确定了一个点后我们想要沿着梯度的方向也就是数值变化最快的方向变化那也就变得非常简单了。</p><p><img src="./Screen%20Shot%202022-02-16%20at%207.32.18%20pm.jpg" /></p><p>我们只需要把原来的<span class="math inline">\(x\)</span>加上一个<span class="math inline">\(\alpha\)</span>倍数，在原来的<span class="math inline">\(y\)</span>上加一个<span class="math inline">\(\β\)</span>的倍数，而这个倍数<span class="math inline">\(\eta\)</span>是相等的，所以就相当于梯度在<span class="math inline">\(x,\,y\)</span>上的分量同时放大或缩小最后的方向是不变的。</p><h3 id="如何在神经网络中使用梯度">如何在神经网络中使用梯度</h3><p>但我们已经理解了什么事梯度后我们其实就可以把原本的损失函数<span class="math inline">\(J\)</span>看成是前面的函数<span class="math inline">\(f\)</span></p><p><img src="./Screen%20Shot%202022-02-16%20at%207.39.39%20pm.jpg" /></p><p>那么损失函数的梯度其实就是代表它增大最快的那个方向，那如果取反就是损失值减小最快的那个方向了。</p><hr /><p><strong><em>以下数学不严谨，只可意会</em></strong></p><hr /><p><img src="./Screen%20Shot%202022-02-16%20at%207.46.02%20pm.jpg" /></p><p>首先这里的<span class="math inline">\(\nabla J\)</span>就是损失函数的梯度啦，<span class="math inline">\(α, \,β, \, \gamma\)</span> 分别是梯度在三个分量上的系数。那么根据前面讲的如果我们需要沿着梯度的反方向改变值的话我们就需要在原来的值基础上减去<span class="math inline">\(\eta\)</span>倍的原来的系数。那么在这一层我们就可以直接对权重和偏执进行更新，但是我们并不能直接修改<span class="math inline">\(a^{[2]}\)</span>，我们需要继续进行方向传播。那既然如此我们不如对它进行一下位置的调换</p><p><img src="./Screen%20Shot%202022-02-16%20at%207.53.22%20pm.jpg" /></p><p>我们就会发现<span class="math inline">\(β\)</span>其实就是目前的<span class="math inline">\(a^{[2]}\)</span>和我们期望的<span class="math inline">\(a^{[2]}\)</span>之间的差值，而我们舍去<span class="math inline">\(\eta\)</span>因为在之后我们继续进行反向传播它还会分配给之后的权重和偏置，所以我们不要在这里乘上这个倍数，因此我们先将他舍去以方便后续的计算。</p><p>到这里我们可以发现这里其实和损失函数有着异曲同工之妙。损失函数是表示我们期望的结果和目前的结果的差值，而这里也是表示上一层隐藏层输出的结果和我们期望的结果的差值。因此我们可以把它假设成一个<strong>“损失函数”</strong>，这里并非是真的损失函数但我们可以假设他是然后用同样的计算进行后续的操作。</p><p>上述的<span class="math inline">\(α, \,β, \, \gamma\)</span> 并不严谨，实际上他们都是以向量的方式表达的，具体数学在这里就不细分析了，以下给出简要的表达式（不会的回去补高数！！） <span class="math display">\[\nabla f(x, y) \hspace{20mm}\\=(\frac{\partial f}{\partial x},\, \frac{\partial f}{\partial y}) \hspace{10mm}\\=\frac{\partial f}{\partial x} \cdot i + \frac{\partial y}{\partial y}\cdot j\]</span> 这样我们就能使用偏导来代替前面的<span class="math inline">\(α, \,β, \, \gamma\)</span> 了 <span class="math display">\[\alpha = \frac{\partial J}{\partial W^{[3]}} \\\gamma = \frac{\partial J}{\partial b^{[3]}} \hspace{2mm}\\\beta = \frac{\partial J}{\partial a^{[2]}} \hspace{1mm}\]</span> 接下来我们就可以直接替换原本的<span class="math inline">\(α, \,β, \, \gamma\)</span> 用偏导代替，但在下一层中的差值就不是由当当一个感知机决定了我们就前面所有的值求平均。</p><p><img src="./Screen%20Shot%202022-02-17%20at%204.16.58%20pm.jpg" /></p><h3 id="梯度下降法的严谨数学表达">梯度下降法的严谨数学表达</h3><p><img src="./Screen%20Shot%202022-02-17%20at%204.30.36%20pm.jpg" /></p><p>接下来我们就用相对严谨的数学进一步的理解梯度下降法中数据是如何反向传递的。首先我们单独拎一个感知机出来看，图中的<span class="math inline">\(a^{[l-1]}\)</span> 表示的是上一层的输出结果<span class="math inline">\(l\)</span>表示第<span class="math inline">\(l\)</span>层，这里的<span class="math inline">\(a^{[l-1]}\)</span>其实是一个矩阵，矩阵的每一个值表示的是上一层每一个感知机的输出结果。<span class="math inline">\(W_i^{[l]}\)</span>表示的是<span class="math inline">\(l\)</span>层的所有权重每个权重都是一个向量。 <span class="math inline">\(b_i^{[l]}\)</span>表示的是<span class="math inline">\(l\)</span>层的偏置。我们把上一层的所有结果乘以权重矩阵的转置加上偏置就是我们的结果<span class="math inline">\(z_i^{[l]}\)</span>，但感知机的输出结果还需要通过激活函数<span class="math inline">\(\sigma\)</span>输出结果<span class="math inline">\(a_i^{[l]}\)</span>。虽然这样的表达已经很简洁了但是，如果我们需要一一个感知机的这么写还是很复杂。</p><p><img src="./Screen%20Shot%202022-02-17%20at%204.49.28%20pm.jpg" /></p><p>其实我们可以直接按整层的来开这了的<span class="math inline">\(z^{[l]}\)</span>是个矩阵代表的是<span class="math inline">\(l\)</span>层所有的输出。权重矩阵每一行表示的是当层每一个感知机的权重，每一列其实可以看成是上一层的每一个感知机的权重。<span class="math inline">\(a^{[l-1]}\)</span>表示的是上一层的所有输出结果，<span class="math inline">\(b^{[l]}\)</span>表示的是<span class="math inline">\(l\)</span>层的所有偏置。 就此我们隐藏式层算是介绍完了。接下来我们就要关注一下输出层了。</p><figure><img src="./Screen%20Shot%202022-02-17%20at%204.57.50%20pm.jpg" alt="Screen Shot 2022-02-17 at 4.57.50 pm" /><figcaption aria-hidden="true">Screen Shot 2022-02-17 at 4.57.50 pm</figcaption></figure><p>我们知道在输出层我们需要使用损失函数<span class="math inline">\(J\)</span>来计算神经网络的输出和我们的期望的差值。这里<span class="math inline">\(a^{[l](k)}\)</span>就是神经网络输出层输出的<span class="math inline">\(k\)</span>个结果，<span class="math inline">\(y^{(k)}\)</span> 其实就是我们训练数据打的标签，对于每个<span class="math inline">\(x^[(k)]\)</span>都是人工识别标注的。在输入层中<span class="math inline">\(x\)</span> 就是我们输入的一个一个数据，<span class="math inline">\(x^{(k)}\)</span>的每一个值就是一个数据的分量，假设如果是图片数据那么<span class="math inline">\(x_1^{(k)} \cdots x_j^{(k)}\)</span>就是图片的每个像素。到此为止我们考虑的都是自由一个输出结果的二分问题，实际上我们一个扩充一下 。</p><h3 id="关于多输出的神经网络的反向传播">关于多输出的神经网络的反向传播</h3><p><img src="./Screen%20Shot%202022-02-17%20at%205.19.17%20pm.jpg" /></p><p>扩充之后输出层就不只有一个节点了而是有<span class="math inline">\(i\)</span>个节点，每个节点都有一个输出值，而这里的损失函数<span class="math inline">\(J\)</span>是对谁有的输出<span class="math inline">\(a_i^{[l](k)}\)</span>的一个统一判断的损失值。也就是整体的这个神经网络离我们的预期还差多少。 因为这里我们只考虑训练神经网络的时候，在训练神经网络的时候这里的<span class="math inline">\(y^{(k)}\)</span>和<span class="math inline">\(x^{(k)}\)</span>都是个确定的值，不是变动参量，所以这里的损失函数我们还可以再简写一下变成<span class="math inline">\(J(a_i^{[l]})\)</span>，损失函数唯一依赖的就是神经网络最后的输出值。</p><p><img src="./Screen%20Shot%202022-02-17%20at%205.25.42%20pm.jpg" /></p><p>我们知道如果要进行反向传播第一步就要对损失函数求梯度，那么因为损失函数依赖于最后每个感知机输出的值，所以对于每个输出都有一个分量，而这个分量就是输出层每个感知机需要承担的偏差值。为了后面描述方便我更愿意在这里添加一个虚拟的<span class="math inline">\(l+1\)</span>层，这个<span class="math inline">\(l+1\)</span>层不是真实存在的只是为了表述方便。我们吧每一个分量当作是一个新的误差函数，而每一个误差函数只对这一个感知机有效对别的感知机无效。</p><p><img src="./Screen%20Shot%202022-02-17%20at%205.34.03%20pm.jpg" /></p><p>那么我们为了继续向前传播就需要对每一个误差函数求梯度，也就是这里的<span class="math inline">\(\nabla J_1^{[l+1]} \cdots \nabla J_i^{[l+1]}\)</span>。</p><p>到这里我们就可以继续一步一步向前传播了，但为了理解我们继续展开来看看。首先我们需要关注的是<span class="math inline">\(\frac{\partial J_1^{[l+1]}}{\partial W_1^{[l]}}\)</span>，我们知道损失函数<span class="math inline">\(J\)</span>其实是一个关于<span class="math inline">\(a^{[l]}\)</span>的函数，而这个<span class="math inline">\(a^{[l]}\)</span>是一个关于激活函数<span class="math inline">\(\sigma\)</span>的函数，所以我们这里需要使用链式求导对她进行展开。 展开之后我们发现对每个分量都有一个<span class="math inline">\(\frac{\partial J_1^{[l+1]}}{\partial \sigma}\)</span>，对于这个我们就可以利用原本那个整体的损失函数<span class="math inline">\(J(a_i^{[l]})\)</span>带进来。就会变成： <span class="math display">\[\nabla J_1^{[l+1]} = (\frac{ v J_1^{[l+1]}}{\partial \sigma}\frac{\partial \sigma}{\partial z_1^{[l]}}\frac{\partial z_1^{[l]}}{\partial W_1^{[l]}},\, \frac{\partial J_1^{[l+1]}}{\partial \sigma}\frac{\partial \sigma}{\partial z_1^{[l]}}\frac{\partial z_1^{[l]}}{\partial a^{[l-1]}},\, \frac{\partial J_1^{[l+1]}}{\partial \sigma}\frac{\partial \sigma}{\partial z_1^{[l]}}\frac{\partial z_1^{[l]}}{\partial b_1^{[l]}})\]</span> 后面为了简化表达就不继续展开了。然后我们还需要关注另一就是<span class="math inline">\(\partial W_1^{[l]}\)</span>，我们知道<span class="math inline">\(W_1^{[l]}\)</span>是个向量所以它是有分量的，队友有分量的进行求偏导其实这里是有简化的。他其实相当于对每个分量进行求偏导。对于<span class="math inline">\(a^{[l-1]}\)</span>也是同理。后面也不继续展开了。</p><p><img src="./Screen%20Shot%202022-02-17%20at%205.49.08%20pm.jpg" /></p><p>但我们已经知道了这些分量后我们就可以对参数进行修改了</p><p><img src="./Screen%20Shot%202022-02-17%20at%205.57.32%20pm.jpg" /></p><p>对于<span class="math inline">\(W,\,b\)</span>我们就可以直接进行修改了这里的<span class="math inline">\(\eta\)</span>其实就是我们常说的学习率了，然后对于<span class="math inline">\(a\)</span>我们可以构建新的损失函数继续进行反向传播。这里我们利用了滑动窗口的思想来理解接下来的操作。</p><p><img src="./Screen%20Shot%202022-02-17%20at%206.02.36%20pm.jpg" /></p><p>对于每一个损失函数求梯度，这里每一个梯度都有多个分量，每个感知机的偏差都由上一层的所有感知机共同承担。这里每一个<span class="math inline">\(a\)</span>又都是一个关于<span class="math inline">\(W,\,a,\,b\)</span>的函数，所以我们可以继续展开。</p><p><img src="./Screen%20Shot%202022-02-17%20at%206.08.32%20pm.jpg" /></p><p>在这里我们需要多注意的是对于<span class="math inline">\(l\)</span>层所有的感知机来说，他们需要承担的偏差值就不是由一个感知机来赋予的了，而是由所有的感知机共同赋予的。我们把所有偏差值的分量统一加起来求平均把它作为需要调整的的量。接下来我们就可以把所有的需要调整的偏差值写出来。 <span class="math display">\[(\Delta W_1^{l},\, \Delta a^{[l-1]},\, \Delta b_1^{[l]},\,\cdots\,,\,\Delta W_i^{l},\, \Delta a^{[l-1]},\, \Delta b_i^{[l]})\]</span></p><p><span class="math display">\[(\Delta W_1^{l},\, J_1^{[l]},\, \Delta b_1^{[l]},\,\cdots\,,\,\Delta W_i^{l},\, J_i^{[l]},\, \Delta b_i^{[l]})\]</span></p><p>其中<span class="math inline">\(W,\, b\)</span>就可以直接进行修改了，然后我们重新定义<span class="math inline">\(J_i^{[l]}\)</span>就可以把这个循环继续下去了。</p><h3 id="references">References</h3><p>https://www.geogebra.org/m/HpDDHprj</p><p>https://www.bilibili.com/video/BV1Zg411T71b?spm_id_from=333.999.0.0</p><hr /><p><strong><em>知识来源作者为b站UP主王木头学科学</em></strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>神经网络</tag>
      
      <tag>数学</tag>
      
      <tag>梯度</tag>
      
      <tag>梯度下降法</tag>
      
      <tag>反向传播</tag>
      
      <tag>偏微分</tag>
      
      <tag>链式反导</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>交叉熵如何做损失函数？</title>
    <link href="/2022/02/15/%E4%BA%A4%E5%8F%89%E7%86%B5/"/>
    <url>/2022/02/15/%E4%BA%A4%E5%8F%89%E7%86%B5/</url>
    
    <content type="html"><![CDATA[<h3 id="最大似然估计为什么又叫交叉熵">“最大似然估计”为什么又叫“交叉熵”</h3><p>下面这个是吴恩达大佬在他的课程里面写出来的最大似然估计法的公式，<span class="math inline">\(y\)</span>是标签值， <span class="math inline">\(\hat{y}\)</span>是神经网络的估计值。 <span class="math display">\[\mathscr{L}\left(\hat{y}, y\right) = -\left(y\log\hat{y} + \left(1-y\right)\log\left(1-\hat{y}\right)\right)\]</span> 这个的确是用最大似然估计法写出来的损失函数，但是，只要你对损失函数有了解，就可能见到过，同样的这个公式也叫<strong>交叉熵</strong>，或者说是<strong>最小交叉熵方法</strong>。</p><p>这就是有疑问的地方了，同样一个东西，为什么既可以叫这个名字，又可以叫那个名字。如果，两个名字相似也就算了，<strong>关键是“最大似然估计”和“交叉熵”两个没有丝毫相似的地方，为什么可以表示同一种东西呢</strong>？</p><p>这就需要搞明白交叉熵到底是什么东西了，等把它搞明白之后，你就会明白，交叉熵和最大似然估计，虽然它们设计损失函数的思路不同，但是它们却是殊途同归，本质上是相同的。</p><p>本章将会了解以下内容：</p><ol type="1"><li>如何比较两个不同的概率分布？</li><li>什么是信息量？信息量是如何定义出来的？</li><li>什么是熵？</li><li>什么是KL散度（相对熵）和交叉熵？</li><li>用交叉熵如何设计损失函数？真的和最大似然估计法没有区别吗？</li></ol><h3 id="熵可以让不同的类型的概率分布实现公度">熵可以让不同的类型的概率分布实现公度</h3><p>还是拿分类问题来举例，给了一堆猫狗的照片要把它们正确的分开，猫狗的区别这是有一个客观的规律的。我们上一次也讲过了，这个客观的规律，我们可以用函数来表示，也可以概率分布来表示。</p><p>假如说，这个真实的规律我们可以用<span class="math inline">\(P\left(y,\,x\,|\,\text{真实规律}\right)\)</span>来表示，其中<span class="math inline">\(y\)</span>判断结果，<span class="math inline">\(x\)</span>是输入的图片，如果以真实规律作为条件，那么输入的图片一定能准确地判断出是猫还是狗。那机器学习呢？其实就是在计算机里面尽可能没有差别地把这个<span class="math inline">\(P\left(y,\,x\,|\,\text{真实规律}\right)\)</span>概率分布学出来。</p><p>这里就出现一个关键问题了，假如说机器学习算法做出了一个猜测，<span class="math inline">\(P\left(y,\,x\,|\,\text{真实规律}\right)\)</span>。我们应该如何判断，这个猜测出来的概率分布与表示真实规律的概率分布是不是一样的？</p><p>其实不只是是判断出来“一样”还是“不一样”就可以了，还需要知道它们之间的差距有多大，这样才能帮助机器学习的算法调整和修改，越来越接近真实规律。</p><p>那么如何才能对两个概率分布做出比较呢？</p><p>如果是同一类的概率分布的话，那还好办。比如说，都是正态分布，影响分布的参数就两个，一个均值一个方差。只需要判断真实规律和猜测规律里面这两个参数是不是一样，不一样的话看看参数差了多少，就行了。</p><p>但真实的情况却不是这么简单，真实规律表现出来是什么样子的，我们根本不知道，别说我们根本无法确定真实规律那个概率分布到底是什么类型的，就算是确定了，决定它的参数也可能有很多，无法进行简单地比较。</p><p>于是，比较两个概率分布的最大障碍出现了。<strong>两个不同类型的概率分布，它们无法直接公度</strong>。</p><p>那怎么办呢？有什么方法可以让无法公度的两个概率分布，变得可以公度吗？</p><p>这件事上，虽然不能一下子想到解决方法，但是说到公度的话，我们的世界里有一个特别伟大的系统，通过它可以让许多本来无法公度的事情变得可以公度，这或许可以给我们带来启发。</p><p>这个系统就是货币系统，它让许多无法公度的事情，都可以变成一个价格数字，通过价格就能进行比较了。</p><p>就比如，一个房子，你家里的老房子，在里面有几代人的记忆，对于你来说这个房子是价值很大的。但是，对于买房的人来说，这并没有什么特殊的，他心中这个房子的价值一定不如你。这本来是一个无法公度的事情，因为你们选择的根本就是不同的价值体系。</p><p>不过没有关系，只要把房子放到货币体系里面，货币体系就可以完成对这个房子价值的评估，在你和买房人之间寻找到一个价值平衡点。</p><p>虽然价格体系的运行方式很复杂，但是有一点是能给我们启发的，那就是不论是什么东西，它都可以把它们换成一串数字，变成数字之和就可以进行公度了。</p><p>那么不同类型的概率分布，它们是不是也可以有类似的方法，先把它们转换成一串数字，将这个数字作为他们进行公度的代表。</p><p>还真有，这个<strong>概率分布的“货币体系”就是熵</strong>。</p><p>所有的概率分布，都可以统一地被转换成熵，比较两个概率分布是不是相同，不同的话，它们之间又相差多少，都可以用熵来进行衡量了。</p><p>那到底是什么是熵呢？在了解它之前，我们还需要了解一个前置概率，信息量。</p><h3 id="信息量是什么">信息量是什么</h3><p>信息量这个词我们还是比较熟悉的，在日常口语中我们就在使用，假如说你看新闻刷到一个惊天大瓜，你可能就会感叹说这个新闻的信息量太足了。</p><p>什么是信息？一条信息的功能就是让你从“不知道”变得“知道”，信息量肯定就是对信息的这个功能进行的度量了。可是，如果信息的使命就是让“不知道”变成“知道”，也就是说这是一个“是否”的二值问题，那信息也就没有度量的必要了，反正就两种情况。</p><p>关键是，一条信息不是“知道”和“不知道”非此即彼的，它还能让你既不是完全不知道，又不是完全知道。如果是这样的话，那对信息进行度量就有意义了，就是去度量一下这个“知道”的程度。</p><p>这种既不是完全不知道，又不是完全知道的状态还真有，举个例子。假如说有8只球队参加世界杯，有这样两种情况：</p><ol type="1"><li>如果你什么消息都没有听说，有人问你阿根廷夺冠没有啊，你回答说不知道。</li><li>随后，你看到一个消息，说阿根廷已经进决赛了，这个时候再问你阿根廷夺冠没有啊，你还是说不知道。</li></ol><p><img src="./7899da57ce319f2ab072772dbac334df69f1dbdb.png@942w_680h_progressive.png" /></p><p>虽然两种情况，你对阿根廷是否夺冠回答的都是不知道，但是这里的“不知道”和“不知道”还是很不一样的。<span class="math inline">\(a\)</span>情况的不知道，因为还没有比赛所以阿根廷夺冠的概率是<span class="math inline">\(\frac{1}{8}\)</span>，b情况阿根廷已经进到决赛了，虽然还没有最终夺冠，但是夺冠的确定性已大大增加，已经达到了<span class="math inline">\(\frac{1}{2}\)</span>。</p><p>所以说，“阿根廷进决赛”这个消息，让你对阿根廷夺冠这个事件，从完全不知道，到有些知道了。也就是说，这个消息它应该是有信息量的。</p><p>从前面这个例子，我们也能看出来对于阿根廷夺冠这件事，不同的消息含有的信息量很可能是不同的。</p><p>如果我和你说，我今天中午多吃了一个包子，这虽然也是个消息，但是这个消息对于阿根廷夺冠来说信息量就<span class="math inline">\(0\)</span>。</p><p>总结一下的话，其实我们应该有这一个感觉了，定性上来说，信息量它应该是，某个消息对“某个事件的确定程度改变了多少”进行的衡量。而确定性改变了多少，其实也就是前面说的那个概率的改变，阿根廷夺冠从原来的<span class="math inline">\(\frac{1}{8}\)</span>变成了<span class="math inline">\(\frac{1}{2}\)</span>。</p><p>但是定量上来说，信息量到底是多少呢？难道就是凭着直觉，简单地用<span class="math inline">\(\frac{1}{2}\)</span>减去<span class="math inline">\(\frac{1}{8}\)</span>，用这个差值去定义信息量吗？ 没有这么简单。</p><h3 id="信息量的良定义">信息量的良定义</h3><p>要想对信息量给出一个良定义，不能产生自我矛盾，就需要考虑一下不同情况中，我们对信息量的理解是什么样的。</p><p>就比如，我们可以看这样一种情况。</p><p><img src="./b84943df5cf47c4a1957bdb1459303aaf6b02a27.png@942w_615h_progressive.png" /></p><p>这里的3个箭头代表着3个消息，绿色消息是阿根廷进入了决赛，蓝色消息则是阿根廷直接夺得冠军，这两个消息的起点都是一样的，都是在你不知道任何比赛结果的时候听到的消息。</p><p>而橙色消息，它则是依赖于绿色消息的，它代表的是，在你知道阿根廷进决赛之后，又赢得决赛夺得冠军。</p><p>如果我们想要信息量来衡量3个消息，那么我们可以看出信息量应该满足下面等式：</p><ul><li>$信息量(蓝色消息)=信息量(绿色消息)+信息量(橙色消息) $</li></ul><p>一个消息的信息量具体是多少，虽然我们现在还不知道，但是我们可以确定，这个信息量应该是和对应事件发生的概率有关。于是我们就可以拿这个概率作为变量，那计算信息量这个函数应该如下：</p><ul><li><span class="math inline">\(信息量(\frac{1}{8})=信息量(\frac{1}{4})+信息量(\frac{1}{2})\)</span> —— ①</li></ul><p>到这里其实还没有完，因为函数里的变量是概率，根据条件概率的性质，我们知道这里还隐含着一个条件，那就是：</p><ul><li><span class="math inline">\(P(夺冠)=P(夺冠|进决赛)×P(进决赛)\)</span> —— ②</li></ul><p>把①和②一结合，我们就可以发现这样一个关系：</p><ul><li><span class="math inline">\(信息量(\frac{1}{4} × \frac{1}{2})=信息量(\frac{1}{4})+信息量(\frac{1}{2})\)</span></li></ul><p>仔细看一下这个式子就能发现，计算信息量的这个函数，如果想要自洽、想要是良定义的，那么它必须满足一个条件，那就是自变量的乘法等于函数值的加法。</p><p>满足这样这样的函数应该是什么样子的？</p><p>理论上来说，满足这个性质的函数应该是有千千万万的，但是其中最简单的应该就是对数运算log了。log对数运算是唯一满足这种关系的初等函数。</p><p>到现在，我想大家心中都会有一个冲动，就是把信息量定义为： <span class="math display">\[\text{信息量}\left(P\left(X\right)\right) :=?log_?P\left(X\right)\]</span> 不论是说<a href="https://baike.baidu.com/item/奥卡姆剃刀原理/10900565?fr=aladdin">奥卡姆剃刀原理</a>，还是说人们本能的喜欢偷懒，这个用最简单的方式给出定义的冲动都特别正常。我想，当年香农给出信息量的定义的时候，也是这么想的。</p><p>接下来需要确定的就是这个式子里的两个问号了，系数是多少？对数的底又是多少？</p><p>一切都为了简单，不考虑别的话，系数应该就是<span class="math inline">\(1\)</span>了，只不过需要确定的是，到底是<span class="math inline">\(1\)</span>还是<span class="math inline">\(-1\)</span>。</p><p>如果硬规定，系数就是1也行，只不过我们现在做的并不是完全凭空发明出信息量这个概念，如果是凭空创造出来的，那么发明人怎么定那我们就怎么用。我们现在面对的问题是，信息量这个概念，我们在日常生活中就在用，只不过定理的定义不是很清晰，我们现在做的其实是把这个定义换成更精确的数学方式表达出来，所以数学的定义不应该和我们的口语表达有冲突。</p><p>所以到底是<span class="math inline">\(1\)</span>还是<span class="math inline">\(-1\)</span>，就需要看一下我们口语中，自变量（也就是那个概率值）越大函数值越大，还是自变量越小函数值越大了。</p><p>还是看上面阿根廷夺冠的例子，绿色消息是阿根廷进入决赛，蓝色消息是阿根廷夺得冠军，一个发生的概率是1/4，一个发生的概率是1/8，单从概率的数值上来看的话，显然绿色消息值更大。但是这两个消息那个信息量更大呢？</p><p>我们的感觉肯定是蓝色的消息信息量更大啊，绿色的消息只是让阿根廷夺冠这件事概率增加了，并没有完全确定，而蓝色消息却是给出了一个完全确定的结果，显然蓝色的消息带来的不确定程度的改变更剧烈，也就是带来的信息量更大。</p><p>所以信息量，它的自变量和函数值应该是一个反比关系，也就是第一个问号，那个系数应该是<span class="math inline">\(-1\)</span>。 <span class="math display">\[\text{信息量}\left(P\left(X\right)\right) :=-log_?P\left(X\right)\]</span> 剩下没有确定的就是对数运算的底了，这里底到底取多少，其实已经不那么重要了，可以取<span class="math inline">\(e\)</span>为底，也可以取<span class="math inline">\(10\)</span>为底，还可以取<span class="math inline">\(2\)</span>为底。当然，现在我们习惯的方式用2为底，这样子计算出来的信息量单位是比特。</p><p>取不同的底，其实就是信息量的单位不同，以<span class="math inline">\(e\)</span>为底的单位是纳特(nat)或者是nit，以<span class="math inline">\(10\)</span>为底的单位是哈特(Hart)或者是dit。</p><p>其中比特我们最熟悉，这最早是由香农提出来的。而以<span class="math inline">\(10\)</span>为底的信息量，最早是1928年有拉尔夫·哈特利(Ralph Hartley)提出来的，后来图灵也用<span class="math inline">\(10\)</span>为底计算过信息量，只不过图灵把这样的信息量单位称为ban。</p><p>这里值得注意的是，信息量是有单位的（也就是说信息量有量纲）。什么意思呢？这里用bit作为例子来说明一下。</p><p>我们知道，说到单位，比如说米、千克，它们都是有一个基准尺度的，具体长度是多少、质量是多少，都是与这个基准尺度做比较得出来的。比如，曾经米的基准就是子午线的千万分之一，后来才改成用光速定义，公斤的基准尺度曾经是用放在法国的国际千克原器的质量，后来才改成用普朗克常数定义。</p><p>既然信息量也是有单位的，那么这个bit单位的基准尺度是什么呢？</p><p>其实bit就是用像抛硬币这种“<span class="math inline">\(50\%\)</span>正、<span class="math inline">\(50\%\)</span>反”的情况作为基准尺度的，其他的bit数值都是与这个基准尺度比较得到的。</p><p><span class="math inline">\(\frac{1}{2}\)</span>概率的事件是<span class="math inline">\(1\)</span>bit，<span class="math inline">\(\frac{1}{4}\)</span>概率的事件是<span class="math inline">\(2\)</span>bit，这就是说这两个概率分别可以用<span class="math inline">\(1\)</span>个硬币和<span class="math inline">\(2\)</span>个硬币等价表示。至于<span class="math inline">\(\frac{1}{3}\)</span>的概率，对应的信息量是约等于<span class="math inline">\(1.58\)</span>bit。虽然我们现实中不可能是抛<span class="math inline">\(1.58\)</span>个硬币，但是数学上还是可以这样来表示出来的。</p><p>这里再多说一下，在计算机里面，我们经常说<span class="math inline">\(8\)</span>bit、<span class="math inline">\(16\)</span>bit这些词，这些词不只表示一个信号里面含有的信息量，还用来表示存储空间的大小。</p><p>这是为什么呢？</p><p>举个例子，假如说计算机里面有一个<span class="math inline">\(16\)</span>bit的空间，这个空间里0、1、0、1到底是怎么排列组合的，是不确定的，任何一种情况的概率都是<span class="math inline">\(\frac{1}{2}^{16}\)</span>。当计算机接受到1个信息，这里的空间存储上了一个2进制数字（具体是什么数字无所谓），这里的可能性就从原来的<span class="math inline">\(\frac{1}{2}^{16}\)</span>概率变成了确定的<span class="math inline">\(1\)</span>，这个信息量是多少？就是<span class="math inline">\(16\)</span>bit啊。这个空间最多可以承载多少的信息量？就是<span class="math inline">\(16\)</span>bit了。</p><p>于是存储空间的大小和信息量统一了，这也是bit又可以表示存储空间的原因。</p><h3 id="熵是一个系统里信息量的期望值">熵是一个系统里信息量的期望值</h3><p>对信息量了解之后，我们就可以来看熵了。</p><p>熵这个概念，现在已经比较出圈了，本来一个学科里面很偏门的概念，现在在互联网圈子里面却人尽皆知。</p><p>主要就是熵增这个概念太火了，它涉及到了整个宇宙的宿命，宇宙的未来就是在不可对抗的熵增过程中归于热寂。那熵到底是什么呢？在科普内容里面，很少有人把熵的定义公式拿出来讲的，都是说<strong>熵是对一个系统的混乱程度的度量</strong>。</p><p>当初的先贤们是如何提出熵这个概念的，他们最初的想法是什么，我们很难还原了，不过我们现在还是可以对熵做逆向工程，试着来理解一下，前面说的系统的混乱程度到底是什么意思？为什么用信息量可以去描述系统的混乱程度？</p><p>我们可以先来看这样一个问题，有两场比赛，假如说这两场比赛就是两个系统。</p><p><img src="./5da5016d8b883f7da6081355f55aae59672fb976.png@942w_290h_progressive.png" /></p><p>一场比赛是比利时对战阿根廷（系统1），因为它们水平差不多，所以两队赢球的概率都是<span class="math inline">\(50\%\)</span>。另一场比赛是法国对中国（系统2），实力相差比较大，所以法国赢球的概率<span class="math inline">\(99\%\)</span>，中国赢球的概率是<span class="math inline">\(1\%\)</span>。</p><p>请问，这两个系统那个的混乱程度更高？</p><p>这个问题并不是靠直觉马上就能回答出来的，还是要琢磨一下。法国对中国，这个系统不出意外的话，肯定是法国赢，也就是最后的结果确定性更高。而比利时对阿根廷，这个就不能说意外不意外了，谁赢都有可能，所以最后结果是什么就很不确定。</p><p>这里我是用不确定的程度来描述两场比赛的，其实这个不确定的程度也就是我们日常说的混乱程度，比利时和阿根廷比赛，因为结果特别不确定，所以很混乱。反过来说你，一个屋子很混乱，也就是你的袜子到底在哪里，非常不确定。</p><p>既然和概率、不确定性搭上关系了，那么我们前面介绍的信息量就可以派上用场了。</p><p>两次比赛，分别对应着两个可能的事件（系统1是“比利时赢”和“阿根廷赢”两个事件，系统2是“法国赢”和“中国赢”两个事件），它们对应的信息量计算结果出来如下：</p><p><img src="./5262bdbc97fbc0edff46ddd34754fc26620a5000.png@942w_414h_progressive.png" /></p><p>比利时对阵阿根廷，不论谁获胜，信息量都是1bit。法国对阵中国，法国赢球的概率很高，所以他们赢球带来的信息量就很少，但是如果中国赢球了，那这个信息量就很大了，超过了6.6bit。</p><p>这么看的话，系统1这个系统里两个事件的信息量加起来才是2bit，还没有中国赢球一个事件的信息量大，如果用信息量来表示熵，是不是就会有问题啊。明明系统1更不确定，但是计算出来却是系统1的信息量更少。</p><p>别急，熵的确是“系统里面所有可能事件对应的信息量总和”，只不过不是把它们简单地加起来就行了，而是需要加权求和。这个权重是什么？就是这个事件发生的概率啊。</p><p><img src="./e577e8cd24c9aafa024487ae7d1fe1084141838e.png@942w_497h_progressive.png" /></p><p>加上权重之后，就合理了，从上图就可以看出系统1得到的值的确是比系统2更大了。</p><p>而且这个加上权重的动作也挺合理的，就比如说，中国队夺冠了这个事情如果发生了的话，信息量的确还挺大的，但是它得真发生了才行了，可事实呢，它只有1%的可能性发生，99%的可能性都是法国夺冠。</p><p>所以，一个系统到底含有多少信息量，那还需要看具体一个事件对整个系统到底能贡献多少信息量才行。如果事件没发生，那就是没有贡献啊，就不能放在总和里面。越是一个事件贡献了多少信息量，就可以理解成信息量乘上对应事件发生的概率。</p><p>那熵到底是什么？这个问题就简单了，熵就是所有事件对应的信息量的加权和，那这个加权和是什么？就是这个系统里面信息量的期望值啊。</p><p>那么我们就可以<strong>对熵做出如下定义</strong>了，其中<span class="math inline">\(H\left(S\right)\)</span>表示<span class="math inline">\(S\)</span>系统的熵，<span class="math inline">\(E\)</span>是求期望，<span class="math inline">\(I(X)\)</span>是求信息量，<span class="math inline">\(P\left(x_i\right)\)</span>表示<span class="math inline">\(x_i\)</span>事件的概率。</p><p><img src="./b14c7987fc718bb8641a09c0821e876d7b7879ba.png@942w_480h_progressive.png" /></p><p>现在我们已经知道熵到底是什么了。我们最开始的目的是什么？是比较两个概率分布，一个表示真实的规律，一个表示机器学习猜测的规律，看看两个概率分布它们相差有多少。</p><p>现在有了熵，我们是不是就可以直接比较两个概率分布的差距了呢？把两个概率分布的熵都算出来，然后看看相差多少。</p><p>哪有这么简单，别忘了，真实规律我们是不知道的，既然不知道，那它的熵还怎么求呢？没有办法。</p><p>那么有没有什么方法，即便不知道一个概率分布的熵具体是多少，也能知道两个概率分布之间的差距是多少呢？ 有！这就是KL散度和交叉熵了。</p><h3 id="kl散度相对熵和交叉熵">KL散度（相对熵）和交叉熵</h3><p>假如说，下面这个图表示的是两个系统的概率分布，其中系统<span class="math inline">\(S\)</span>代表的是真实的规律，系统<span class="math inline">\(O\)</span>代表的是机器学习模型里面猜测的那个规律。</p><p><img src="./166b97f632272d046a9d62720bf536756e4bac6b.png@942w_363h_progressive.png" /></p><p>这两个系统的概率分布如果是相同的话，那么毫无疑问，两个系统的熵也一定是相等的，而且我还能大概确定，两个系统越像，熵应该是越接近的。</p><p>不过，这个事情不能反过来想，两个系统的熵相同，两个系统的概率分布就一定相同吗？好像并没有这么简单，因为简单的一个数字，维度太少了。一张200元的高铁票和一件200元的衣服，它们价格相同，但是这两个东西却是天差地别。</p><p>所以，看两个系统是不是相同，不能是直接比较两个系统的熵，这会太简单粗暴。那怎么办呢？这个时候就需要KL散度这个概念了。</p><p>KL散度就不是粗暴的比较一个总体的熵了，而是比较得更细致，每一个事件<span class="math inline">\(x_i\)</span>对应的信息量，都会拿来进行比较。如果每一个事件的信息量都是相同的，那么两个概率分布肯定就是相同的了。</p><p>于是KL散度就可以做出如下定义：</p><p><img src="./65ad9077e81ac853dc82efa4470f3fd0f9b583a4.png@942w_198h_progressive.png" /></p><p>可以注意到，这个定义本质上也是一个加权求和，求和的是两个系统中同一个事件的信息量的差值，加的那个权重是其中一个系统里这个事件的概率值。从这里也能看出来，这里的系统<span class="math inline">\(S\)</span>和系统<span class="math inline">\(O\)</span>，它们并不是平等的，把<span class="math inline">\(S\)</span>和<span class="math inline">\(O\)</span>交换之后并不能保证得到相同的值。 <span class="math display">\[D_{KL}\left(S\,\|\,O\right)\neq D_{KL}\left(O\,\|\,S\right)\]</span> 也就是说，KL散度它相当于会在两个系统中挑选了一个作为基准（我这里用的是<span class="math inline">\(S\)</span>系统作为基准），拿另一个系统与这个基准进行比较。因为这是用<span class="math inline">\(S\)</span>系统的熵作为基准，去衡量另一个系<span class="math inline">\(O\)</span>的熵，所以KL散度也叫相对熵。</p><p>当KL散度给出来之后，用熵直接比较太简单粗暴的问题给解决了，但是这个东西我们应该怎么用呢？直接看KL散度的定义的话，还是很难想到怎么用的，不过只需要对KL散度的定义变变形，这个问题就会变得简单了。</p><p><img src="./4ac700e2f47237fc391422f788cbd2b5075fe19f.png@942w_261h_progressive.png" /></p><p>经过变形之后我们就能发现，KL散度可以被分成两个部分，其中后面的那个部分计算出来就是系统<span class="math inline">\(S\)</span>的熵，这部分算出来是多少是与系统<span class="math inline">\(O\)</span>无关的。所以，真正决定KL散度的其实是前面那部分，它的大小决定着KL散度的大小。</p><p>于是这部分就可以被单独拿出来讨论，所以<strong>它就被定义成为了交叉熵</strong>。想知道系统<span class="math inline">\(S\)</span>和系统<span class="math inline">\(O\)</span>是否一样，不需要去计算它们的KL散度，只需要去看它们的交叉熵。</p><p>我们的目标是什么，是希望机器学习模型中猜测出来的那个概率分布<span class="math inline">\(O\)</span>，与真实的概率分布<span class="math inline">\(S\)</span>接近。这个接近如果用KL散度来表示的话，就是KL散度要尽可能地接近数值0，正值太大、负值太小都不行。</p><p>那如果我们的目标不用KL散度来表示，而是用交叉熵来表示，应该是什么样子的呢？如果直接看前面推导出的那个式子，我们可以看到，我们的目标可以表示成交叉熵的值与系统<span class="math inline">\(S\)</span>的熵最接近时，目标达成。</p><p>但是这里也就有问题了，这代表着如何能找到最合适的交叉熵，要分两种情况来考虑：</p><ul><li>当交叉熵的值大于系统<span class="math inline">\(S\)</span>的熵时，我们的目标是寻找交叉熵最小的值</li><li>当交叉熵的值小于系统<span class="math inline">\(S\)</span>的熵时，我们的目标是寻找交叉熵最大的值</li></ul><p>这个时候，我们一般都会不禁地想，如果只有一种情况该多好啊，这样问题就简单了，我们寻找最接近系统<span class="math inline">\(S\)</span>的系统<span class="math inline">\(O\)</span>，就变成一个对交叉熵求最值的问题了，如果是第一种情况就是求最小值，如果是第二种情况就是求最大值。</p><p>我想数学家们也和我们有同样的想法，所以他们真的从数学上证明了，不需要两种情况都考虑，只需要考虑第一种情况。</p><p>这是因为，从数学上就可以证明，交叉熵的值一定是会大于等于系统<span class="math inline">\(S\)</span>的熵的。所以，只需要考虑如何对交叉熵求最小值就行了。一个系统与系统<span class="math inline">\(S\)</span>的交叉熵最小值，那么这个系统与S最接近。</p><p>这个证明过程就不写了，感兴趣的话，大家可以自己去了解一下<a href="https://zh.wikipedia.org/wiki/吉布斯不等式">吉布斯不等式</a>。（重点关注一下条件，概率值<span class="math inline">\(p_i\)</span>和<span class="math inline">\(q_i\)</span>是归一的，后面要用到）</p><p>至此，我们终于了解交叉熵到底是怎么来的，以及为什么交叉熵最小的时候，两个概率分布最接近。</p><p>但是，这个概念是如何应用到神经网络里面的？它对应的损失函数应该如何设计？为什么求交叉熵最小的方法，又可以被称为最大似然估计法？</p><h3 id="最小交叉熵和最大似然估计两种损失函数等价">“最小交叉熵”和“最大似然估计”两种损失函数等价</h3><p>要想把交叉熵这个概念应用到神经网络里面，那我们首先需要做的是把神经网络变成一个概率问题。假设说这是一个判断是猫是狗的二分问题，那么真实规律和神经网络猜测的规律，可以用下面两个概率分布来进行表示。</p><p>其中随机变量<span class="math inline">\(z\)</span>，表示这个规律对图片的判断结果。</p><p><img src="./5d5e5b42dfab7438fbdd16ec58eabb3a686c6941.png@942w_359h_progressive.png" /></p><p>于是，交叉熵就可以写成如下形式，（因为是归一的，所以可以用<a href="https://zh.wikipedia.org/wiki/吉布斯不等式">吉布斯不等式</a>，也就是KL散度可以转化成交叉熵问题）：</p><p><img src="./ab41c87fe55a68afff093d5a24e6ffaeeb5fef22.png@942w_144h_progressive.png" /></p><p>不过，只是这样的话，我们是没有办法计算交叉熵的，因为我们并不清楚<span class="math inline">\(P\left(z_i,\,x_i\,|\,\text{真实规律}\right)\)</span>和<span class="math inline">\(P\left(z_i,\,x_i\,|\,\text{猜测规律}\right)\)</span>的概率分布</p><p>我们知道是什么？</p><p>是<span class="math inline">\(P\left(z_i,\,x_i\,|\,\text{真实规律}\right)\)</span>和<span class="math inline">\(P\left(z_i,\,x_i\,|\,\text{猜测规律}\right)\)</span>的概率，这里不一样的是<span class="math inline">\(x_i\)</span>的位置，<span class="math inline">\(x_i\)</span>也就是输入的数据、猫狗的图片从原来的随机变量，变成了条件。</p><p>然后我们就可以得到下图的关系。其中<span class="math inline">\(\hat{y}\)</span>表示神经网络在输入图片后的计算结果，因为<span class="math inline">\(\hat{y}\)</span>经常是经过sigmoid计算后的结果，所以可以直接看做是一个概率值。</p><p><img src="./704b2dc51a6681951fb2f5d1bfc1dfa73d0e4534.png@942w_279h_progressive.png" /></p><p>从<span class="math inline">\(P\left(z_i,\,x_i\,|\,\text{真实规律}\right)\)</span>，到<span class="math inline">\(P\left(z_i\,|\,x_i,\,\text{真实规律}\right)\)</span>，我们知道中间差了一个<span class="math inline">\(P(x_i)\)</span> <span class="math display">\[P\left(z_i,\,x_i\,|\,真实规律\right)=P\left(z_i\,|\,x_i,\,真实规律\right)\cross P\left(x_i\right)\]</span> 于是交叉熵就可以写成下面的样子：</p><p><img src="./ddb7708dfaf12ffcd1570e4b5f273a4687845fe6.png@942w_135h_progressive.png" /></p><p>这里的<span class="math inline">\(P(x_i)\)</span>其实代表的就是，这个训练用的图片是按照什么概率从茫茫多的图片中抽样出来的。这个值我们并不清楚，不过训练集的图片我们基本上也就是认为它们是被随机挑选出来的，也就是说不同图片的概率应该都是相同的。于是P(xi)就可以看做是一个常数。</p><p>又因为我们希望求的是在交叉熵取最小值时的“猜测规律”的情况，所以当<span class="math inline">\(P(x_i)\)</span>是常数的时候，对最后的结果是不会有影响的。</p><p>也就是说：</p><p><img src="./1125e2d70ade5d39f2d5fe7ec93775dadff5b41a.png@942w_207h_progressive.png" /></p><p><img src="./fb6a922a72973f7dd35146c4960c9efcf70c1e4b.png@942w_224h_progressive.png" /></p><p>当然，我们更习惯的用法，其实是将猫狗用<span class="math inline">\(1\)</span>和<span class="math inline">\(0\)</span>来表示，如果说用<span class="math inline">\(1\)</span>表示是猫，<span class="math inline">\(0\)</span>表示是狗，那么<span class="math inline">\(y\)</span>作为图片的标签值有：猫的标签值<span class="math inline">\(y=1\)</span>，狗的标签值<span class="math inline">\(y=0\)</span>。于是前面的那个概率关系就可以变成如下的样子：</p><p><img src="./6fb867e1e224e8c75043c45e99a4b3dfb632d8dc.png@942w_362h_progressive.png" /></p><p>然后我们再对上面几种情况归纳整理一下，就可以得出最小交叉熵的最终表达形式了，其中<span class="math inline">\(i\in\left\{1,2,\cdots,n\right\}\)</span>，表示的是训练集图片有<span class="math inline">\(n\)</span>个，<span class="math inline">\(j\in\left\{1, 2\right\}\)</span>，表示这是一个二分类问题：</p><p><img src="./e88a8a33291cc7949a5f25cb202b1849b285c61a.png@942w_389h_progressive.png" /></p><p><img src="./c0858206816dd5da24c49d42d955b6b42a72bbf9.png@942w_186h_progressive.png" /></p><p>到了这一步，是不是就非常眼熟了？我们可以再把最开始吴恩达老师课程里的那个损失函数表达式拿下来看一下： <span class="math display">\[\mathscr{L}\left(\hat{y}, y\right) = -\left(y\log\hat{y} + \left(1-y\right)\log\left(1-\hat{y}\right)\right)\]</span> 是不是一模一样的？吴恩达老师给出的是一个图片的计算公式，如果考虑的是把所有图片的交叉熵都计算出来，就是我写出来的样子了。也就是说，最小交叉熵和最大似然估计，它们殊途同归，本质上是等价的。</p><p>当然，这里还有多提一下，从数学上来看，最小交叉熵和最大似然估计是等价的，但是硬要较真儿的话，两个方法在物理上还是不同的。因为，交叉熵是有量纲的，而似然值没有量纲，最大似然值最后之所以会出现log和负号，也只是为了计算的方法，本身并没有物理意义。交叉熵就不同了，它的log和负号，是让它有单位的关键。</p><h3 id="references">References</h3><p>https://www.bilibili.com/video/BV15V411W7VB?spm_id_from=333.999.0.0</p><p>https://www.bilibili.com/read/cv15258489?spm_id_from=333.999.0.0</p><p>https://baike.baidu.com/item/奥卡姆剃刀原理/10900565?fr=aladdin</p><p>https://zh.wikipedia.org/wiki/吉布斯不等式</p><hr /><p><strong><em>知识来源作者为b站UP主王木头学科学</em></strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>人工智能</tag>
      
      <tag>熵</tag>
      
      <tag>信息量</tag>
      
      <tag>机器学习</tag>
      
      <tag>神经网络</tag>
      
      <tag>深度学习</tag>
      
      <tag>损失函数</tag>
      
      <tag>交叉熵</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>“损失函数”是如何设计出来的？直观理解“最小二乘法”和“极大似然估计法”</title>
    <link href="/2022/02/13/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    <url>/2022/02/13/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p>在吴恩达的课程中提到了两个公式分别是最小二乘法和极大似然估计 <span class="math display">\[\mathscr{L}\left(\hat{y}, y\right) = \frac{1}{2}\left(\hat{y}-y\right)^2\]</span></p><p><span class="math display">\[\mathscr{L}\left(\hat{y}, y\right) = -\left(y\log\hat{y} + \left(1-y\right)\log\left(1-\hat{y}\right)\right)\]</span></p><p>本章要解决的问题：</p><ol type="1"><li>直观的理解损失函数是什么， 为什么这么重要</li><li>吴恩达老师给出的两个损失函数分布是最小二乘法和极大似然估计，他们是怎么来的， 为什么叫这个名字</li><li>最小二乘法和极大似然估计有什么联系</li></ol><h3 id="损失函数的作用">损失函数的作用</h3><p>在弄明白损失函数是如何设计出来之前，我们得先清楚损失函数的作用是什么</p><p>首先如果我们要判断一张照片是不是猫，对于人来说是很简单的我们只需要看一眼便有了答案。如果让我们去制定一个标准来认定符合什么的是猫符合什么的不是猫其实并没有那么容易，但在我们心里我们知道是有那么一个定义或者规律的。</p><p>所以对于机器来说我们并不需要直接告诉他们去判断一个物品是什么的准确标准是什么，而是让他们学习找到这个规律。 具体过程就是先判断再比较然后调整，一直循环这个过程。而损失函数就是用来比较这个环节用来比较模型的判断和我们脑中的判断的差距有多大。</p><p>通过损失函数我们能知道当前模型和我们脑中的模型的一个差值， 然后我们可以通过比如梯度下降来把损失函数计算出来的差值分配给各个参数。使用梯度下降的好处就是我们可以知道具体哪个参数贡献的差值较多哪个较少。最后通过调整参数然后一遍一遍的判断计算损失值修改我们最后把差值降低到一定的范围之内。</p><h3 id="最小二乘法是怎么得出来的">“最小二乘法”是怎么得出来的</h3><p>想要获得真实规律和神经网络里规律的差值我们就需要设计出损失函数对他们进行比较，但我们无法将真实规律和模型的规律进行直接比较因为我们并不知道真实的规律。</p><p>庆幸的是我有已经打好标签的数据集，这些数据我们已经知道正确结果了，换句话来说这些标签其实就是真实规律的判读结果。那既然我们无法直接比较规律我们就可以比较他们判断的结果。如果我们猜测的规律就是真实规律的话， 那么神经网络的判断结果一定和数据标签一致。<span class="math inline">\(\hat{y}\)</span>是神经网络判断的结果， <span class="math inline">\(y\)</span>是标签的真实结果，那么损失函数就可以设计成， 把数据集里所有数据都放到神经网络判断一遍，挨个比较猜测的结果和真实的结果，看看它们之间差了多少，然后把所有的差值都加起来。 <span class="math display">\[\sum_{i=1}^{n} \left| \hat{y}_i-y_i \right|\]</span> 我们都知道，绝对值这个函数并不是全定义域都可导的，而随后求最小值还要进行求导，所以我们就可以把绝对值换成平方（还额外加了一个系数<span class="math inline">\(\frac{1}{2}\)</span>，这是因为求导的时候指数部分的<span class="math inline">\(2\)</span>会拿下来，可以和<span class="math inline">\(\frac{1}{2}\)</span>抵消）。 <span class="math display">\[\sum_{i=1}^{n} \frac{1}{2} \left( \hat{y}_i-y_i \right)^2\]</span> 于是寻找最接近真实规律的过程，就可以描述成是求上面这个式子最小值的过程，而这就是最小二乘法，二乘其实就是以前对平方的一种称呼。</p><h3 id="如果深度学习是个概率问题">如果深度学习是个概率问题</h3><p>第一个式子是怎么设计出来的，这个问题我解决了。那第二个式子又是如何设计出来的？它又为什么叫做极大似然估计法，似然又是个啥？</p><p>要想明白这些，就需要切换一下视角了，需要从概率的视角来看深度学习问题。</p><p>怎么切换成概率呢？我们可以先来看一下最理想的情况，比如，我们可以想象一下，把真实规律用概率分布的方式表示出来，会是什么样子。 （假如说就是判断是一个非猫即狗的二分问题）</p><p><img src="./c9ae479fee42ac6ebd90dcb960aec72ec926bd5f.png@942w_564h_progressive.png" /></p><p>也就是说，只要图片是猫，那么判断的结果一定不会是狗；如果图片是狗，那么判断的结果就一定不是猫，没有任何判断错误的情况出现。（注意：“具体一个猫的图片判断结果也是猫”这个事件的概率并不等于1，“所有猫的图片都判断成猫”、“所有狗的图片都判断成狗”，它们这些事件的概率全加起来才是1）</p><p>但是我们猜测出来的规律呢？虽然仍然可以用一个概率分布来表示，但是就没有这么准了，就算是给了一张猫的图片，但是神经网络还是有概率把它判断成狗。最理想的情况，当然是让我们猜测出来的规律可以和真实规律的概率分布一模一样，但现实是，我们几乎不可能得到和真实规律一模一样的规律，只能近似。（这个原因，需要对PAC框架和VC维理论有比较深入的理解之后才能解释清楚，这里就不多解释了。可以简单的理解为，任何一种机器学习的模型能力都是有限的，所以无法学到真实规律。）</p><p>不过，不论这么样，不论是真实的规律，还是我们猜测的规律，都可以用一个条件概率分布来呈现。我们得到的数据集里面打好标签的数据，其实就是在真实规律这个概率分布下进行抽样得到的结果，而深度学习的过程，就是我们已经有了样本数据，去反推背后概率分布是什么的过程。</p><p>这就相当于，你有一个不知道正反概率是什么的硬币，抛了10次结果是7正3反，如何才能反推出这个硬币正反的真实概率。</p><h3 id="已知样本数据-如何反推概率分布">已知样本数据， 如何反推概率分布</h3><p>如何才能反推出硬币真实的概率呢？投了10次，7正3反，是不是说硬币的概率就一定是正面的概率是0.7，反面的概率是0.3呢？</p><p>这么想很符合我们的直觉，但这并不是一件板上钉钉的事情。</p><p>你可以想一下，假如说，我们的硬币是正反概率都是0.5的话，你抛10次，难道就真的能保证一定是5次正、5次反吗？不一定吧，出现6正4反，4正6反也还是挺常见的吧。更甚者，运气好到极点，10次全部是正面也是有可能的。</p><p>那么，当我们不知道硬币正反概率的时候，7正3反，就一定0.7的概率吗？也不一定，对吧。完全有可能是，硬币的概率是0.1正、0.9反，但是运气就是很好，抛出了7正3反的结果。或者是，概率本来是0.8正、0.2反，但是运气就差那么一点，抛出了7正3反。</p><p><img src="./bacfcc010cdd58ecb38063d4ee08b6153b150c0a.png@942w_567h_progressive.png" /></p><p>也就是说，我们知道抛硬币的结果（抽样结果），我们没有办法唯一确定一个真实的概率（背后的规律）。就像前面看到的，7正3反的硬币结果，没有办法排除掉任何一种概率，它们都有可能。</p><p>不过，虽然我们没有办法百分百确定样本背后的概率分布原本是什么样子的，但是我们还是可以确定，最有可能情况是什么。</p><p>比如，<span class="math inline">\(C_1\)</span>~<span class="math inline">\(C_{10}\)</span>代表着10次抛硬币的结果，<span class="math inline">\(\theta\)</span>是硬币决定正反概率的属性（这个属性是未知的；也可以直接理解为硬币固有的概率属性），那么抛10次硬币有7次是正面对应的概率就是等号右边这么多。 <span class="math display">\[P\left(C_1, C_2, C_3, \cdots, C_{10}\,|\, \theta\right)=\binom{10}{7}\prod_{i=1}^{10}P\left(C_i\,|\,\theta\right)\]</span> 有了这个式子之后，我们就可以算出来，如果硬币抛出来正面朝上的概率分别是0.1、0.7和0.8的时候，要想得到抛10次硬币7次朝上的概率分布是多少。</p><p><img src="./4ab09f469008f93a1341e23ac2e8751e2a68c27f.png@942w_572h_progressive.png" /></p><p>大家算一下就知道，显然当正面概率是0.7的时候，发生的概率是最大的。</p><p>所以，我们直觉上觉得抛10次硬币7次正面，硬币的概率应该是0.7，不是没有根据的，这种情况与其他的情况想比，的确是可能性最大的。其实对于任何已经知道了样本，想要反推背后的概率分布，都可以用类似的思路。这种思路，虽然没有办法百分百的知道真实的情况是什么，但是显然猜0.7是正面，这样的正确的可能性最大。对应到深度学习里面也一样，也是已知了一堆样本数据，目的是想办法反推出生成样本数据的真实概率分布。虽然没有办法百分百确定是哪一个，但是我们还是有办法确定哪一个的可能性最大。</p><p>而这个思路，就是最大似然估计法的思路，其中的“最大”这个词，对应的就是前面说的可能性最大。至于为什么是似然值，而不是概率值，这个就用解释一下似然值和概率值的区别了。</p><h3 id="似然和概率有什么不一样">“似然”和“概率”有什么不一样</h3><p>什么是似然值？首先，它也是用来表示可能性的，但是它又和概率描述的问题不一样。就比如，<span class="math inline">\(C\)</span>代表了硬币是正还是反，<span class="math inline">\(\theta\)</span>是硬币决定正反概率的属性。 <span class="math display">\[P\left(C\, | \,\theta\right)\]</span> 这是一个概率分布的前提是，<span class="math inline">\(C\)</span>是随机变量。随机变量是什么意思呢？其实就是在说，当<span class="math inline">\(\theta\)</span>是一个固定值的时候，把所有<span class="math inline">\(C\)</span>的可能取值都考虑进来，把它们对应的概率值加起来，最后的结果是归一的。 <span class="math display">\[\sum_{x\in All}P\left(C = x\,|\,\theta=a\right)=1\]</span> 但是我们可以想一下，在前面我们的问题是什么？我们面临的问题是，<span class="math inline">\(C\)</span>是一个确定的值（也就是样本已经确定了），未知的是<span class="math inline">\(\theta\)</span>。<span class="math inline">\(\theta\)</span>是一个条件，它不是随机变量，也就是说如果把全部<span class="math inline">\(\theta\)</span>的取值都考虑进来，它并不要求满足归一。也就是下式不一定等于1。 <span class="math display">\[\sum_{x\in All}P\left(C = b\,|\,\theta=x\right)\neq1\]</span> 了解这些之后，我们应该就能明白了，如果我们设计一个函数，它的变量是<span class="math inline">\(\theta\)</span>： <span class="math display">\[\mathscr{L}\left(\theta\right)=P\left(C\,|\,\theta\right)\]</span> 这个L函数的结果，虽然还是一个概率值，也能表示某个事件发生的可能性，但是它又和概率分布的概率不太一样。概率如果写成函数的话，变量一定是随机变量才对，而这里变量是条件。</p><p>而我们在已知某个抽样结果后，反推那种情况的可能性最大，其实就是在求这个L函数的最大值。</p><p>至于这个函数呢？因为和概率表达意义不同，所以就被赋予了一个新的名字，似然函数。我们说的最大似然估计法，其实就是在说，要求出似然函数的最大值，这个最大值对着的就是最有可能的规律。</p><h3 id="最大似然估计法为什么要写成这个样子">“最大似然估计法”为什么要写成这个样子</h3><p>最大似然估计法到底是什么意思，我们已经知道了，剩下的就是神经网络里面的最大似然法为什么写出来是这个样子的。 <span class="math display">\[\mathscr{L}\left(\hat{y}, y\right) = -\left(y\log\hat{y} + \left(1-y\right)\log\left(1-\hat{y}\right)\right)\]</span> 我们先来看一下前面的抛硬币的例子。在这个例子里面，我们已经知道了抛硬币的结果，求原本的硬币概率是多少。如果把抛硬币的例子和神经网络对应起来的话，抛硬币的结果对应的就是已经有的数据集<span class="math inline">\(\left&lt;x_i,\,y_i\right&gt;\)</span>，求硬币的概率<span class="math inline">\(\theta\)</span>对应到神经网络里面就是求所有的参数<span class="math inline">\(W,\,b\)</span>。</p><p>有了这个对应之后，我们就比较容易思考了，于是就有如下：</p><p><img src="./2eddf21423ed4fc545d7a150c5e507473c817487.jpg@942w_531h_progressive.jpg" /></p><p>经过上面的整理之后，就得到了似然函数的表达式了。我们的目标，也就是最接近真实规律的神经网络的参数<span class="math inline">\(\left(W,\,b\right)\)</span>，其实就是求上式在取得最大值时<span class="math inline">\(W,\,b\)</span>分别等于什么。</p><p>(在求最大值的时候灰色部分是可以忽略的。特别是P(xi)，这是因为我们默认数据集是优质的数据集，数据集里的图片都是相互独立的，而且应该是等概率的。如果这部分有问题，那就需要重新整理数据集，让数据集尽可能满足这个条件。)</p><p><img src="./ae305c47cc4014af3104a0a4dabc3db2de9f4e1b.jpg@942w_531h_progressive.jpg" /></p><p>通过上面的推导，就可以看出来了，为什么吴恩达老师的最大似然估计法的式子要写成那个样子了。</p><h3 id="最小二乘法可以等价于最大似然估计法">“最小二乘法”可以等价于“最大似然估计法”</h3><p>本来，讲到这里，最开始我们所有的问题就都已经解决了。不论是是最小二乘法，还是极大似然估计法，它们其实都是用来比较神经网络猜测的那个规律和真实的规律的方法。</p><p>最小二乘法认为，当所有的误差的平方值最小时，神经网络里面猜测的规律与真实的规律最接近。最大似然估计法则认为，当似然值最大的时候，猜测的规律与真实的规律最接近。</p><p>如果就是这么看的话，最小二乘法好像和极大似然估计法是两套不想干的判断标准，最后选择哪个好像就是一个偏好问题。</p><p>但其实如果对最小二乘法的本质有所了解的话，就会发现从某种程度上来说，最小二乘法与最大似然估计在底层是相通的。</p><p>为什么这么说呢？</p><p>我们可以看看最小二乘法最后求出来的最值是什么。为了简化问题，我们把Y当做变量，代表不同<span class="math inline">\(W,\,b\)</span>下神经网络得出的判断结果。这样的话，损失函数就可以写成： <span class="math display">\[J\left(Y\right) = \sum_{i=1}^n\frac{1}{2}\left(Y-y_i\right)^2\]</span> 当损失函数取值最小的时候，<span class="math inline">\(Y\)</span>等于什么，我们可以通过求导的方式求出来，因为<span class="math inline">\(J\)</span>函数最小值的时候，导数一定为0。于是就有： <span class="math display">\[\frac{\mathrm{dJ} }{\mathrm{d} x} = 0 \\\Rightarrow \sum_{i=1}^n\left(Y-y_i\right) = 0\\\Rightarrow Y = \frac{\sum_{i=1}^ny_i}{n}\hspace{7mm}\\\Rightarrow Y = \bar{y}\hspace{23mm}\]</span> 从这里就可以看出来，当<span class="math inline">\(Y\)</span>等于所有<span class="math inline">\(y_i\)</span>的平均值时得到最小值。</p><p>如果只是进行到这一步的话，我们还什么都看不出来。但是我们还可以把<span class="math inline">\(Y-y_i\)</span>看做是神经网络的判断结果与真实结果的误差，也就是： <span class="math display">\[\varepsilon = Y - y_i\]</span> 那么我们是可以把数据集里每个数据对应的<span class="math inline">\(\varepsilon\)</span>看做抽样结果，也就相当于前面抛硬币例子里面7正3反的结果。这样的话，我们其实是可以利用最大似然估计法的。(注意这里用最大似人估计法时，随机变量是误差<span class="math inline">\(\varepsilon\)</span>，而前面用最大似然估计法的时候随机变量是判断结果<span class="math inline">\(y_i\)</span>，这还是有些不一样的。)</p><p>利用最大似然估计法的话，可以得到似然函数如下: <span class="math display">\[L(Y) = P\left(\varepsilon_1,\varepsilon_2,\cdots,\varepsilon_n\,|\,Y\right)\\=\prod_{i=1}^{n}P(Y-y_i)\hspace{1mm}\]</span> 求最大值，其实就是下面的函数对<span class="math inline">\(Y\)</span>求导等于0： <span class="math display">\[\frac{\mathrm{dL} }{\mathrm{d} Y} = 0\]</span> 具体这里的最大值求出来是多少我们先放一下，但是在前面我们已经知道，用最小二乘法已经求出来了，当Y等于yi的平均值时，是我们的目标。而最小二乘法和极大似然估计法，它们虽然用到了不同的思路，但都是在解决同一个问题，那我们是不是可以认为，它们其实是殊途同归的，最后的答案都是<span class="math inline">\(Y\)</span>应该等于<span class="math inline">\(y_i\)</span>的平均值。</p><p>如果真的可以做出这样的假设的话，那把平均值这个答案带到最大似然估计法里面，就可以去反推一下这个概率分布是什么样子的了。带进去之后，就会发现，这个概率分布的概率密度函数如下： <span class="math display">\[f\left(\varepsilon\right)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{\varepsilon^2}{2\sigma^2}}\]</span> 这是什么？这就是正态分布啊。</p><p>于是最小二乘法和最大似然估计法的关系就变成了这样：如果我们认定神经网络得到的结果与真实情况的误差，是属于正态分布的话，那么最小二乘法与极大似然估计法是等价的。</p><p>我们都知道正态分布最开始是被高斯最先提出来的，他提出来的思路是什么？虽然细节上可能会有差别，但是大体上他就是做了类似的思考，也就是认为最小二乘法和极大似然估计法应该殊途同归，然后计算得出了正态分布的表达式。</p><p>所以，最小二乘法和极大似然估计法，虽然形式上非常不同，但是它们本质上还是相通的。只不过，最小二乘法比极大似然估计法多了一个前提，那就是它要求误差的分布属于正态分布，只有这样的时候，最小二乘法和极大似然估计法才是等价的。</p><p>其实，最大似然估计法很多人也把它称为交叉熵法，这是因为极大似然估计法和交叉熵方法是彻彻底底的等价，而不是最小二乘法这种有条件的等价。</p><h3 id="references">References</h3><p>https://www.bilibili.com/read/cv14977249?spm_id_from=333.999.0.0</p><p>https://www.bilibili.com/video/BV1Y64y1Q7hi?spm_id_from=333.999.0.0</p><p>https://www.bilibili.com/video/BV1FT4y1E74V?from=search&amp;seid=1554295885016367140&amp;spm_id_from=333.337.0.0</p><hr /><p><strong><em>知识来源作者为b站UP主王木头学科学</em></strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>神经网络</tag>
      
      <tag>损失函数</tag>
      
      <tag>机器学期</tag>
      
      <tag>最小二乘法</tag>
      
      <tag>极大似然估计</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>卷积神经网络模型</title>
    <link href="/2021/12/04/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"/>
    <url>/2021/12/04/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h3 id="卷积神经网络lenet">卷积神经网络（LeNet)</h3><figure><img src="https://miro.medium.com/max/1400/1*1TI1aGBZ4dybR6__DI9dzA.png" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>模型结构</strong>：卷积层块， 全链接层块</p><ul><li>卷积层块：2个<strong>卷积层 + 最大池化层</strong> 的结构组成。 由于LeNet是较早的CNN， 在每个卷积层 + 池化层后多会跟一个sigmod层 来修正输出结果。 而现在用的较多的是Relu。</li><li>全连接层块：输入为二维向量。 单卷积层块的输出传入全连接层的时候会对小批量对每个样本进行扁平化（flatten）</li></ul><p>LeNet 会随着网络的加深，宽度逐渐降低，通道逐渐增多。</p><h3 id="深度卷积神经网络alexnet">深度卷积神经网络（AlexNet）</h3><h3 id="scheme-of-the-alexnet-network-used.-download-scientific-diagram"><img src="https://www.researchgate.net/publication/320052364/figure/fig1/AS:543136445198336@1506505227088/Scheme-of-the-AlexNet-network-used.png" alt="Scheme of the AlexNet network used. | Download Scientific Diagram" /></h3><p><strong>模型结构</strong>：5层卷积 + 2层全连接隐藏层 + 1层全连接输出层</p><ul><li>卷积层： 前2个用的分别是11x11和5x5的卷积核，其余的都是3x3的卷积核。 第一， 第二， 第五个卷积层后都使用了3x3，步幅为2 的最大池化层。</li><li>全连接层：2个输出个数为4096的全连接层携带着将近1GB的模型参数。</li><li>激活函数：AlexNet使用了Relu激活函数。相比于sigmod，Relu有着更简单的计算并且在不同初始化的情况下更容易训练。例如在一些特殊初始化下， sigmod在正区间的输出极度接近0， 这会导致模型很难继续更新，而Relu在正区间的值恒为1。</li><li>过拟合：AlexNet使用了丢弃法来控制模型复杂度和防止过拟合。并且它用了大量的图象增广， 包括翻转， 裁剪， 改变颜色等，来进一步防止过拟合。</li></ul><h3 id="使用重复元素的网络vgg">使用重复元素的网络（VGG）</h3><figure><img src="https://www.researchgate.net/profile/Max-Ferguson/publication/322512435/figure/fig3/AS:697390994567179@1543282378794/Fig-A1-The-standard-VGG-16-network-architecture-as-proposed-in-32-Note-that-only.png" alt="Fig. A1. The standard VGG-16 network architecture as proposed in [32].... | Download Scientific Diagram" /><figcaption aria-hidden="true">Fig. A1. The standard VGG-16 network architecture as proposed in [32].... | Download Scientific Diagram</figcaption></figure><p><strong>模型结构</strong>：VGG块 + 全连接层块</p><ul><li>VGG块：卷积层 + 池化层， 卷积层都是用相通的填充为1，3x3的卷积核接上一个步幅为2 ， 窗口为2x2的最大池化层</li><li>全连接层块：与LeNet相似</li></ul><p>VGG是个十分对称的网络，每层都成倍的增加或者减少。相比AlexNet它提供了一种简单固定的卷积模型和深度模型的构建思路。</p><h3 id="网络中的网络nin">网络中的网络（NiN）</h3><figure><img src="https://miro.medium.com/max/1400/1*fWGsLkUnDaWz7KbIlRt9Hg.png" alt="An overview of VGG16 and NiN models | by Khuyen Le | MLearning.ai | Medium" /><figcaption aria-hidden="true">An overview of VGG16 and NiN models | by Khuyen Le | MLearning.ai | Medium</figcaption></figure><p><strong>模型结构</strong> ： NiN块</p><ul><li>NiN块：AlexNet是用多个卷积层 + 全连接层输出的结构，NiN提出了另一种思路， 它通过将小块<strong>卷积层+“全连接”层</strong>串联组成网络。由于全连接层是二维而卷积层通常来说是四维的， 所以NiN块使用1x1的卷积层代替全连接层（期中空间维度（高宽）上的每一个元素相当于样本，通道相当于特征）。每个卷积层与AlexNet类似，都是11x11， 5x5， 3x3.并且每个NiN块后接一个步幅为2，窗口大小为3x3的最大池化层。</li></ul><p>相比AlexNet，NiN去掉了最后3个全连接层，使用输出通道等于标签类别的NiN块， 然后使用全局平局池化层对每个通道中所有元素求平均并直接用于分类。 这个好处是可以显著减小模型参数尺寸， 但会造成训练时间的增加。</p><h3 id="含有并行连接的网络googlenet">含有并行连接的网络（GoogLeNet）</h3><figure><img src="https://pytorch.org/assets/images/googlenet1.png" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li>Inception块：GoogLeNet的基础块，它借鉴NiN的网络串联网络的思路。 在每个Inception块中包含4条并行线路。前3条分别使用1x1， 3x3， 5x5的卷积层来抽取不通空间尺度下的特征信息， 期中第二三条线中先使用了1x1的卷积层来减少输入通道数，以降低模型复杂度。 最后一条使用3x3的最大池化层接1x1的卷积层来改变通道数。4条线都适用合适的填充来保证输入和输出的高宽一致。</li></ul><figure><img src="https://miro.medium.com/max/2542/1*rXcdL9OV5YKlYyks9XK-wA.png" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h3 id="残差网络resnet">残差网络（ResNet)</h3><figure><img src="https://d2l.ai/_images/resnet-block.svg" alt="7.6. Residual Networks (ResNet) — Dive into Deep Learning 0.17.2 documentation" /><figcaption aria-hidden="true">7.6. Residual Networks (ResNet) — Dive into Deep Learning 0.17.2 documentation</figcaption></figure><ul><li>残差块：一般来说对于激活函数的输入是神经网络一层层的计算的输出结果，但是由于网络的不断加深容易出现梯度不稳定（梯度爆炸，梯度消失）。随着网络的逐渐加深，误差并不会越来越小残差块的目的就是为了解决梯度不稳定。 它通过一种跳跃的连接方式让输出结果需要参考输入结果。</li></ul><figure><img src="https://miro.medium.com/max/874/1*R-Yzqn6VLmIyITO3ZxA1sQ.png" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li>残差块原理：<span class="math inline">\(a^{[l+2]}=g(z^{[l+2]}+a^{[l]})=g(w^{[l+2]}a^{[l+1]} + b^{[l+2]}a^{[l]})\)</span> 我们现在不考虑 <span class="math inline">\(b^{[l+2]}\)</span>, 当发生梯度消失的时候， <span class="math inline">\(w^{[l+2]}=0\)</span>, 此时<span class="math inline">\(a^{[l+2]}=g(a^{[l]})\)</span>, 相当于把第一层的输出直接经过Relu输出。并不会因为梯度消失产生负面的影响。</li></ul><h3 id="稠密连接网络densenet">稠密连接网络（DenseNet）</h3><p><img src="https://pytorch.org/assets/images/densenet1.png" alt="img" style="zoom:60%;" /></p><p><strong>模型结构</strong>：稠密层 + 过渡层</p><ul><li>稠密层：DenseNet和ResNet十分相似，区别在于DenseNet不像ResNet将前一个模块的输出直接加到模块的输出上而是直接在通道上进行叠加</li><li>过渡层：为了防止通道数一直叠加导致模型复杂度过大，过渡层通过使用1x1的卷积层减小通道数，并使用步幅为2的平均池化层减半高宽进一步降低复杂度。</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kaggle--图像分类(CIFAR-10) 基于Pytorch的实现</title>
    <link href="/2021/08/29/Kaggle%20-%20%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB(CIFAR-10)/"/>
    <url>/2021/08/29/Kaggle%20-%20%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB(CIFAR-10)/</url>
    
    <content type="html"><![CDATA[<blockquote><p>CIFAR-10 是计算机视觉领域中一个非常重要的数据集. 它由Hinton的学生Alex Krizhevsky 和 Ilya Sutskever整理的小型数据集. 其中包括 10 个不同类别的RGB 3通道 32 * 32 的图像: 飞机 (airplane)、汽车 (automobile)、鸟类 (bird)、猫 (cat)、鹿(deer)、狗(dog)、蛙类(frog)、马(horse)、船(ship) 和卡车 (truck). 我们可以直接从Kaggle官网获得数据集 https://www.kaggle.com/c/cifar-10. 其中包含一个test文件和train文件. test 文件中有60000张图像, 每个类各有6000张. train文件中包含300000万张图像, 其中只有10000张作为测试, 省下的是Kaggle为了防止人工标记数据集的额外数据.</p></blockquote><h2 id="整理数据集">1. 整理数据集</h2><p>首先我们先导入一些必要的库</p><figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> shutil<br><span class="hljs-keyword">import</span> collections<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> models<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>data_dir = <span class="hljs-string">&quot;C:\\Users\\***\\OneDrive\\桌面\\kaggle\\CIFAR-10&quot;</span><br></code></pre></td></tr></table></figure><p>我们需要对数据集进行整理以一遍训练和测试使用. 函数<strong>read_labels</strong>用来读取训练集的标签文件并以 <strong>name: label</strong> 的字典形式储存.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_labels</span>(<span class="hljs-params">file</span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        lines = f.readlines()[<span class="hljs-number">1</span>:]<span class="hljs-comment">#从1开始读是为了排除文件的title行</span><br>    tokens = [l.rstrip().split(<span class="hljs-string">&#x27;,&#x27;</span>) <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">dict</span>((name, label) <span class="hljs-keyword">for</span> name, label <span class="hljs-keyword">in</span> tokens)<br></code></pre></td></tr></table></figure><p>我们使用一种非常常规的数据处理方法将文件每个标签作为一个文件夹储存对应的图片, 但这种方法并不高效, 我们相当于把所有图片copy了一次, 当数据量非常大到时候这个方法可能会过于耗时.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">copyfile</span>(<span class="hljs-params">filename, target_dir</span>):<span class="hljs-comment">#将图片复制到对应文件夹, 如果文件夹不存在则创建文件夹</span><br>    os.makedirs(target_dir, exist_ok=<span class="hljs-literal">True</span>)<br>    shutil.copy(filename, target_dir)<br></code></pre></td></tr></table></figure><p>下面我们对所有图片进行reorganize, 其中valid_ratio是验证集样本和原始数据集样本的比 (我们需要把数据急分成两部分一部分用作验证一部分用作训练, 由于数据量并不是很小所以不需要做k折交叉验证). 让我们以 valid_ratio=0.1 为例，由于原始的训练集有 50000 张图像，因此 train_valid_test/train 路径中将有 45000 张图像⽤ 于训练，而剩下 5000 张图像将作为路径 train_valid_test/valid 中的验证集。组织数据集后，同类别的图像将被放置在同⼀⽂件夹下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">reorg_train_valid</span>(<span class="hljs-params">data_dir, labels, valid_ratio</span>):<br>    n = collections.Counter(labels.values()).most_common()[-<span class="hljs-number">1</span>][<span class="hljs-number">1</span>]<span class="hljs-comment">#每一个标签的数量</span><br>    n_valid_per_label = <span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>, math.floor(n * valid_ratio))<span class="hljs-comment">#验证集中每个标签的数量</span><br>    label_count = &#123;&#125;<br>    <span class="hljs-keyword">for</span> train_file <span class="hljs-keyword">in</span> os.listdir(os.path.join(data_dir, <span class="hljs-string">&#x27;train&#x27;</span>)):<br>        label = labels[train_file.split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>]]<br>        filename = os.path.join(data_dir, <span class="hljs-string">&#x27;train&#x27;</span>, train_file)<br>        copyfile(filename, os.path.join(data_dir, <span class="hljs-string">&#x27;train_valid_test&#x27;</span>, <span class="hljs-string">&#x27;train_valid&#x27;</span>, label))<br>        <span class="hljs-keyword">if</span> label <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> label_count <span class="hljs-keyword">or</span> label_count[label] &lt; n_valid_per_label:<br>            copyfile(filename, os.path.join(data_dir, <span class="hljs-string">&#x27;train_valid_test&#x27;</span>, <span class="hljs-string">&#x27;valid&#x27;</span>, label))<br>            label_count[label] = label_count.get(label, <span class="hljs-number">0</span>) + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">else</span>:<br>            copyfile(filename, os.path.join(data_dir, <span class="hljs-string">&#x27;train_valid_test&#x27;</span>, <span class="hljs-string">&#x27;train&#x27;</span>, label))<br>    <span class="hljs-keyword">return</span> n_valid_per_label<br></code></pre></td></tr></table></figure><p>然后我们再定义一个函数对测试集进行整理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">reorg_test</span>(<span class="hljs-params">data_dir</span>):<br>    <span class="hljs-keyword">for</span> test_file <span class="hljs-keyword">in</span> os.listdir(os.path.join(data_dir, <span class="hljs-string">&#x27;test&#x27;</span>)):<br>        copyfile(os.path.join(data_dir, <span class="hljs-string">&#x27;test&#x27;</span>, test_file),<br>                 os.path.join(data_dir, <span class="hljs-string">&#x27;train_valid_test&#x27;</span>, <span class="hljs-string">&#x27;test&#x27;</span>, <span class="hljs-string">&#x27;unknown&#x27;</span>))<br>      <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">reorg_CIFAR10</span>(<span class="hljs-params">data_dir, valid_ratio</span>):<br>    labels = read_labels(os.path.join(data_dir, <span class="hljs-string">&#x27;trainLabels.csv&#x27;</span>))<br>    reorg_train_valid(data_dir, labels, valid_ratio)<br>    reorg_test(data_dir)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size = <span class="hljs-number">128</span><br>valid_ratio = <span class="hljs-number">0.1</span><span class="hljs-comment"># 10% 的训练集数据作为验证集</span><br>reorg_CIFAR10(data_dir, valid_ratio)<br></code></pre></td></tr></table></figure><h2 id="图像增广">2. 图像增广</h2><p>为了防止过拟合我们对图像进行增强, 由于测试集只用作测试所以我们字对其做标准化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">transform_train = torchvision.transforms.Compose([<br>    torchvision.transforms.Resize(<span class="hljs-number">40</span>),<span class="hljs-comment"># 这里吧图像放大到 40*40 后在按比例取32*32是为了取局部特征</span><br>    torchvision.transforms.RandomResizedCrop(<span class="hljs-number">32</span>, scale=(<span class="hljs-number">0.64</span>, <span class="hljs-number">1.0</span>), ratio=(<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>)),<br>    torchvision.transforms.RandomHorizontalFlip(),<span class="hljs-comment"># 垂直翻转</span><br>    torchvision.transforms.RandomVerticalFlip(),<span class="hljs-comment"># 水平翻转</span><br>    torchvision.transforms.ToTensor(),<br>    torchvision.transforms.Normalize([<span class="hljs-number">0.4914</span>, <span class="hljs-number">0.4822</span>, <span class="hljs-number">0.4465</span>], [<span class="hljs-number">0.2023</span>, <span class="hljs-number">0.1994</span>, <span class="hljs-number">0.2010</span>]),<br>    torchvision.transforms.ColorJitter(brightness=<span class="hljs-number">0.5</span>, contrast=<span class="hljs-number">0.5</span>, saturation=<span class="hljs-number">0.5</span>, hue=<span class="hljs-number">0.5</span>) <span class="hljs-comment"># 百分之五十的概率对曝光, 对比度, 饱和度, 色调进行变换</span><br>])<br><br>transform_test = torchvision.transforms.Compose([<br>    torchvision.transforms.ToTensor(),<br>    torchvision.transforms.Normalize([<span class="hljs-number">0.4914</span>, <span class="hljs-number">0.4822</span>, <span class="hljs-number">0.4465</span>], [<span class="hljs-number">0.2023</span>, <span class="hljs-number">0.1994</span>, <span class="hljs-number">0.2010</span>])<br>])<br></code></pre></td></tr></table></figure><h2 id="读取数据集">3. 读取数据集</h2><p>接下来问他们用torchvision.datasets.ImageFolder实例来读取不同的数据集包括每张图片的标签.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">train_ds, train_valid_ds = [<br>    torchvision.datasets.ImageFolder(<br>        os.path.join(data_dir, <span class="hljs-string">&#x27;train_valid_test&#x27;</span>, folder),<br>        transform=transform_train<br>    ) <span class="hljs-keyword">for</span> folder <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;train&#x27;</span>, <span class="hljs-string">&#x27;train_valid&#x27;</span>]<br>]<br><br>valid_ds, test_ds = [<br>    torchvision.datasets.ImageFolder(<br>        os.path.join(data_dir, <span class="hljs-string">&#x27;train_valid_test&#x27;</span>, folder),<br>        transform=transform_test<br>    ) <span class="hljs-keyword">for</span> folder <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;valid&#x27;</span>, <span class="hljs-string">&#x27;test&#x27;</span>]<br>]<br></code></pre></td></tr></table></figure><p>使用DataLoader对数据进行图像增广的操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">train_iter, train_valid_iter = [<br>    DataLoader(<br>        dataset, batch_size, shuffle=<span class="hljs-literal">True</span>, drop_last=<span class="hljs-literal">True</span><span class="hljs-comment"># drop last现在可有可无</span><br>    ) <span class="hljs-keyword">for</span> dataset <span class="hljs-keyword">in</span> (train_ds, train_valid_ds)<br>]<br><br>valid_iter = DataLoader(valid_ds, batch_size, shuffle=<span class="hljs-literal">False</span>, drop_last=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">4</span>)<br>test_iter = DataLoader(test_ds, batch_size, shuffle=<span class="hljs-literal">False</span>, drop_last=<span class="hljs-literal">False</span>, num_workers=<span class="hljs-number">4</span>)<br><span class="hljs-comment"># num_workers 使用多线程运行</span><br></code></pre></td></tr></table></figure><h2 id="定义模型">4.定义模型</h2><p>这里我们使用models 模块中的resnet50模型, 对于CIAFAR-10我们从头训练不使用迁移学习. 但我们需要讲最后一层全连接层的输出改成我们需要的输出类别个数. 损失函数这里使用交叉熵误差.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_net</span>():<br>    num_classes = <span class="hljs-number">10</span><br>    net = models.resnet50(pretrained=<span class="hljs-literal">False</span>)<br>    net.fc = nn.Linear(models.resnet50().fc.in_features, num_classes)<br>    <span class="hljs-keyword">return</span> net<br><br>loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&quot;none&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="定义训练函数">5. 定义训练函数</h2><h3 id="辅助函数">辅助函数</h3><p>对象Accumulator 用于计算所有变量之和</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Accumulator</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;For accumulating sums over `n` variables.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n</span>):<br>        self.data = [<span class="hljs-number">0.0</span>] * n<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">self, *args</span>):<br>        self.data = [a + <span class="hljs-built_in">float</span>(b) <span class="hljs-keyword">for</span> a, b <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.data, args)]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reset</span>(<span class="hljs-params">self</span>):<br>        self.data = [<span class="hljs-number">0.0</span>] * <span class="hljs-built_in">len</span>(self.data)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> self.data[idx]<br></code></pre></td></tr></table></figure><p>accuracy 用于计算预测正确的数量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">accuracy</span>(<span class="hljs-params">y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Compute the number of correct predictions.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(y_hat.shape) &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> y_hat.shape[<span class="hljs-number">1</span>] &gt; <span class="hljs-number">1</span>:<br>        y_hat = argmax(y_hat, axis=<span class="hljs-number">1</span>)<br>    cmp = astype(y_hat, y.dtype) == y<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>(reduce_sum(astype(cmp, y.dtype)))<br></code></pre></td></tr></table></figure><p>evaluation_acc 用于计算验证准确率</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_acc</span>(<span class="hljs-params">net, data_iter, device=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(net, nn.Module):<br>        net.<span class="hljs-built_in">eval</span>()<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> device:<br>            device = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(net.parameters())).device<br><br>    metric = Accumulator(<span class="hljs-number">2</span>)<br><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(X, <span class="hljs-built_in">list</span>):<br>                X = [x.to(device) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X]<br>            <span class="hljs-keyword">else</span>:<br>                X = X.to(device)<br>            y = y.to(device)<br>            metric.add(accuracy(net(X), y), size(y))<br>    <span class="hljs-keyword">return</span> metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure><p>train_batch 用于对每个batch进行训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_batch</span>(<span class="hljs-params">net, feature, label, loss, optimizer, device</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(feature, <span class="hljs-built_in">list</span>):<br>        feature = [x.to(device) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> feature]<br>    <span class="hljs-keyword">else</span>:<br>        feature = feature.to(device)<br>    loss = loss.to(device)<br>    net.train()<br>    net.cuda()<br>    label = label.cuda(<span class="hljs-number">0</span>)<br>    optimizer.zero_grad()<br>    pred = net(feature)<br>    l = loss(pred, label)<br>    l.<span class="hljs-built_in">sum</span>().backward()<br>    optimizer.step()<br>    train_loss_sum = l.<span class="hljs-built_in">sum</span>()<br>    train_acc_sum = (pred.argmax(dim=<span class="hljs-number">1</span>) == label).<span class="hljs-built_in">sum</span>().item()<br>    <span class="hljs-keyword">return</span> train_loss_sum, train_acc_sum<br></code></pre></td></tr></table></figure><h3 id="定义训练函数-1">定义训练函数</h3><p>接下来我们定义train函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">net, train_iter, valid_iter, num_epochs, lr, wd, device, lr_period, lr_decay</span>):<br>    output_params = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">id</span>, net.fc.parameters()))<br>    feature_params = <span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> p: <span class="hljs-built_in">id</span>(p) <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> output_params, net.parameters())<br>    optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=wd)<br>    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_period, lr_decay)<br>    num_batches = <span class="hljs-built_in">len</span>(train_iter)<br>    legend = [<span class="hljs-string">&#x27;train loss&#x27;</span>, <span class="hljs-string">&#x27;train acc&#x27;</span>]<br>    <span class="hljs-keyword">if</span> valid_iter <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        legend.append(<span class="hljs-string">&#x27;valid acc&#x27;</span>)<br>    net.cuda()<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        start = time.time()<br>        net.train()<br>        metric = Accumulator(<span class="hljs-number">3</span>)<br>        <span class="hljs-keyword">for</span> i, (feature, label) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_iter):<br>            l, acc = train_batch(net, feature, label, loss, optimizer, device)<br>            metric.add(l, acc, label.shape[<span class="hljs-number">0</span>])<br>        <span class="hljs-keyword">if</span> valid_iter <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            valid_acc = evaluate_acc(net, valid_iter, device)<br>        scheduler.step()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span>&#x27;</span> + <span class="hljs-string">f&#x27;train loss <span class="hljs-subst">&#123;metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">2</span>]:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span> + <span class="hljs-string">f&#x27;train acc <span class="hljs-subst">&#123;metric[<span class="hljs-number">1</span>] / metric[<span class="hljs-number">2</span>]:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span> + <span class="hljs-string">f&#x27; time: <span class="hljs-subst">&#123;time.time() - start&#125;</span> sec&#x27;</span>)<br>    measures = (<span class="hljs-string">f&#x27;train loss <span class="hljs-subst">&#123;metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">2</span>]:<span class="hljs-number">.3</span>f&#125;</span>, &#x27;</span><br>                <span class="hljs-string">f&#x27;train acc <span class="hljs-subst">&#123;metric[<span class="hljs-number">1</span>] / metric[<span class="hljs-number">2</span>]:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br>    <span class="hljs-keyword">if</span> valid_iter <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        measures += <span class="hljs-string">f&#x27;, valid acc <span class="hljs-subst">&#123;valid_acc:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span><br>    <span class="hljs-built_in">print</span>(measures + <span class="hljs-string">f&#x27; examples/sec on <span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(device)&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="训练模型">6. 训练模型</h2><p>我们开始对模型进行训练, 这里使用GPU训练, 并且lr_period, lr_decay我们设置为4, 0.9, 意味着每4个周期学习率自乘0.9</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">device, num_epochs, lr, wd = <span class="hljs-string">&#x27;cuda&#x27;</span>, <span class="hljs-number">100</span>, <span class="hljs-number">2e-4</span>, <span class="hljs-number">5e-4</span><br>lr_period, lr_decay, net = <span class="hljs-number">4</span>, <span class="hljs-number">0.9</span>, get_net()<br>train(net, train_iter, valid_iter, num_epochs, lr, wd, device, lr_period, lr_decay)<br></code></pre></td></tr></table></figure><h2 id="提交结果">7. 提交结果</h2><p>但我们训练出了满意的结果后我们使用设计好的超参数和训练好的模型对测试集重新训练并且对测试集进行分类提交.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">net, preds = get_net(), []<br>train(net, train_valid_iter, <span class="hljs-literal">None</span>, num_epochs, lr, wd, device, lr_period, lr_decay)<br><span class="hljs-keyword">for</span> X, _ <span class="hljs-keyword">in</span> test_iter:<br>    y_hat = net(X.to(device))<br>    preds.extend(y_hat.argmax(dim=<span class="hljs-number">1</span>).<span class="hljs-built_in">type</span>(torch.int32).cpu().numpy())<br>sorted_ids = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(test_ds) + <span class="hljs-number">1</span>))<br>sorted_ids.sort(key=<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">str</span>(x))<br>df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;id&#x27;</span>: sorted_ids, <span class="hljs-string">&#x27;label&#x27;</span>: preds&#125;) <span class="hljs-comment"># 此为Kaggle要求格式</span><br>df[<span class="hljs-string">&#x27;label&#x27;</span>] = df[<span class="hljs-string">&#x27;label&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: train_valid_ds.classes[x])<br>df.to_csv(<span class="hljs-string">&#x27;C:\\Users\\***\\OneDrive\\桌面\\kaggle\\CIFAR-10\\submission.csv&#x27;</span>, index=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>最终我们会得到一个submission.csv文件我们就可以把他上传到Kaggle啦.</p><h2 id="references">References</h2><p>https://tangshusen.me/Dive-into-DL-PyTorch/#/</p><p>https://zh-v2.d2l.ai/</p><p>https://github.com/d2l-ai/d2l-zh</p><p>https://pytorch.org/docs/stable/index.html</p><p>https://blog.csdn.net/mao_hui_fei/article/details/89477938</p>]]></content>
    
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ggplot2 cheat sheet (转载)</title>
    <link href="/2021/05/11/ggplot2-cheat-sheet-%E8%BD%AC%E8%BD%BD/"/>
    <url>/2021/05/11/ggplot2-cheat-sheet-%E8%BD%AC%E8%BD%BD/</url>
    
    <content type="html"><![CDATA[<p><img src= "https://i.loli.net/2021/05/11/L8SQ9tZkW7YdRX4.png"></p><p><img src="https://i.loli.net/2021/05/11/6LzuwcQAZnqlDfg.png"></p><h2 id="reference">reference</h2><p>https://www.rstudio.com/resources/cheatsheets/</p>]]></content>
    
    
    
    <tags>
      
      <tag>ggplot2</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>R语言 dnorm, pnorm, qnorm, rnorm的区别</title>
    <link href="/2021/05/09/R%E8%AF%AD%E8%A8%80-dnorm-pnorm-qnorm-rnorm%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <url>/2021/05/09/R%E8%AF%AD%E8%A8%80-dnorm-pnorm-qnorm-rnorm%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<h1 id="前言">前言</h1><p>dnorm, pnorm, qnorm, rnorm 是R语言中常用的正态分布函数. <strong>norm</strong> 指的是正态分布(也可以叫高斯分布(<strong>normal distribution</strong>)), R语言中也有其他不同的分布操作也都类似. <strong>p q d r</strong> 这里分别指的是不同的函数下面将会详细简介这不同函数在正态分布中的应用以及这是个命令在R中如何使用.</p><h2 id="dnorm">dnorm</h2><p><strong>d</strong> - 指的是概率密度函数(probability density function)</p><p>正态分布的公式: <span class="math display">\[f(x|\mu, \sigma)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}\]</span> <img src="https://i.loli.net/2021/05/09/oEpTxL26XQB7AFZ.png" width="75%"></p><p>dnorm实质上是正态分布概率密度函数值. 说人话就是返回上面这个函数的值.下面我们在代码中演示下:</p><figure class="highlight r"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><pre><code class="hljs R"><span class="hljs-comment"># 输出在标准正态分布下(mean = 0, standard deviation = 1) 0 的z-sore</span><br>dnorm<span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-punctuation">,</span> mean<span class="hljs-operator">=</span><span class="hljs-number">0</span><span class="hljs-punctuation">,</span> sd<span class="hljs-operator">=</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.3989423</span><br><span class="hljs-comment"># 因为是标准正态分布所以mean和sd是可以省略的</span><br>dnorm<span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.3989423</span><br><span class="hljs-comment"># 如果是一个非标准正态分布如下:</span><br>dnorm<span class="hljs-punctuation">(</span><span class="hljs-number">2</span><span class="hljs-punctuation">,</span> mean<span class="hljs-operator">=</span><span class="hljs-number">5</span><span class="hljs-punctuation">,</span> sd<span class="hljs-operator">=</span><span class="hljs-number">3</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.08065691</span><br></code></pre></td></tr></table></figure><h2 id="pnorm">pnorm</h2><p><strong>p</strong> - 指的是概率密度积分函数（从无限小到 x 的积分）(Probability density integral function)</p><p>x指的是一个z-score, 专业名词听着玄幻, 其实就是正态分布曲线下x左边的面积(概率占比), 我们知道z-score求在哪个分为数上</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs R"><span class="hljs-comment"># 标准正态分布</span><br>pnorm<span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.5 (50%)</span><br>pnorm<span class="hljs-punctuation">(</span><span class="hljs-number">2</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.9772499</span><br><span class="hljs-comment"># 非标准正态分布</span><br>pnorm<span class="hljs-punctuation">(</span><span class="hljs-number">2</span><span class="hljs-punctuation">,</span> mean<span class="hljs-operator">=</span><span class="hljs-number">5</span><span class="hljs-punctuation">,</span> sd<span class="hljs-operator">=</span><span class="hljs-number">3</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.1586553</span><br><span class="hljs-comment"># 也可以求x右边的概率</span><br>pnorm<span class="hljs-punctuation">(</span><span class="hljs-number">2</span><span class="hljs-punctuation">,</span> mean<span class="hljs-operator">=</span><span class="hljs-number">5</span><span class="hljs-punctuation">,</span> sd<span class="hljs-operator">=</span><span class="hljs-number">3</span><span class="hljs-punctuation">,</span> lower.tail<span class="hljs-operator">=</span><span class="hljs-literal">FALSE</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.81586553</span><br><span class="hljs-comment"># pnorm也能用来求置信区间</span><br>pnorm<span class="hljs-punctuation">(</span><span class="hljs-number">3</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">-</span> pnorm<span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.1573054</span><br></code></pre></td></tr></table></figure><p><img src="https://i.loli.net/2021/05/09/UunzrTedDcxh7Vf.png"></p><p>上图用R可以这么写</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs R">pnorm<span class="hljs-punctuation">(</span><span class="hljs-number">2</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0.9772499</span><br></code></pre></td></tr></table></figure><h2 id="qnorm">qnorm</h2><p><strong>q</strong> - 指的是分位数函数(quantile function)</p><p>简单来说它就是pnorm的反函数, 通过百分比算z-score, 我知道分位数求z-score, 例如:</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs R"><span class="hljs-comment"># 在标准正态分布中求z-score</span><br>qnorm<span class="hljs-punctuation">(</span><span class="hljs-number">0.5</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 0</span><br>qnorm<span class="hljs-punctuation">(</span><span class="hljs-number">0.96</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 1.750686</span><br>qnorm<span class="hljs-punctuation">(</span><span class="hljs-number">0.99</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 2.326348</span><br></code></pre></td></tr></table></figure><h2 id="rnorm">rnorm</h2><p><strong>r</strong> - 指的是随机数函数(random function)（常用于概率仿真）</p><p>它是用来生成一组符合正态分布的随机数, 例如:</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs R"><span class="hljs-comment"># 设置随机数种子</span><br>set.seed<span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span><br><span class="hljs-comment"># 生成5个符合标准正态分布的随机数</span><br>rnorm<span class="hljs-punctuation">(</span><span class="hljs-number">5</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078</span><br><span class="hljs-comment"># 生成10个mean=70, sd=5的正态分布随机数</span><br>rnorm<span class="hljs-punctuation">(</span><span class="hljs-number">10</span><span class="hljs-punctuation">,</span> mean<span class="hljs-operator">=</span><span class="hljs-number">70</span><span class="hljs-punctuation">,</span> sd<span class="hljs-operator">=</span><span class="hljs-number">5</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 65.89766 72.43715 73.69162 72.87891 68.47306 77.55891 71.94922 66.89380 58.92650 75.62465</span><br></code></pre></td></tr></table></figure><p>在R语言中生成别的各种分布也都是以d, p, q, r开头, 原理和正态分布相似</p><h2 id="references">references</h2><p>http://www.360doc.com/content/18/0913/18/19913717_786412696.shtml</p><p>https://www.runoob.com/r/r-basic-operators.html</p>]]></content>
    
    
    
    <tags>
      
      <tag>R</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hexo d部署报错之spawn failed的解决方案</title>
    <link href="/2021/05/09/Hexo%20d%E9%83%A8%E7%BD%B2%E6%8A%A5%E9%94%99%E4%B9%8Bspawn%20failed%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <url>/2021/05/09/Hexo%20d%E9%83%A8%E7%BD%B2%E6%8A%A5%E9%94%99%E4%B9%8Bspawn%20failed%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
    
    <content type="html"><![CDATA[<p>关于Hexo部署的时候报错导致无法推送到github估计是很多小伙伴第一次接触Hexo框架编写博客的常见问题, 下面介绍两种解决方案.</p><p><img src="https://i.loli.net/2021/05/09/fsRDw1AS2VpO35o.png"></p><h2 id="解决方案一">解决方案(一)</h2><ol type="1"><li>在博客文件夹(通常是***)中删除时 <strong>.deploy_git</strong> 文件</li><li>命令行(terminal)[不推荐使用<strong>cmd</strong>, 使用 <strong>git bash</strong> 等] 中输入 <code>git config --global core.autocrlf false</code>把git加入系统环境变量</li><li>重新执行<code>hexo c</code> <code>hexo g</code> <code>hexo d</code></li></ol><p>上Google百度一查大部分都是这种方法, xdm可以自己试试看万一成了呢. 但我下面推荐另一种可能的解决方案</p><h2 id="解决方案二">解决方案(二)</h2><ol type="1"><li><p>首先用文本编辑器(我使用的是Notepad++)打开博客文件夹(通常是***)中的 **_config.yml** 配置文件</p></li><li><p>修改配置文件中的<strong>repo</strong></p><figure class="highlight dts"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><pre><code class="hljs dts"><span class="hljs-meta"># Deployment</span><br><span class="hljs-meta">## Docs: https:<span class="hljs-comment">//hexo.io/docs/one-command-deployment</span></span><br><span class="hljs-symbol">deploy:</span><br><span class="hljs-symbol">  type:</span> git<br><span class="hljs-symbol">  repo:</span>https:<span class="hljs-comment">//github.com/YourName/YourName.github.io.git(不要使用这个)</span><br>  git@github.com:YourName/YourName.github.io.git(用这个)<br><span class="hljs-symbol">  branch:</span> master<br></code></pre></td></tr></table></figure></li><li><p>重新执行<code>hexo c</code> <code>hexo g</code> <code>hexo d</code></p></li></ol><p>这样就大功告成啦, 很简单吧, 继续写你的博客吧!</p><h2 id="reference">reference</h2><p>https://blog.zhheo.com/p/128998ac.html</p><p>https://blog.csdn.net/njc_sec/article/details/89021083</p>]]></content>
    
    
    
    <tags>
      
      <tag>Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
